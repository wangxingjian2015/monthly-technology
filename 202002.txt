可以看出MyISM的索引文件仅仅保存数据记录的地址，在MyISM中，主索引和辅助索引(Secondary Index)在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。
因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键(MyISM可以没有)，如果没有显式指定，则MySQL会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，自动为InnoDB表生成一个隐含字段作为主键，这个字段的长度为6个字节，类型为长整型。

Eureka：
	1. EurekaServer默认有两个缓存，一个是ReadWriteMap, 另一个是ReadOnlyMap。有服务提供者注册服务或者维持心跳时，会修改ReadWriteMap。当有服务调用者查询实例列表时，默认会从ReadOnlyMap读取(这个在原生Eureka可以配置，SpringCloud Eureka中不能配置，一定会启用ReadOnlyMap读取)，这样可以减少ReadWriteMap读写锁的争用，增大吞吐量。EurekaServer定时把数据从ReadWriteMap更新到ReadOnlyMap中。
	ReadWriteMap是一个Guava Cache，过期时间是可以配置的。
	2. 服务提供者注册服务后，会定时心跳。这个根据服务提供者的Eureka配置中的服务刷新时间决定。还有个配置是服务过期时间，这个配置在服务提供者配置但是在EurekaServer使用，但是默认配置EurekaServer不会启用这个字段。需要配置好EurekaServer的扫描失效时间，才会启用EurekaServer的主动失效机制。在这个机制启用下：每个服务提供者会发送自己服务过期时间上去，EurekaServer会定时检查每个服务过期时间和上次心跳时间，如果在过期时间内没有收到任何一次心跳，同时没有处于保护模式下，则会将这个实例从ReadWriteMap中去掉。
	3. 在默认没有启用EurekaServer主动失效服务实例的情况下，服务过期是利用ReadWriteMap超时缓存失效实现的，只有发送心跳的实例缓存不会失效。
	4. 服务调用者有本地缓存，定时从Eureka服务器上增量拉取所有服务实例列表。

服务提供者和服务调用者配置不够灵敏，总是服务提供者在停掉很久之后，服务调用者很长时间并没有感知到变化的原因:EurekaServer自己的ReadWriteMap缓存失效延迟，刷新到ReadOnlyMap的延迟，服务调用者自己本地刷新的延迟。

服务已经注册上去了，但是服务调用方很长时间还是调用不到，发现不了这个服务：刷新到ReadOnlyMap的延迟，服务调用者自己本地缓存刷新的延迟。
---------------------------------------------------
# eureka server刷新readCacheMap的时间，注意:client读取的是readCacheMap,这个时间决定了多久会把readWriteCacheMap的缓存更新到readCacheMap上
#默认30S
eureka.server.responseCacheUpdateIntervalMs=3000
#eureka server缓存readWriteCacheMap失效时间，这个只有在这个时间过去后缓存才会失效，失效前不会更新，过期后从registry重新读取注册服务信息，registry是一个ConcurrentHashMap。
#由于启用了evict其实就用不太上改这个配置了
#默认180秒
eureka.server.responseCacheAutoExpirationInSeconds=180

#启用主动失效，并且每次主动失效检测间隔为3秒
eureka.server.eviction-interval-timer-in-ms=3000

#服务过期时间配置，超过这个时间没有接收到心跳EurekaServer就会将这个实例剔除
#注意，EurekaServer一定要设置eureka.server.evition-interval-timer-in-ms否则这个配置无效，这个配置一般为服务刷新时间配置的三倍
#默认90秒
eureka.instance.lease-expiration-duration-in-seconds=15
#服务刷新时间配置，每隔这个时间会主动心跳一次
#默认30秒 
eureka.instance.lease-renewal-interval-in-seconds=5

#eureka client刷新本地缓存时间
#默认30秒 
eureka.client.registryFetchIntervalSeconds=5
#eureka客户端ribbon刷新时间
#默认30秒 
ribbon.ServerListRefreshInterval=5000
---------------------------------------------------
public final class String implements java.io.Serializable,
	Comparable<String>, CharSequence {
	...
	/* Returns a canonical representation for the string object.
		A pool of strings, initially empty, is maintained privately by the 
		class #String.
		When the intern method is invoked, if the pool already contains 
		a string equals to this #String object as determined by the 
		#equals(Object) method, then th string from the pool is returned.
		Otherwise, this #String object is added to the pool and a reference to 
		this #String object is returned.
		It follows that for any two strings #s and #t, s.intern() == t.intern() is 
		#true if and only if #s.equals(t) is true.
		All literal strings and string-valued constant expressions are interned. 
		String literals are defined in section 3.10.5 of Java Specification.
	*/
	public native String intern();
}

判断字符串是否被缓存到常量池的两大要素：
	1. 编译期间：字符串连接中没有使用变量或者调用方法(没有直接new)；
	2. 是否使用了intern()：使用了该方法的字符串变量的值如果不存在常量池，则放在常量池中。

javap/jad
Sting对象的不可变性的好处：
	1. 保证String对象的安全性。假设String对象是可变的，那么String对象将可能被恶意修改。
	2. 保证hash属性值不会频繁变更，确保了唯一性，使得类似HashMap容器才能实现相应的key-value缓存功能。
	3. 可以实现字符串常量池。
	
String str = new String(“abc”) 这种方式，首先在编译类文件时，"abc"常量字符串将会放入到常量结构中，在类加载时，“abc"将会在常量池中创建；其次，在调用 new 时，JVM 命令将会调用 String 的构造函数，同时引用常量池中的"abc” 字符串，在堆内存中创建一个 String 对象；最后，str 将引用 String 对象。	
	

Netty的ByteBuf API的优点：
	1. 可以被用户自定义的缓冲区类型扩展；
	2. 通过内置的复合缓冲区类型实现了透明的零拷贝；
	3. 容量可以按需增长(类似于JDK的StringBuilder)；
	4. 在读和写两种模式之间切换不需要调用ByteBuffer的flip()方法；
	5. 读和写使用了不同的索引；
	6. 支持方法的链式调用；
	7. 支持引用计数；
	8. 支持池化。

ByteBuf是一个抽象类，内部全部是抽象的函数接口，AbstractByteBuf这个抽象类基本实现了ByteBuf。
ByteBuf都是基于字节序列的，类似于一个字节数组。在AbstractByteBuf里面定义了下面5个变量：
int readerIndex;
int writerIndex;
private int markedReaderIndex;
private int markedWriterIndex;
private int maxCapacity;
ByteBuf与JDK中的ByteBuffer最大区别就是：
	1. Netty的ByteBuf采用读写索引分离，一个初始化的ByteBuf的readerIndex和writerIndex都处于0位置。
	2. 当读索引和写索引处于同一位置时，如果继续读取，会抛出IndexOutOfBoundsException。
	3. 对于ByteBuf的任何读写操作都会单独维护读索引和写索引。maxCapacity最大容量是Integer.MAX_VALUE。

Netty中对于IO通信线程中读写缓存时建议使用DirectByteBuffer，因为涉及大量的IO数据读写。对于后端的业务消息的编解码模块使用HeapByteBuffer。


使用ThreadLocal时要注意什么？
	1. 一般需要声明为private static final。
	2. 在线程池环境下，由于线程一直存在，使用ThreadLocal可能看到之前Runnable的变量值；解决方法：当前任务执行完后将ThreadLocal进行remove或设置为初始值。
	3. 内存泄漏。解决方法：显式remove

public class CopyOnWriteArrayList<E> implements List<E>, RandomAccess,
		Cloneable, java.io.Serializable {
	private static final long serialVersionUID = 8673264195747942595L;
	// The lock protecting all mutators 
	final transient ReentrantLock lock = new ReentrantLock();
	// The array, accessed only via getArray/setArray
	private transient volatile Object[] array;
	...
	public E set(int index, E element) {
		final ReentrantLock lock = this.lock;
		lock.lock();
		try {
			Object[] elements = getArray();
			E oldValue = get(elements, index);
			if (oldValue != element) {
				int len = elements.length;
				Object[] newElements = Arrays.copyOf(elements, len);
				newElements[index] = element;
				setArray(newElements);
			} else {
				// Not quite a no-op; ensures volatile write semantics
				setArray(elements);
			}
			return oldValue;
		} finally {
			lock.unlock();
		}
	}
	...
}

CopyOnWriteArrayList在删除操作时，可能会存在线程不安全问题：当一个线程打算读取最后一个元素，但另外一个线程删除了最后一个元素，此时数组元素个数减少，发生数组越界异常。

RegisterChannelFuture/NioEventLoop
Netty是一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能协议服务器和客户端。

Channel, ChannelPipeline, ChannelHandler, ChannelEvent, ServerBootstrap,
NioServerSocketChannelFactory, ChannelPipelineFactory, ChannelPipeline,Channels,
SimpleChannelUpstreamHandler, ChannelHandlerContext, MessageEvent, ChannelBuffer,

JDK原生NIO程序的问题：
	1. NIO的类库和API繁杂，使用麻烦，需要熟悉:Selector, ServerSocketChannel, SocketChannel, ByteBuffer等。
	2. 需要具备其他额外技能。例如熟悉Java多线程编程，因为NIO涉及Reactor模式，必须对多线程和网络编程非常熟悉，才能编写出高质量的NIO程序。
	3. 可靠性能力补齐，开发工作量和难度都非常大。例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常码流的处理。

Netty作为异步事件驱动的网络，高性能主要来自于IO模型和线程处理模型，前者决定如何收发数据，后者决定如何处理数据。
NioEventLoop 
----------------------------
事件驱动模型，主要包括4个基本组件：
	1. 事件队列(event queue):接收事件的入口，存储待处理事件；
	2. 分发器(event mediator): 将不同的事件分发到不同的业务逻辑单元；
	3. 事件通道(event channel)： 分发器和处理器之间的联系渠道；
	4. 事件处理器(event processor)：实现业务逻辑，处理完成后会发出事件，触发下一步操作。
可以看出，相对于传统轮询模式，事件驱动有如下优点：
	1. 可扩展性好，分布式的异步架构，事件处理器之间高度解耦，可以方便扩展事件处理逻辑。
	2. 高性能，基于队列暂存事件，能方便并行异步处理事件。
----------------------------
取决于Reactor的数量和Handler线程数量的不同，Reactor模型有3个变种：
	1. 单Reactor单线程;
	2. 单Reactor多线程;
	3. 主从Reactor多线程;
Netty主要基于主从Reactor多线程模型做了一定的修改，其中主从Reactor多线程模型有多个Reactor：
	1. MainReactor负责客户端的连接请求，并将请求转交给SubReactor；
	2. SubReactor负责相应通道的IO读写请求；
	3. 非IO请求(具体逻辑处理)的任务会直接写入队列，等待worker threads进行处理。
特别说明：虽然Netty的线程模型基于主从Reactor多线程，借用了MainReactor和SubReactor的结构。但是实际实现上SubReactor和Worker线程在同一个线程池中。
Netty中的IO操作是异步的，包括bind,write,connect等操作会简单的返回一个ChannelFuture。调用者并不能立刻获得结果，而是通过Future-Listener机制，可以方便的主动获取或者通过通知机制获得IO操作结果。
NioSocketChannel, NioServerSocketChannel, NioDatagramChannel, NioSctpChannel, NioSctpServerChannel
NioEventLoop中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用NioEventLoop的run方法，执行IO任务和非IO任务：
	IO任务，即selectionKey中的ready事件，如accept,connect,read,write等，由processSelectedKeys方法触发。
	非IO任务，添加到taskQueue中的任务，如register0,bind0等任务，由runAllTasks方法触发。
两种任务的执行时间由变量ioRatio控制，默认为50，则表示非IO任务执行的时间和IO任务的执行时间相等。
NioEventLoopGroup，主要管理eventLoop的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程(NioEventLoop)负责处理多个Channel上的事件，而一个Channel只对应一个线程。
ChannelHandler, ChannelInboundHandler, ChannelOutboundHandler, ChannelInboundHanderAdapter,
ChannelOutboundHandlerAdapter, ChannelDuplexHandler
ChannelHandlerContext ChannelPipelin 

unclean.leader.election.enable设置为false，表明，当存在最新一条记录的replication宕机的时候，Kafka自己会选举出一个主节点，如果默认允许还未同步最新数据的replication所在的节点被选举为主节点的话，你的数据为丢失，因此应该按需将参数设置为false；
auto.offset.reset参数设置为earlist避免出现offset丢失的时候，跳过需要消费的数据情况，准确来说这里并非丢失，即使因为参数配置问题出现跳过的情况，也可以通过前置offset找回历史消息。

从Kafka 0.11版本开始，生产者就支持两种额外的发送模式：幂等发送(The idempotent producer)和事务发送(The transactional producer)，可以说是Kafka在支持EOS(exactly-once semantics)上的重要功能。
为了实现Producer的幂等性，Kafka引入了Producer ID(即PID)和Sequence Number。
PID：当Producer在初始化的时候，会分配一个唯一的PID,这个PID对用户是不可见的。
Sequence Number:对于每个PID，该Producer发送数据的每个<Topic, Partition>都对应一个从0开始单调递增的Sequence Number。
Broker端在缓存中保存了Sequenc Number，对于接收的每条消息，如果其序号比Broker缓存中序号大于1则接受，否则将其丢弃。这样就可以实现了消息重复提交了。但是，只能保证单个Producer对于同一个<Topic,Partition>的EOS，不能保证同一个Producer一个topic不同partition幂等。

目前比较新版本的Kafka正式替换了Scala版本的old producer，使用了由java重写的producer，新版本的producer采用异步发送机制，KafkaProducer.send(ProducerRecord)方法仅仅是把这条消息放入一个缓存中（即RecordAccumulator,本质上使用队列来缓存记录），同时后台的IO线程会不断扫描该缓存区，将满足条件的消息封装到某个batch中然后发送出去，显然，这个过程中就有一个数据丢失的窗口：若IO线程发送之前client端挂掉了，累积在accumulator中的数据的确有可能会丢失。

Producer的另一个问题是消息乱序问题，假设客户端代码依次执行下面的语句将两条消息发到相同的分区
producer.send(record1);
producer.send(record2);
如果此时由于某些原因（比如瞬间的网络抖动）导致record1没有成功发送，同时kafka又配置了重试机制和max.in.flight.requests.per.connection大于1(默认值是5，本来就是大于1的)，那么重试record1成功后，record1在分区中就在record2之后，从而造成消息的乱序，很多某些要求强顺序保证的场景是不允许出现这种情况的。发送之后重发就会丢失顺序
max.in.flight.requests.per.connection=1:限制客户端在单个连接上能够发送的未响应请求的个数，设置此值为1表示Kafka Broker在响应请求之前Client不能再向同一个Broker发送请求，注意：设置此参数是为了避免消息乱序。

BKA是指在表连接的过程中为了提升join性能而使用的一种join buffer，其作用是在读取被join表的记录的时候使用顺序IO，BKA被使用的标识是执行计划的extr信息中会有"Batched Key Access"信息。
使用BKA的表的join过程如下：
	1. 连接表将满足条件的记录放入JOIN_CACHE，并将两表连接的字段放入一个 DYNAMIC_ARRAY ranges 中，此过程类似于 MRR 操作的过程，且在内存中使用的是同样的结构体 DsMrr_impl；
	2. 在进行表的过接过程中，会将 ranges 相关的信息传入 DsMrr_impl::dsmrr_fill_buffer，并进行被连接表主建的查找及排序等操作操作，这个过程比较复杂，包括需要判断使用的 key、key 是主建时的特殊操作等；
	3. JOIN_CACHE_BKA::join_matching_records 会调用过程2中产生的有序主建，然后顺序读取数据并进入下一步的操作（evaluate_join_record 等）；
	4. 当缓冲区的数据被读完后，会重复进行过程2，3, 直到记录被读取完。
由上面的分析可以看出，BKA将有序主键投递到存储引擎是通过MRR的接口的调用来实现的(DsMrr_impl::dsmrr_next)，所以BKA依赖MRR，如果要使用BKA，MRR是需要打开的，另外batched_key_access是默认关闭的，如果要使用，需要打开此选项。

Netty的零拷贝：
	1. 使用FileChannel.transfer避免在用户态和内核态之间的拷贝操作；
	2. 通过CompositeByteBuf组合多个ByteBuffer；
	3. 通过slice获取ByteBuffer的切片；
	4. 通过wrapper把普通ByteBuffer封装成netty.ByteBuf。
----------------------------------------------------
数据库隔离怎么实现的(原理)：
read_uncommited的原理：
	- 事务对当前被读取的数据不加锁；
	- 事务在更新某数据的瞬间(就是发生更新的瞬间)，必须先对其加行级共享锁，直到事务结束才释放。
read_commited的原理：
	- 事务对当前被读取的数据加行级共享锁(当读到时才加锁)，一旦读完该行，立即释放该行级共享锁；
	- 事务在更新某数据的瞬间(就是发生更新的瞬间)，必须先对其加行级排它锁，直到事务结束才释放。 
repeatable_read的原理:
	- 事务在读取某数据的瞬间(就是开始读取的瞬间)，必须对其加行级共享锁，直到事务结束才释放；
	- 事务更新某数据的瞬间(就是发生更新的瞬间)，必须对其加行级排它锁，直到事务结束才释放。
serializable的原理：
	- 事务在读取数据时，必须先对其加表级共享锁，直到事务结束才释放；
	- 事务在更新数据时，必须先对其加表级排它锁，直到事务结束才释放。
----------------------------------------------------
数据库事务有不同的隔离级别，不同的隔离级别对锁的使用是不同的，锁的应用最终导致不同事务的隔离级别。
MySQL的repeatable_read可重复读可以通过MVCC解决幻读问题，但不能解决下面的问题：A,B两个事务，A事务开始，B事务开始，A事务插入一条记录，A事务提交，B事务插入同一条记录，B事务提交。最终导致主键冲突。这种情况只能在serializable隔离级别下才能解决。
MySQL和其他数据库不一样，它可以在可重复读范围内解决幻读问题。

select机制的问题：
	1. 每次调用select，都需要把fd_set集合从用户态拷贝到内核态，如果fd_set集合很大时，那么开销很大；
	2. 每次调用select都需要遍历从内核传递过来的所有fd_set，如果fd_set集合很大时，那么开销很大；
	3. 为了减少数据拷贝带来的性能损失，内核对被监控的fd_set集合大小做了限制，并且这个是通过宏控制的，大小不可改变(限制为1024).
poll的机制与select类似，与select本质上没有多大差别，管理多个描述符也是进行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。也就是，poll只解决了上面的问题3，并没有解决问题1，2的性能开销问题。
epoll在Linux2.6内核正式提出，是基于事件驱动的IO方式，相对于select来说，epoll没有描述符个数限制，使用一个文件描述符管理多个描述符，将用户关心的文件描述符的事件存放在内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。
epoll是Linux内核为处理大批量文件描述符而改进的poll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下系统CPU利用率。原因就是获取事件的时候，它无需遍历真个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。
epoll除了提供select/poll那种IO事件的水平触发(Level Triggered)外，还提供了边缘触发(Edge Triggered)，这就使得用户空间程序有可能缓存IO状态，减少epoll_wait/epoll_pwait的调用，提高应用程序效率。
水平触发(LT)：默认工作模式，即当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序可以不立即处理该事件；下次调用epoll_wait时，会再次通知此事件。
边缘触发(ET): 当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次通知此事件(直到你做了某些操作导致该描述符变成未就绪状态了，也就是说边缘触发只在状态由未就绪变为就绪时，只通知一次)。
ET模式很大程度上减少了epoll事件的触发次数，因此效率比LT模式下高。

Active Record(活动记录)，是一种领域模型模式，特点是一个模型类对应关系型数据库中的一个表，而模型类的一个实例对应表中的一行记录。

MyBatis的#{}和${}的区别：
	1. #是预编译的方式，$是直接拼接；
	2. #不需要关注数据类型，MyBatis实现自动数据类型转换；$不做数据类型转换，需要自行判断类型；
	3. #可以防止SQL注入，$无法防止SQL注入；
	4. 如果parameterType只有一个参数，默认情况下，#{}中可以写任意的名字；${}只能用value来接收。
	5. 因为预编译语句可以缓存PreparedStatement对象，MyBatis会预编译，#{}性能相对会高一些。
在某些场景下，只能用${}，比如order by后的排序字段、表名、列名等，因为需要替换为不变的常量

Record Locks:行锁，该锁是对索引记录进行加锁。锁是加在索引上而不是行上。
Gap Locks:间隙锁，是对索引的间隙加锁，其目的只有一个，防止其他事务插入数据。在Read Committed隔离级别下，不会使用间隙锁。隔离级别比Read Committed低的情况下，也不会使用间隙锁，如隔离级别为Read Uncommitted时，也不存在间隙锁。当隔离级别为Repeatable Read和Serializable时，就会存在间隙锁。

begin/start transaction命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表的语句(第一个快照读语句)，事务才真正启动。如果想要马上启动一个事务，可以使用start transaction with consistent snapshot这个命令。

在MySQL中，有两个"视图"的概念：
	1. 一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view ...，而它的查询方法与表一样。
	2. 另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view,用于支持RC和RR隔离级别的实现。

在实现上，InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在"活跃"的所有事务ID。"活跃"指的是：启动了但还没提交。
数组里事务ID的最小值为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。
这个视图数组和高水位，就组成了当前事务的一致性视图(read-view)。而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的比对结果得到的。
一条规则：更新数据都是先读后写，而这个读，只能读当前的值，称为"当前读"(current read)。
其实，除了update语句外，select语句如果加锁，也是当前读。所以，如果select * from t where id=1，加上lock in share mode或for update，也都可以读到版本号是最新的值。
可重复读的核心就是一致性读(consistent read)；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。
而读提交(RC)和可重复读的逻辑类似，它们最主要的区别是：
	1. 在可重复读隔离级别下，只需要事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
	2. 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。

消息队列具有以下优势：
	1. 削峰填谷(主要解决瞬时写压力大于应用服务器能力导致消息丢失、系统崩溃等问题);
	2. 系统解耦(解决不同重要程度、不同能力级别系统之间依赖导致系统同生共死)；
	3. 提升性能(当存在一对多调用时，可以发一条消息给消息系统，让消息系统通知相关系统);
	4. 蓄流压测(线上有些链路不好压测，可以通过堆积一定量消息再放开来压测)
RocketMQ相比于RabbitMQ,Kafak具有的优势：
	1. 支持事务型消息(消息发送和DB操作保持两方的最终一致性，RabbitMQ和Kafka不支持);
	2. 支持结合RocketMQ的多个系统之间数据最终一致性(多方事务、二方事务是前提)；
	3. 支持18个级别的延迟消息(RabbitMQ和Kafka不支持)；
	4. 支持指定次数和时间间隔的失败消息重发(Kafka不支持，RabbitMQ需要手动确认)；
	5. 支持Consumer端tag过滤，减少不必要的网络传输(RabbitMQ和Kafka不支持);
	6. 支持重复消费(RabbitMQ不支持，Kafka支持).

LOCK_REC_NOT_GAP：锁带上这个flag时，表示这个锁对象只是单纯的锁在记录上，不会锁记录之前的gap。在RC隔离级别下一般加的都是该类型的记录锁(但唯一二级索引上的duplicate key检查除外，总是加LOCK_ORDINARY类型的锁)。
LOCK_GAP:表示只锁住一段范围，不锁记录本身，通常表示两个索引记录之间，或者索引上的第一个记录之前，或者最后一条记录之后的锁。可以理解为一种区间锁，一般在RR隔离级别下会使用到GAP锁。
可以通过切换到RC隔离级别，或者开启选项innodb_locks_unsafe_for_binlog来避免GAP锁。这时候只有在检查外键约束或者duplicate key检查时才会使用到GAP LOCK。
LOCK_ORDINARY(Next-Key Lock):即next-key锁，包括记录本身及记录之前的GAP。当前MySQL默认情况下使用RR的隔离级别，而Next-key Lock正是为了解决RR隔离级别下的幻读问题。所谓幻读就是一个事务内执行相同的查询，会看到不同的行记录。在RR隔离级别下这是不允许的。

大多数情况下，事务锁都是在事务提交时释放，但有两种意外：
	1. Auto-inc锁在SQL结束时直接释放；
	2. 在RC隔离级别下执行DML语句时，从引擎层返回到Server层的记录，如果不满足where条件，则需要立刻unlock掉。
除了这两种情况外，其他的事务都是在事务提交时释放的。事务持有的所有锁都维护在链表trx_t::lock.trx_locks上，依次遍历释放即可。

Redis底层数据结构：
简单动态字符串
链表
字典
跳跃表
整数集合
压缩列表
对象 

SDS与传统C字符串的区别：
	1. 获取字符串长度SDS是O(1),C字符串O(n)；
	2. 杜绝缓冲区溢出；Redis中SDS的空间分配策略完全杜绝了发生缓冲区溢出的可能性:当需要对SDS进行修改时候，Redis会在执行拼接操作之前，预先检查给定SDS空间是否足够，如果不够，会先扩容。
	3. 减少修改字符串时带来的内存重分配次数；
	4. 惰性空间释放；
	5. 二进制安全；C字符串的字符必须符合某种编码，并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串末尾，这些限制使得C字符串只能保存文本数据，而不能保存图片、音频、视频、压缩文件这样的二进制数据。但是在Redis中，不是靠空字符来判断字符串末尾的，而是通过len属性。即便中间出现了空字符对于SDS来说，读取该字符仍然是可以的。
	6. 兼容部分C字符串函数。
链表的特性：
	1. 双端：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点的时间复杂度是O(1);
	2. 无环：表头节点的prev指针和表尾节点的next都是NULL。
	3. 表头和表尾：因为链表带有head指针和tail指针，程序获取链表头节点和尾节点的时间复杂度是O(1);
	4. 长度计数器：链表中存有链表长度的属性len；
	5. 多态：链表节点使用void*指针来保存节点值，并且可以通过list结构的dup,free,match三个属性为节点值设置类型特定函数。

如果一个hashmap有一亿条数据怎么实现高效查找; 
答：可以考虑优化hash函数减少碰撞(事后大佬指点分布不均匀的话更好的应该是进行分层)

mybatis的dao接口跟xml文件里面的sql是如何建立关系的:
	1. SqlSource以及动态标签SqlNode;
	2. MappedStatement对象；
	3. Spring工厂Bean以及动态代理；
	4. SqlSession以及执行器；

磁盘到内核空间属于DMA拷贝，用户空间与内核空间之间的数据传输并没有类似DMA这种可以不需要CPU参与的传输方式，因此用户空间与内核空间之间的数据传输是需要CPU全程参与的。DMA拷贝即直接内存存取，原理是外部设备不通过CPU而直接与系统内存交换数据。所以也就有了使用零拷贝技术，避免不必要的CPU数据拷贝过程。
使用NIO零拷贝，流程简化为两步：
	1. transferTo方法调用触发DMA引擎将文件上下文信息拷贝到内核读缓冲区，接着内核将数据从内核缓冲区拷贝到与套接字相关的缓冲区；
	2. DMA引擎将数据从内核套接字缓冲区传输到协议引擎(第三次数据拷贝)；
相比较传统IO，使用NIO零拷贝后改进的地方：
	1. 已经上下文切换次数从4次减少到2次；
	2. 将数据拷贝从4次减少到了3次(其中只有1次涉及了CPU，另外两次是DMA直接存取)；
如果底层NIC(网络接口卡)支持gather操作，可以进一步减少内核中的数据拷贝。在Linux2.4以及更高版本的内核中，socket缓冲区描述符已被修改用来适应这个需求。这种方式不但减少上下文切换，同时消除了需要CPU参与的重复的数据拷贝。
用户这边的使用方式不变，依旧通过transferTo方法，但是方法的内部实现发生了变化：
	1. transfterTo方法调用触发DMA引擎将文件上下文信息拷贝到内核缓冲区；
	2. 数据不会被拷贝到套接字缓冲区，只有数据的描述符(包括数据位置和长度)被拷贝到套接字缓冲区。DMA引擎直接将数据从内核缓冲区拷贝到协议引擎，这样减少了最后一次需要消耗CPU的拷贝操作。
NIO零拷贝适用于下列场景：
	1. 文件较大，读写较慢，追求速度；
	2. JVM内存不足，不能加载太大数据；
	3. 内存带宽不够，即存在其他程序或线程存在大量的IO操作，导致带宽本来就小。

Linux提供的mmap系统调用，它可以将一段用户空间内存映射到内核空间，当映射成功后，用户对这段内存区域的修改可以直接反映到内核空间；同样地，内核空间对这段区域的修改也直接反映用户空间。正因为有这样的映射关系，就不需要在用户态(user-space)和内核态(kernel-space)之间拷贝数据，提高了数据传输的效率，这就是内存直接映射技术。
使用直接内存的原因：
	1. 对垃圾回收停顿的改善。因为FGC时，垃圾收集器会对所有分配的堆内内存进行扫描，垃圾收集对Java应用造成的影响，跟堆的大小是成正比的。过大的堆会影响Java应用的性能。如果使用堆外内存的话，堆外内存是直接受操作系统管理。这样做的结果就是能保持一个较小的JVM堆内存，以减少垃圾收集对应用的影响(FGC时会触发堆外空闲内存的回收)。
	2. 减少了数据从JVM拷贝到Native堆的次数，在某些场景下可以提升程序IO性能；
	3. 可以突破JVM内存限制，操作更多的物理内存。(当直接内存不足时会触发FGC，排查FGC时候，一定要考虑)。
使用直接内存的问题：
	1. 堆外内存难以控制，如果内存泄漏，那么很难排查(VisualVM可以通过安装插件来监控堆外内存);
	2. 堆外内存只能通过序列化和反序列化来存储，保持对象速度比堆内存慢，不适合存储复杂对象。一般简单的对象或扁平化的比较适合。
	3. 直接内存的访问速度(读写方面)会快于堆内存。在申请内存空间时，堆内存速度高于直接内存。直接内存适合申请次数少，访问频繁的场合。如果内存空间需要频繁申请，则不适合直接内存。

自JDK6之后，Java通过泛型解决了容器类型安全问题。泛型的本质是参数化类型。Java实现泛型完全是作为语法糖实现的，也就是说泛型对于JVM来说是透明的，有泛型和无泛型的代码，经过编译器编译后所生成的二进制代码是完全相同的。这个语法糖的实现被称为擦除。泛型是为了将具体的类型作为参数传递给方法、类、接口。擦除是在代码运行过程中将具体的类型都抹除。

> object encoding <key>
embstr, int, quiklist, SDS, skiplist, dict, intset, ziplist, 
Redis触发扩容的条件：
	1. 服务器目前没有执行bgsave命令或者bgrewriteaop命令，并且负载因子大于等于1；
	2. 服务器正在执行bgsave或者bgrewriteaop命令，并且负载因子大于等于5；
负载因子=哈希表已存在节点数量/哈希表大小；
渐进式rehash: 也就是扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几十个，那么rehash操作可以瞬间完成，但是如果键值对有百万，千万甚至更多，那么要一次性的进行rehash，势必造成Redis一段时间内不能进行其他操作。所以Redis采用渐进式rehash，这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行 增加操作，一定是在新的哈希表上进行的。
压缩列表(ziplist)是Redis为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序性数据结构，一个压缩列表可以包含任意多个节点(entry)，每个节点可以保存一个字节数组或者一个整数值。
压缩列表的原理：压缩列表并不是对数据利用某种算法进行压缩，而是将数据按照一定规则编码在一块连续的内存区域，目的是节省内存。

Exchanger是一种线程间安全交换数据的机制。当线程A调用Exchanger对象的exchange()方法后，会进入阻塞状态，直到线程B也调用了exchange()，然后以线程安全的方式交换数据，之后线程A和B继续运行。
Exchanger类底层的关键技术点：
	1. 使用CAS自旋指令完成数据交换；
	2. 使用LockSupport的park方法使得交换线程进入阻塞状态，LockSupport#unpark唤醒等待线程；
	3. 使用Node对象用于存储交换数据。
public class Exchanger<V> {
	...
	/* Nodes hold partially exchanged data, plus other per-thread bookkeeping.
		Padded via @sun.misc.Contended to reduce memory contention.
	*/
	@sun.misc.Contended 
	static final class Node {
		int index;              // Arena index 
		int bound;              // Last recorded value of Exchange.bound 
		int collides;           // Number of CAS failures at current bound 
		int hash;               // Pseudo-random for spins
		Object item;            // This thread's current item 
		volatile Object match;  // Item provided by releasing thread 
		volatile Thread parked; // Set to this thread when parked, else null
	}
	
	// The corresponding thread local class 
	static final class Participant extends ThreadLocal<Node> {
		public Node initialValue() { return new Node(); }
	}
	...
}
MyBatis: SqlSessionFactoryBean, mapperLocation, SqlSource, DynamicSqlSource, StaticSqlSource, SqlNode, IfSqlNode, ForEachSqlNode, TrimSqlNode, WhereSqlNode, StaticTextSqlNode, MappedStatement, Configuration#mappedStatements, MappedFactoryBean, MapperProxy, SqlSession, 
------------------------------------------------------------------
微服务是怎么划分的，划分粒度怎么确定：
	1. 康威定律；
	2. 领域模型；
	3. 伸缩需求；
	4. 修改相关性；
	5. 部署频率；
	6. 避免分布式事务；
康威定律简单来说就是系统设计(产品结构)等同组织形式，每个设计系统的组织，其产生的设计等同于组织之间的沟通结构。如果单个服务由不同的组织管理，需求无法达成统一，面临着令出多头、需求干扰的风险。
伸缩需求：同一个进程之内的不同业务功能，有时在业务量会出现较大的差异，具体要求的进程数量会有较大差别，这样的模块锁定在同一个进程之内，势必会造成资源的浪费。
修改相关性：如果同一个交付物的不同组件，经常被同步修改，这可能说明，如果发生拆分，这两个模块应该是在一起的。
领域建模：针对业务领域，引入限界上下文(Bounded Context)和上下文映射(Context Map)对业务领域进行合理的分解，识别出核心领域(Core Domain)和子领域(Sub Domain)，并确定领域的边界以及它们之间的关系。根据核心领域和子域划分微服务边界。
对于一个单体应用，拆分过程应该是循序渐进、逐步拆分、有简到繁、由粗到细，是一个渐进过程。例如先将有明显边界的业务拆分为独立服务，无法明确边界的先混在一起，等业务需求逐步清晰后再拆。拆分时先拆分几个相对较粗粒度的服务，根据业务需求情况，逐步将粗粒度的服务中相对稳定，可以沉淀的业务拆分为独立服务。在这个过程中，原有的单体应用也可以承担部分兼容能力，在改造完成前，不对外系统造成过大影响。
微服务的拆分是跟业务需求强相关，如果业务需求变更不多、相对稳定，处理的请求并发不高，单体应用的稳定性和可维护性更好，更加适用。
------------------------------------------------------------------
实践微服务架构中，有遇到什么问题：
	1. 划分的粒度；
	2. 分布式事务；
	3. 底层的不稳定：网络异常/超时，服务的启停；
	4. 部署的复杂性；
	5. 数据的整合聚合；
	6. 日志的聚合，调用链监控的难度；

RocketMQ的消费者：与Name Server集群中的其中一个节点(随机)建立长连接，定期从Name Server拉取topic路由信息，并向提供Topic服务的Master Broker、Slave Broker建立长连接，且定时向Master Broker、Slave Broker发送心跳。Consumer既可以从Master Broker订阅消息，也可以从Slave Broker订阅消息，订阅规则由Broker配置决定。

ElasticSearch搜索的过程：
	1. 搜索被执行成一个两阶段过程，称之为Query Then Fetch;
	2. 在初始查询阶段，查询会广播到索引中每一个分片(主分片或者副本分片)。每个分片在本地执行搜索并构建一个匹配文档的大小为from+size的优先队列；
	PS：在搜索的时候是会查询FileSystem Cache，但是有部分数据还在MemoryBuffer，所以搜索是近实时的。
	3. 每个分片返回各自优先队列中，所有文档的ID和排序值给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。
	4. 接下来就是取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个GET请求。每个分片加载并丰富文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。
	5. 补充：Query The Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准备，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document Frequency，这个评分更准确，但是性能会变差。

排序列表Array/List:使用二分法查找，不平衡
HashMap/TreeMap:性能高，内存消耗大，几乎是原始数据的三倍
SkipList:跳跃表，可快速查找词语，在Lucene,Redis,HBase等均有实现。相对于TreeMap等结构，特别适合高并发场景。
Trie:适合英文词典，如果系统中存在大量字符串且这些字符串基本没有公共前缀，则相应的trie树将非常消耗内存。
Double Array Trie:适合做中文词典，内存占用小，很多分词工具均采用此算法。
Ternary Search Tree:三叉树，每个node有三个节点，兼具空间和查询快的优点。
Finite State Transduceers(FST)：一种有限状态转移机，Lucene4有开源实现，并大量使用。

MySQL中的锁可以分为两个粒度：表锁和行锁，表锁有：表级读锁，表级写锁，读意向锁，写意向锁，自增锁；行锁有：读记录锁，写记录锁，间隙锁，Next-Key锁，插入意向锁。绝大多数的死锁问题都是由这些锁之间的冲突导致的。不同的隔离级别加锁也不一样，比如RR隔离级别下有间隙锁和Next-Key锁，在RC隔离级别下是没有的。
行锁都是加在索引上的，最终都会落在聚簇索引上。
加行锁的过程是一条一条记录加的。
select ...语句正常情况下为快照读，不加锁；但是在Serializable隔离级别下为当前读，加S锁。
RC 隔离级别下没有间隙锁和Next-key锁(特殊情况下也会有:purge+unique key)；
-------------------------------------------------
为什么RocketMQ没有选择ZooKeeper，而是自己实现了一个NameServer集群：
ZK可以提供Master选举功能，比如Kafka用来给每个分区选一个broker作为leader，但对于RocketMQ来说，topic的数据在每个Master上是对等的，没有哪个Master上有topic上的全部数据，所以这里选举leader没有意义；RocketMQ集群中，需要有构件来处理一些通用数据，比如broker列表，broker刷新时间，虽然ZK也能存放数据，并有一致性保证，但处理数据之间的一些逻辑关系却比较麻烦，而且数据的逻辑解析操作得交给Zookeeper客户端来做，如果有多种角色的客户端存在，自己解析多级数据确实是个麻烦事；既然RocketMQ集群中没有用到Zookeeper的一些重量级功能，只是使用Zookeeper的数据一致性和发布订阅的话，与其依赖重量级的Zookeeper,还不如写个轻量级的NameServer，NameServer也可以集群部署，NameServer之间无任何信息同步，只有一千多行的NameServer稳定性肯定高于Zookeeper，占用的系统资源也比较少。
RocketMQ的架构设计决定了只需要一个轻量级的元数据服务器就足够了，只需要保持最终一致，而不需要Zookeeper这样的强一致性解决方案，不需要再依赖另一个中间件，从而减少整体维护成本。
敏锐的同学肯定已经意识到了，根据CAP理论，RocketMQ在名称服务这个模块的设计上选择了AP，而不是CP：
-------------------------------------------------
命中二级唯一索引，在给二级索引加锁的时候，主键索引也会一并加锁。
二级唯一索引，查询未命中，RR隔离级别下会加GAP锁，RC隔离级别不加锁。这种情况下只会在二级索引加锁，不会在聚簇索引上加锁。
为什么非唯一索引会加GAP锁，而唯一索引不用加GAP锁？GAP锁的作用是为了解决幻读，防止其他事务插入相同索引值的记录，而唯一索引和主键约束都已经保证了该索引值肯定只有一条记录，所以无需加GAP锁。
其实，在InnoDB存储引擎中，每个数据页中都会有两个虚拟的行记录，用来限定记录的边界，分别是:Infimum Record和Supremum Record，Infimum是比该页中任务记录都要小的值，而Supremum比该页中最大的记录值还要大，这两条记录在创建页的时候就有了，并且不会删除。

如果where条件不走索引，在没有索引的时候，只能走聚簇索引，对表中的记录进行全表扫描。在RC隔离级别下会给所有记录加行锁，在RR隔离级别下，不仅会给所有记录加锁，所有聚簇索引和聚簇索引之间还会加锁GAP锁。
不过在实际的实现中，MySQL有一些改进，如果是RC隔离级别，在MySQL Server过滤条件不满足后，会调用unlock_row方法，把不满足条件的记录锁释放掉(违背了2PL的约束)。这样做可以保证只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略。在RR隔离级别下，一般情况下MySQL是不能这样优化的，除非设置了innodb_locks_unsafe_for_binlog参数，这时也会提前释放锁，并且不加GAP锁，这就是所谓的semi-consistent read。

semi-consistent read是read committed与consistent read两者的结合。一个update语句，如果读到一行已经加锁的记录，此时InnoDB返回记录最近提交的版本，由MySQL上层判断此版本是否满足update的where条件。若满足(需要更新)，则MySQL会重新发起一次读操作，此时会读取行的最新版本(并加锁)。
semi-consistent read只会发生在read committed隔离级别下，或者是参数innodb_locks_unsafe_for_binlog被设置为true。

活锁：死锁是互相拿不到资源都占用对方的资源，而活锁是拿到资源却又互相释放不执行。
解决活锁的一个简单办法是：在下一次尝试获取资源之前，随机休眠一小段时间。
解决活锁的方法二：约定优先级；
解决活锁的方法三：比如月ing重试机制避免再次冲突。例如自动驾驶的防碰撞系统，可以根据序列号检测到相撞风险时，序列号小的朝上飞，序列号大的飞机朝下飞。

饥饿：一个线程因为CPU时间全部被其他线程抢占而得不到CPU运行时间，导致线程无法执行。
产生饥饿的原因：
	1. 高优先级线程抢占低优先级线程的CPU；
	2. 其他线程总是能持续地获得同步块的访问，线程被永久阻塞在一个等待进入同步块中；
	3. 其他线程总是被抢先被唤醒，线程一直在等待被唤醒;

丢失更新/提交覆盖(Read-Modify-Write问题)/回滚覆盖
回滚覆盖称之为第一类丢失更新问题，提交覆盖称为第二类丢失更新问题。

回滚覆盖/脏读/不可重复读/提交覆盖/幻读
譬如在 SQL 标准中，RR 隔离级别解决了不可重复读问题，但是依然存在幻读现象；而在 MySQL 的 RR 隔离级别下，通过多版本快照读和间隙锁技术解决了幻读问题。

活锁指的是任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试—失败—尝试—失败的过程。处于活锁的实体是在不断的改变状态，活锁有可能自行解开。

Redis快的原因：
	1. 完全基于内存，绝大部分请求是存粹内存操作，非常快速。
	2. 数据结构简单，对数据操作也简单，Redis中的数据结构是专门设计过的。
	3. 采用单线程，避免了不必要的上下文切换和锁竞争，也不存在多进程或多线程导致的切换消耗CPU，不用考虑各种锁，不存在加锁释放锁操作，不会因为死锁导致性能消耗。
	4. 使用多路IO复用，非阻塞IO；
	5. 使用底层模型不同，它们之间底层实现方法以及与客户端之间通信的应用协议不一样，Redis直接构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去拷贝和请求。

Undo log保存了记录修改前的镜像。在InnoDB存储引擎中，undo log分为：
	- insert undo log
	- update undo log
insert undo log是指在insert操作中产生的undo log。由于insert操作的记录，只是对本事务可见，其他事务不可见，所以undo log可以在事务提交后直接删除，而不需要purge操作。
update undo log是指在delete和update操作中产生的undo log。该undo log会被后续用于MVCC当中，因此不能提交的时候删除。提交后会放入undo log的链表，等待purge线程进行最后的删除。

除此之外，Redis4.0之后的版本抛弃了单线程模型这一设计，原本用单线程运行的Redis也开始选择性使用多线程模型。在Redis4.0之后的版本，情况有些改变，新版Redis在执行一些命令时就会使用主线程之外的其他线程，例如unlink, flushall async, flushdb async等非阻塞的删除操作。

Redis 选择使用单线程模型处理客户端的请求主要还是因为 CPU 不是 Redis 服务器的瓶颈，所以使用多线程模型带来的性能提升并不能抵消它带来的开发成本和维护成本，系统的性能瓶颈也主要在网络 I/O 操作上；而 Redis 引入多线程操作也是出于性能上的考虑，对于一些大键值对的删除操作，通过多线程非阻塞地释放内存空间也能减少对 Redis 主线程阻塞的时间，提高执行的效率。

InnoDB采用WAL技术，即InnoDB Redo Log记录了对数据文件的物理更改，并保证总是日志先行，在持久化数据文件之前，保证之前的redo日志已经写到磁盘。

四种隔离级别的加锁策略如下：
	1. RU:事务读不阻塞其他事务读和写，事务写阻塞其他事务写但不阻塞读；通过对写操作加"持续X锁"，对读操作不加锁实现。
	2. RC:事务读不会阻塞其他事务读和写，事务写会阻塞其他事务读和写；通过对写操作加"持续X锁"，对读操作加"临时S锁"实现，不会出现脏读；
	3. RR:事务读会阻塞其他事务写但不阻塞读，事务写会阻塞其他事务读和写；通过对写操作加"持续X锁"，对读操作加"持续S锁"实现；
	4. Serializable: 为了解决幻读，行级锁做不到，需使用表级锁。

通过对锁的类型(读锁还是写锁)、锁的粒度(行锁还是表锁)、持有锁的时间(临时锁还是持续锁)合理的进行组合，就可以实现四种不同的隔离级别。这四种不同的加锁策略实际上又称为封锁协议(Locking Protocol)，所谓协议，就是说不论加锁还是释放锁都得按照特定的规则来。读未提交的加锁策略又称为一级封锁协议，后面的分别是二级、三级，序列化的加锁策略又称为四级封锁协议。
其中三级封锁协议在事务的过程中为写操作加持续X锁，为读操作加持续S锁，并且在事务结束时才对锁进行释放，像这种加锁和解锁明确的分成两阶段称为两段锁协议(2-phase locking，简称2PC)。在两段锁协议中规定，加锁阶段只允许加锁，不允许解锁；而解锁阶段只允许解锁，不允许加锁。这种方式虽然无法避免死锁，但是两段锁协议可以保证事务的并发调度是串行化的。在两段锁协议中，还有一种特殊的形式，叫一次封锁，意思是指在事务开始的时候，将事务可能遇到的数据全部一次锁住，再在事务结束时全部一次释放，这种方式可以有效的避免死锁发生。但是这在数据库系统中并不适用，因为事务在开始时并不知道这个事务要用到哪些数据，一般在应用程序中使用的比较多。

MVCC 的全称叫做 Multi-Version Concurrent Control（多版本并发控制），InnoDb 会为每一行记录增加几个隐含的“辅助字段”，（实际上是 3 个字段：一个隐式的 ID 字段，一个事务 ID，还有一个回滚指针），事务在写一条记录时会将其拷贝一份生成这条记录的一个原始拷贝，写操作同样还是会对原记录加锁，但是读操作会读取未加锁的新记录，这就保证了读写并行。要注意的是，生成的新版本其实就是 undo log，它也是实现事务回滚的关键技术。

尽管RR和RC隔离级别都实现了MVCC来满足读写并行，但是读的实现方式是不一样的：RC 总是读取记录的最新版本，如果该记录被锁住，则读取该记录最新的一次快照，而RR 是读取该记录事务开始时的那个版本。虽然这两种读取方式不一样，但是它们读取的都是快照数据，并不会被写操作阻塞，所以这种读操作称为 快照读（Snapshot Read），有时候也叫做 非阻塞读（Nonlocking Read），RR隔离级别下的叫做一致性非阻塞读（Consistent Nonlocking Read）。

除了 快照读 ，MySQL还提供了另一种读取方式：当前读（Current Read），有时候又叫做 加锁读（Locking Read） 或者 阻塞读（Blocking Read），这种读操作读的不再是数据的快照版本，而是数据的最新版本，并会对数据加锁，根据加锁的不同，又分成两类：
SELECT ... LOCK IN SHARE MODE：加 S 锁
SELECT ... FOR UPDATE：加 X 锁
INSERT/UPDATE/DELETE：加 X 锁
当前读在RR和RC两种隔离级别下的实现也是不一样的：RC只加记录锁，RR除了加记录锁，还会加间隙锁，用于解决幻读问题。
-----------------------------------------------------
innodb_flush_method:控制innodb数据文件，日志文件的打开和刷写的方式，建议取值:fsync, O_DIRECT。
innodb_flush_lot_at_trx_commit:控制每次事务提交时，重做日志的写盘和落盘策略，可取值:0,1,2
当innodb_flush_log_at_trx_commit=1时，每次事务提交，日志写到InnoDB Log Buffer后，会等待Log Buffer中的日志写到InnoDB日志文件并刷新到磁盘上才返回成功。
sync_binlog:控制每次事务提交时，Binlog日志多久刷新到磁盘上，可取值：0或者n(n为正整数)
不同取值会影响MySQL的性能和异常crash后数据能恢复的程度。
当sync_binlog=1时，MySQL每次事务提交都会将binlog_cache中的数据强制写入磁盘。
innodb_doublewrite:控制是否打开double writer功能，取值on或者off。
当Innodb的page size默认16k，磁盘单次写的page大小通常为4k或者远小于InnoDB的page大小时，发生了系统断电/OS crash，刚好只有一部分写是成功的，则会遇到partial page write问题，从而可能导致crash后由于部分写失败的page影响数据的恢复。
InnoDB为此提供了Double Writer技术来避免页断裂(partial write)的发生。
innodb_support_xa：控制是否开启InnoDB的两阶段事务提交，默认情况下，innodb_support_xa=true，支持xa两阶段事务提交。
-----------------------------------------------------
MyIsam和InnoDB的索引不同：
	1. 存储结构
		InnoDB的数据文件本身就是主索引文件，而MyISAM的主索引和数据是分开的
		InnoDB的二级索引data域存储相应记录主键的值而不是地址。而MyISAM的辅助索引和主索引没有多大区别。
		InnoDB是聚簇索引，数据挂在主键索引之下。
	2. 锁：MyISAM使用的是表锁，InnoDB使用行锁
	3. 事务：MyISAM没有事务和MVCC，InnoDB支持事务和MVCC
	4. 全文索引:MyISAM支持fulltext类型的全文索引；InnoDB不支持fulltext类型的全文索引，但是InnoDB可以使用Sphinx插件支持全文索引，并且效果更好。
	5. 主键 
		MyISAM允许没有任何索引和主键的表存在，索引都是保存行的地址。
		InnoDB如果没有设定主键或非空唯一索引，就会自动生成一个6字节的主键。
	6. 外键：MyISAM不支持外键，InnoDB支持外键。