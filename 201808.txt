Spring Cloud Kubernetes provide Spring Cloud common interface implementations that consume Kubernetes native services. The main objective of the projects provided in this repository is to facilitate the integration of Spring Cloud and Spring Boot applications running inside Kubernetes.
Spring Cloud Kubernetes Features:
	- Kubernetes awareness.
	- DicoveryClient implementation.
	- PropertySource objects configured via ConfigMaps.
	- Client side loadbalancing via Netflix Ribbon.

ConfigMapPropertySource, SecretsPropertySource

YGC的时机：
	- Eden空间不足时
FGC的时机
	- Old空间不足时
	- Perm空间不足时
	- 显示调用System.gc()，包括RMI等的定时触发
	- YGC时的悲观策略
	- dump live内存信息时(jmap - dump:live)
	- 通过设置JVM参数，定时执行FGC

YGC的悲观策略: 它触发的机制是首先会计算之前晋升的平均大小，也就是从新生代通过YGC变成老年代的平均大小，然后若干老年代剩余的空间小于晋升大小，那么就会触发一次FullGC。JVM考虑的策略是，从平均和长远的情况来看，下次晋升空间不够的可能性非常大，与其等到那个时候FGC，不然悲观的认为下次肯定会触发FGC，直接先执行一次FGC。而且从实际使用过程来看，也达到了比较稳定的效果。
---------------------------------------------
JMS Transaction management:
	Spring provides a JmsTransactionManager that manages transactions for a single JMS ConnectionFactory . This allows JMS applications to leverage the managed transaction features of Spring as described in Chapter 17, Transaction Management. The JmsTransactionManager performs local resource transactions, binding a JMS Connection/Session pair from the specified ConnectionFactory to the thread. JmsTemplate automatically detects such transactional resources and operates on them accordingly.
	In a Java EE environment, the ConnectionFactory will pool Connections and Sessions, so those resources are efficiently reused across transactions. In a standalone environment, using Spring’s SingleConnectionFactory will result in a shared JMS Connection , with each transaction having its own independent Session . Alternatively, consider the use of a provider-specific pooling adapter such as ActiveMQ’s PooledConnectionFactory class.
	JmsTemplate can also be used with the JtaTransactionManager and an XA-capable JMS ConnectionFactory for performing distributed transactions. Note that this requires the use of a JTA transaction manager as well as a properly XA-configured ConnectionFactory! (Check your Java EE server’s / JMS provider’s documentation.)
	Reusing code across a managed and unmanaged transactional environment can be confusing when using the JMS API to create a Session from a Connection . This is because the JMS API has only one factory method to create a Session and it requires values for the transaction and acknowledgement modes. In a managed environment, setting these values is the responsibility of the environment’s transactional infrastructure, so these values are ignored by the vendor’s wrapper to the JMS Connection. When using the JmsTemplate in an unmanaged environment you can specify these values through the use of the properties sessionTransacted and sessionAcknowledgeMode. When using a PlatformTransactionManager with JmsTemplate , the template will always be given a transactional JMS Session.
---------------------------------------------
当并发访问或更新数据库时，有可能出现脏读(Dirty Read)、不可重复读(Unrepeatable Read)、幻读(Phantom Read)、更新丢失(Lost update)等数据不一致情况，为了解决这些问题，MySQL引入了多种锁的概念。

MySQL InnoDB对数据行的锁定类型一共有四种：共享锁(读锁，S锁), 排他锁(写锁，X锁), 意向共享锁(IS锁)和意向排它锁(IX锁)。
MySQL支持三种锁定方式：
	- 行锁:Record Lock, 锁直接加在索引记录上面；
	- 间隙锁:Gap Lock, 锁加在不存在的空闲空间上，可以是两个索引记录之间，也可能是第一个索引记录之前或最后一个索引之后的空间。
	- Next-Key Lock: 行锁与间隙锁组合起来用就叫做Next-Key Lock。
默认情况下，InnoDB工作在可重复读隔离级别下(Reaptable-Read)，并且以Next-Key Lock的方式对数据进行加锁，这样可以有效防止幻读的发生。Next-Key Lock是行锁和间隙锁的组合，当InnoDB扫描索引记录的时候，会首先对选中的索引记录加上行锁(Record Lock)，再对索引记录两边的间隙加上间隙锁(Gap Lock)。当一个间隙被事务Transaction加了锁，其他事务是不能在这个间隙插入记录的。
MySQL锁的实现：
	- 在可重复读级别下，InnoDB以Next-Key Lock的方式对索引加锁；在读已提交级别下，InnoDB以Index-Record Lock的方式对索引加锁；
	- 被加锁的索引如果不是聚簇索引，那被加锁的索引所指向的聚簇索引以及其他指向相同聚簇索引的索引也会被加锁。
	- select * from ... lock in share mode对索引加共享锁；select * from ... for update对索引加排他锁。
	- select * from ... 是非阻塞读，不会对索引加锁(除了Serializable级别)。在读已提交级别下，总是查询记录的最新、有效的版本；在可重复读级别下，会记住第一次查询时的版本，之后的查询会基于该版本。例外的情况是在串行化隔离级别下，这时会以Next-Key Lock的方式对索引加共享锁。
	- update ... where 和 delete ... where对索引加排他锁。
	- insert into ...以Index-Record Lock的方式对索引加排它锁。

使用select ... for update会把数据给锁住，不过需要注意一些锁的级别，MySQL InnoDB默认Row-Level Lock，所以只有明确地指定主键/索引，MySQL才会执行Row Lock(只锁住所选取的数据)，否则MySQL将会执行Table Lock(将整个表给锁住)。
悲观锁的优点：
	- 悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。
	- 悲观锁基于DB层面实现，对业务代码无入侵，使用方便
悲观锁的缺点：
	- 悲观锁适用于可靠的持续性连接，诸如C/S应用。 对于Web应用的HTTP连接，先天不适用
	- 锁的使用意味着性能的损耗，在高并发、锁定持续时间长的情况下，尤其严重。Web应用的性能瓶颈多在数据库处，使用悲观锁，进一步收紧了瓶颈
	- 非正常中止情况下的解锁机制，设计和实现起来很麻烦，成本还很高
	- 不够严谨的设计下，可能产生莫名其妙的，不易被发现的死锁问题
	- 悲观的缺陷是不论是页锁还是行锁，加锁的时间可能会很长，这样可能会长时间的限制其他用户的访问，也就是说悲观锁的并发访问性不好

线程池如何调优，最大数目如何确认:对于线程池大小的设定，需要考虑以下问题：
	- CPU个数
	- 内存大小
	- 任务类型，是计算密集型(CPU密集型)还是IO密集型
	- 是否需要一些稀缺资源，像数据库连接这种
	- 其他情况
有个简单的估算方式，设N为CPU个数
	- 对于CPU密集型的应用，线程池的大小设置为N + 1；
	- 对于IO密集型的应用，线程池的大小设置为2N + 1；
这种设置方式适合于单台机器上的应用的类型是单一的，并且只有一个线程池，实际情况还需要根据实际情况进行验证。
在IO优化中，下面的估算公式会更合理：
最佳线程数量 = ((线程等待时间 + 线程CPU时间) / 线程CPU时间) * CPU个数

基于MQ的最终一致性分布式事务如何保证高可用性：
	1. 生产者：落库(状态为待发送) + 发送MQ，发送成功更改状态为发送完成。如果发送失败，回滚数据库。如果更改状态失败，后续通过异步轮询线程查询状态为待发送的记录，重新发送，消费者需要保证幂等性；
	2. MQ:保证高可用、高并发
	3. 消费者：保证消费的幂等性；消费不成功时，不要提交offset。
	4. 对MQ的消息堆积进行监控，查看是否有没消费的消息；同时设置死信队列，排查最终没有消费的消息，排查后将消息重新投递到原队列。
	5. MQ不可用后的降级方案：1. 封装MQ客户端，直接改为同步调用；2. 封装MQ客户端，使用Redis作为MQ的替代；3. 其他类似MQ的替代品。考虑点：如果切换降级方案，比如某单位时间内失败N次后，生产者通过Zookeeper设置降级标记。消费者通过监听这个Zookeeper的标记，恰当的时机进行切换(比如尽量把之前的消息消费完毕)。同时在熔断后，在某个时间内，尝试一次发往MQ，如果成功，关闭降级开关。否则继续降级。这个可以参考Hystrix的做法。

Spring Cloud Alibaba Sentinel 1.6.0引入了Sentinel API Gateway Adapter Common模块，此模块中包含网关限流的规则和自定义API的实体和管理逻辑：
	- GatewayFlowRule: 网关限流规则，针对API Gateway的场景定制的限流规则，可以针对不同route或自定义的API分组进行限流，支持对请求中的参数、Header、来源IP等进行定制化的限流。
	- ApiDefinition: 用户自定义的API分组，可以看作是一些URL匹配的组合。比如可以定义一个API叫my_api，请求path模式为/foo/**和/baz/**的都归属到my_api这个API分组下面。限流的时候可以针对这个分组维度进行限流。

spring.main.allow-bean-definition-overriding=true
jcmd可以查看当前所有java进程，比jps详细一点。
jhat是jdk内置的工具之一，主要用来分析java堆，可以将堆中的对象以html的形式显示出来，包括对象的数量、大小等，并支持对象查询语言(Object Query Language)。可以使用如下步骤：
第一步:导出堆，#jmap -dump:live,file=xxx.dump <pid>
	除了使用jmap还可以通过下面方式获取堆转储文件
		- 使用jconsole，通过HotSpotDiagnosticMXBean从运行时获得堆转储(生成dump文件)
		- JVM启动时如果指定了-XX:+HeapDumpOnOutOfMemoryError，则在抛出OutOfMemoreyError时，自动进行堆转储
		- hprof
第二步：分析堆文件；jhat -J-Xmx512m xxx.dump ， 如文件很大，可以增大mx参数

对于jhat启动后显示的html页面中提供的功能如下：
	1. All classes (excluding platform)
	2. All classed (including platform)
	3. Show all members of rootset
		- Java Static References
		- Java Local References 
		- Busy Monitor References 
		- JNI Global References 
		- System Class References 
	4. Show instance counts for all classes(including platform)
	5. Show instance counts for all classes(excluding platform)
	6. Show heap histogram
	7. Show finalizer summary
	8. Execute Object Query Language (OQL) query

public interface Spliterator<T> {
	boolean tryAdvance(Consumer<? super T> action);
	default void forEachRemaining(Consumer<? super T> action) {
		do {} while (tryAdvance(action));
	}
	Spliterator<T> trySplit();
	long estimateSize();
	default long getExactSizeIfKnown() {
		return (characteristics() & SIZED) == 0 ? -1L : estimateSize();
	}
	int characteristics();
	default boolean hasCharacteristics(int characteristics) {
		return (characteristics() & characteristics) == characteristics;
	}
	default Comparator<? super T> getComparator() {
		throw new IllegalStateException();
	}
	public static final int ORDERED    = 0x00000010;
	public static final int DISTINCT   = 0x00000001;
	public static final int SORTED     = 0x00000004;
	public static final int SIZED      = 0x00000040;
	public static final int NONNULL    = 0x00000100;
	public static final int IMMUTABLE  = 0x00000400;
	public static final int CONCURRENT = 0x00001000;
	public static final int SUBSIZED   = 0x00004000;
	
	public interface OfPrimitive<T, T_CONS, T_SPLITR extends Spliterator.OfPrimitive<T, T_CONS, T_SPLITR>>
			extends Spliterator<T> {
		@Override
		T_SPLITR trySplit();
		@SuppressWarnings("overloads")
		boolean tryAdvance(T_CONS action);
		@SuppressWarnings("overloads")
		default void forEachRemaining(T_CONS action) {
			do {} while (tryAdvance(action));
		}
	}
	
	public interface OfInt extends OfPrimitive<Integer, IntConsumer, OfInt> {
		@Override
		OfInt trySplit();
		@Override
		boolean tryAdvance(IntConsumer action);
		@Override
		default void forEachRemaining(IntConsumer action) {
			do {} while (tryAdvance(action));
		}
		@Override
		default boolean tryAdvance(Consumer<? super Integer> action) {
			if (action instanceof IntConsumer) {
				return tryAdvance((IntConsumer)action);
			} else {
				if (Tripwire.ENABLED)
					Tripwire.trip(getClass(), 
						"{0} calling Spliterator.OfInt.tryAdvance((IntConsumer) action::accept)");
				return tryAdvance((IntConsumer) action::accept);
			}
		}
		
		@Override
		default void forEachRemaining(Consumer<? super Integer> action) {
			if (action instanceof IntConsumer) {
				forEachRemaining((IntConsumer)action);
			} else {
				if (Tripwire.ENABLED)
					Tripwire.trip(getClass(),
						"{0} calling Spliterator.OfInt.forEachRemaining((IntConsumer) action::accept)");
				forEachRemaining((IntConsumer)action::accept);
			}
		}
	}
	
	public interface OfLong extends OfPrimitive<Long, LongConsumer, OfLong> {
        @Override
        OfLong trySplit();
        @Override
        boolean tryAdvance(LongConsumer action);
        @Override
        default void forEachRemaining(LongConsumer action) {
            do { } while (tryAdvance(action));
        }
        @Override
        default boolean tryAdvance(Consumer<? super Long> action) {
            if (action instanceof LongConsumer) {
                return tryAdvance((LongConsumer) action);
            }
            else {
                if (Tripwire.ENABLED)
                    Tripwire.trip(getClass(),
                                  "{0} calling Spliterator.OfLong.tryAdvance((LongConsumer) action::accept)");
                return tryAdvance((LongConsumer) action::accept);
            }
        }
        @Override
        default void forEachRemaining(Consumer<? super Long> action) {
            if (action instanceof LongConsumer) {
                forEachRemaining((LongConsumer) action);
            }
            else {
                if (Tripwire.ENABLED)
                    Tripwire.trip(getClass(),
                                  "{0} calling Spliterator.OfLong.forEachRemaining((LongConsumer) action::accept)");
                forEachRemaining((LongConsumer) action::accept);
            }
        }
    }

    /**
     * A Spliterator specialized for {@code double} values.
     * @since 1.8
     */
    public interface OfDouble extends OfPrimitive<Double, DoubleConsumer, OfDouble> {
        @Override
        OfDouble trySplit();
        @Override
        boolean tryAdvance(DoubleConsumer action);
        @Override
        default void forEachRemaining(DoubleConsumer action) {
            do { } while (tryAdvance(action));
        }
        /**
         * {@inheritDoc}
         * @implSpec
         * If the action is an instance of {@code DoubleConsumer} then it is
         * cast to {@code DoubleConsumer} and passed to
         * {@link #tryAdvance(java.util.function.DoubleConsumer)}; otherwise
         * the action is adapted to an instance of {@code DoubleConsumer}, by
         * boxing the argument of {@code DoubleConsumer}, and then passed to
         * {@link #tryAdvance(java.util.function.DoubleConsumer)}.
         */
        @Override
        default boolean tryAdvance(Consumer<? super Double> action) {
            if (action instanceof DoubleConsumer) {
                return tryAdvance((DoubleConsumer) action);
            }
            else {
                if (Tripwire.ENABLED)
                    Tripwire.trip(getClass(),
                                  "{0} calling Spliterator.OfDouble.tryAdvance((DoubleConsumer) action::accept)");
                return tryAdvance((DoubleConsumer) action::accept);
            }
        }

        /**
         * {@inheritDoc}
         * @implSpec
         * If the action is an instance of {@code DoubleConsumer} then it is
         * cast to {@code DoubleConsumer} and passed to
         * {@link #forEachRemaining(java.util.function.DoubleConsumer)};
         * otherwise the action is adapted to an instance of
         * {@code DoubleConsumer}, by boxing the argument of
         * {@code DoubleConsumer}, and then passed to
         * {@link #forEachRemaining(java.util.function.DoubleConsumer)}.
         */
        @Override
        default void forEachRemaining(Consumer<? super Double> action) {
            if (action instanceof DoubleConsumer) {
                forEachRemaining((DoubleConsumer) action);
            }
            else {
                if (Tripwire.ENABLED)
                    Tripwire.trip(getClass(),
                                  "{0} calling Spliterator.OfDouble.forEachRemaining((DoubleConsumer) action::accept)");
                forEachRemaining((DoubleConsumer) action::accept);
            }
        }
    }
}

当对表设计、SQL优化、索引优化、读写分离、缓存后，数据库的压力还是很大，这时就需要进行数据库拆分了。数据库拆分就是指通过某种特定的条件，按照某个维度，将存放在同一个数据库中的数据分散存放到多个数据库(主机)上，以达到分散单库(单机)负载的效果。分为：垂直拆分和水平拆分两种模式。

垂直拆分：专库专用，一个数据库由很多表构成，每个表对应着不同的业务，垂直拆分是指按照业务将表进行分类，分布到不同的数据库上，这样也就将数据或者说压力分担到不同的库。
	优点：
		1. 拆分后业务清晰，拆分规则明确。
		2. 系统之间整合或扩展容易。
		3. 数据维护简单。
	缺点：
		1. 部分业务表无法join,只能通过接口方式解决，提高了系统复杂度。
		2. 受热点业务的限制存在单库性能瓶颈，不容易数据扩展和性能提高。
		3. 事务处理复杂。

水平拆分：垂直拆分后遇到单库瓶颈，可以使用水平拆分。相对于垂直拆分的区别是：垂直拆分是把不同的表拆到不同的数据库里，而水平拆分是把同一个表拆分到不同的库。相对于垂直拆分，水平拆分不是将表的数据做分类，而是按照某个字段的某种规则来分散到多个库中，每个表中包含一部分数据。简单来说，水平拆分是按照数据行的切分，就是将表中的某些行切分到一个库，而另外的某些行切分到其他的库，主要有分库、分表两种模式。
	优点：
		1. 不存在单表大数据，高并发的性能瓶颈。
		2. 对应用透明，应用端改造较少。
		3. 按照合理拆分规则拆分，join操作基本避免跨库。
		4. 提高了系统的稳定性和负载能力。
	缺点：
		1. 拆分规则难以抽象。
		2. 事务一致性难以解决。
		3. 数据多次扩展难度大，维护量大。
		4. 跨库join性能差。
水平拆分和垂直拆分的共同缺点：
	1. 引入了分布式事务的问题。
	2. 跨节点join的问题。
	3. 跨节点合并、排序、分页问题。
拆分原则：
	1. 尽量不拆分，架构是进化而来，不是一蹴而就。(SOA)
	2. 最大可能找到最佳的拆分维度。
	3. 由于数据库中间件对数据join实现的优劣难以把握，而且难度较高，业务读取尽量少用join,尽量通过数据冗余、分组避免数据跨库多表join。
	4. 尽量避免分布式事务。
	5. 单表拆分到数据几百万以内。

JDK8中的HashMap是先插入后扩容，原因如下：
在final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict)函数中有代码片段：
if (e != null) {   // existing mapping for key
	V oldValue = e.value;
	if (!onlyIfAbsent || oldValue == null)
		e.value = value;
	afterNodeAccess(e);
	return oldValue;
}
源码很清楚的表达了扩容原因：调用put不一定是新增数据，还可能覆盖原来的数据，这里就存在一个key的比较问题。以先扩容为例，需要先判断是否是新增的数据，再判断新增数据后是否扩容，这样判断会比较浪费时间。而后扩容，判断不是新增数据，直接返回即可，不执行扩容，这样可以提高效率。

Kafka的缺点以及如何优化：
	1. 不支持事务。不支持JMS
	2. 只支持同一Partition内的消息有序，不支持消息全局有序。
	3. 不支持Exactly Once语义。只支持At least once。
	4. 复杂性。需要ZK支持管理元数据。
	5. 由于是批量发送，数据并非真正实时。
	6. 不支持延迟功能。
	7. 监控不完善，需要安装插件。
	8. 不支持MQTT协议
	
2PC的优缺点：
	- 优点：原理简单，实现方便
	- 缺点：同步阻塞、单点问题、脑裂(主从数据不一致)、保守(协调者超时机制判断是否要中断)
3PC(事务询问-CanCommit, 执行事务预提交-PreCommit, 执行提交-DoCommit, 回滚-Rollback)的优缺点：
	- 优点：降低了参与者的阻塞范围，能够在单点故障后继续达成一致
	- 缺点：在参与者接收到预提交消息后，如果网络出现分区，此时协调者所在节点和参与者无法进行网络通信，在这种情况下，该参与者依然会进行事务提交，这必然出现数据的不一致性。

Is Zab just a special implementation of Paxos?
No, Zab is a different protocol than Paxos, although it shares with it some key aspects, as for example:
	- A leader proposes values to the followers
	- Leaders wait for acknowledgements from a quorum of followers before considering a proposal committed(learned)
	- Proposals include epoch numbers, which are similar to ballot numbers in Paxos
The main conceptual difference between Zab and Paxos is that it is primarily designed for primary-backup systems, like Zookeeper, rather than for state machine replication.

What is the difference between primary-backup and state machine replication?
	A state machine is a software component that processes a sequence of requests. For every processed request, it can modify its internal state and produce a reply. A state machine is deterministic in the sense that, given two runs where it receives the same sequence of requests, it always makes the same internal state transitions and produces the same replies.
	A state machine replication system is a client-sever system ensuring that each state machine replica executes the same sequence of client requests, even if these requests are submitted concurrently by clients and received in different orders by the replicas. Replicas agree on the execution order of client requests using a consensus algorithm like Paxos. Client requests that are sent concurrently and overlap in time can be executed in any order. If a leader fails, a new leader that executes recovery is free to arbitrarily reorder any uncommitted request since it is not yet completed.
	In the case of primary-backup systems, such as Zookeeper, replicas agree on the application order of incremental (delta) state updates, which are generated by a primary replica and sent to its followers. Unlike client requests, state updates must be applied in the exact original generation order of the primary, starting from the original initial state of the primary. If a primary fails, a new primary that executes recovery cannot arbitrarily reorder uncommitted state updates, or apply them starting from a different initial state.
	In conclusion, agreement on state updates (for primary-backup systems) requires stricter ordering guarantees than agreement on client requests (for state machine replication systems).

What are the implications for agreement algorithms?
	Paxos can be used for primary-backup replication by letting the primary be the leader. The problem with Paxos is that, if a primary concurrently proposes multiple state updates and fails, the new primary may apply uncommitted updates in an incorrect order. An example is presented in our DSN 2011 paper (Figure 1). In the example, a replica should only apply the state update B after applying A. The example shows that, using Paxos, a new primary and its follows may apply B after C, reaching an incorrect state that has not been reached by any of the previous primaries.
	A workaround to this problem using Paxos is to sequentially agree on state updates: a primary proposes a state update only after it commits all previous state updates. Since there is at most one uncommitted update at a time, a new primary cannot incorrectly reorder updates. This approach, however, results in poor performance.
	Zab does not need this workaround. Zab replicas can concurrently agree on the order of multiple state updates without harming correctness. This is achieved by adding one more synchronization phase during recovery compared to Paxos, and by using a different numbering of instances based on zxids.

ZK的应用：
	1. 命名服务
	2. 负载均衡
	3. 分布式锁(排他锁和共享锁)
	4. 配置管理
	5. Leader选举
	6. 分布式队列
	7. 服务注册/发现
	
ZK的设计目的：
1. 最终一致性：client无论连接到哪个server，展示的都是同一个视图，这是ZK最重要的性能；
2. 可靠性：具有简单、健壮、良好的性能，如果消息被接受，那么它将被所有的server接受；
3. 实时性：ZK保证客户端将在一个时间间隔内获得服务器的更新信息，或者服务器失效的信息。但由于网络延迟原因，ZK不能保证两个客户端能同时得到刚刚更新的数据，如果需要最新数据，应该在读数据前调用sync()接口。
4. 等待无关(wait-free)：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。
5. 原子性：更新只能成功或失败，没有中间状态。
6. 顺序性：包括全局有序和偏序两种。全局有序是指如果在一台服务器上消息A在消息B之前发布，则在所有Server上消息A都将在消息B之前被发布；偏序是指如果一个消息B在消息A后被同一个发送者发布，A必将排在B前面。

ZK的Follower主要有4个功能：
	1. 向Leader发送请求(Ping消息、Request消息、Ack消息、Revalidate消息)
	2. 接收Leader消息并进行处理
	3. 接收Client消息，如果为写请求，发送给Leader处理
	4. 返回Client结果

Follower的消息循环处理以下来自Leader的消息：
	1. Ping消息：心跳消息
	2. Proposal消息：Leader发起的提案，要求Follower投票
	3. Commit消息：服务端最新一次提案的信息
	4. Uptodate消息：表明同步完成
	5. Revalidate消息：根据Leader的Revalidate结果，关闭待revalidate的session还是允许其接受消息
	6. Sync消息：返回Sync结果给客户端，这个消息最初由客户端发起，用来强制得到最新的更新

ZK的Observer: Zookeeper需保证高可用和强一致性；为了支持更多的客户端，需要增加更多Server，Server增多，投票延迟增大，影响性能；权衡伸缩性和高吞吐率，引入Observer；Observer不参与投票；Observer接受客户端的连接，并将写请求转发给Leader节点；加入更多Observer节点，提高伸缩性，同时不影响吞吐率。
ZK的Server数目一般为奇数(3、5、7等)，如果有3个，则最多允许1个挂掉；如果有4个，则同样最多允许1个挂掉；由此，3个和4个Server的容灾能力是一样的，所以为了节省服务器资源，一般采用奇数个数，作为服务器部署个数。	

Zookeeper的临时节点不能创建子节点。

你也可以想象 Zookeeper 维护了两条监视链表：数据监视和子节点监视(data watches and child watches) getData() and exists() 设置数据监视，getChildren() 设置子节点监视。或者，你也可以想象 Zookeeper 设置的不同监视返回不同的数据，getData() 和 exists() 返回 znode节点的相关信息，而 getChildren() 返回子节点列表。因此， setData()会触发设置在某一节点上所设置的数据监视(假定数据设置成功)，而一次成功的 create()操作则会出发当前节点上所设置的数据监视以及父节点的子节点监视。一次成功的 delete()操作将会触发当前节点的数据监视和子节点监视事件，同时也会触发该节点父节点的child watch。

Zookeeper中的监视是轻量级的，因此容易设置、维护和分发。当客户端与 Zookeeper服务器端失去联系时，客户端并不会收到监视事件的通知，只有当客户端重新连接后，若在必要的情况下，以前注册的监视会重新被注册并触发，对于开发人员来说这通常是透明的。只有一种情况会导致监视事件的丢失，即：通过 exists() 设置了某个 znode 节点的监视，但是如果某个客户端在此znode 节点被创建和删除的时间间隔内与 zookeeper 服务器失去了联系，该客户端即使稍后重新连接zookeeper服务器后也得不到事件通知。

序列化协议：
	1. Thrift
	2. 自定义协议(TLV协议, 8583协议)
	3. Avro
	4. FastJson
	5. FST
	6. Gson
	7. Hessian2
	8. java原生
	9. Kryo
	10. Protobuf
	11. Xml
	12. Jboss marshaling
	13. MessagePack
	
选择标准
	1. 是否跨语言;
	2. 性能：序列化性能和反序列化性能;
	3. 和现有框架的集成度(Spring, RPC);
	4. 可读性(可调试性);
	5. 是否具备兼容性(对于数据字段的增删)、扩展性；
	6. 序列化后的空间、网络占用带宽(是否支持压缩编码)；
	7. 是否支持丰富的数据类型；

FST是完全兼容JDK序列化协议的序列化框架，序列化速度大概是JDK的4-10倍，大小是JDK大小的1/3左右。

不同的场景适用的序列化协议：
	- 对于公司间的系统调用，如果性能要求在100ms以上的服务，基于XML的SOAP协议是一个值得考虑的方案。
	- 基于Web browser的Ajax，以及Mobile app与服务端之间的通讯，JSON协议是首选。对于性能要求不太高，或者以动态类型语言为主，或者传输数据载荷很小的的运用场景，JSON也是非常不错的选择。
	- 对于调试环境比较恶劣的场景，采用JSON或XML能够极大的提高调试效率，降低系统开发成本。
	- 当对性能和简洁性有极高要求的场景，Protobuf，Thrift，Avro之间具有一定的竞争关系。
	- 对于T级别的数据的持久化应用场景，Protobuf和Avro是首要选择。如果持久化后的数据存储在Hadoop子项目里，Avro会是更好的选择。
	- 由于Avro的设计理念偏向于动态类型语言，对于动态语言为主的应用场景，Avro是更好的选择。
	- 对于持久层非Hadoop项目，以静态类型语言为主的应用场景，Protobuf会更符合静态类型语言工程师的开发习惯。
	- 如果需要提供一个完整的RPC解决方案，Thrift是一个好的选择。
	- 如果序列化之后需要支持不同的传输层协议，或者需要跨防火墙访问的高性能场景，Protobuf可以优先考虑。

如何在发布时，新服务起来之后，不把请求发往老服务？
	1. 对于有LB的服务，在LB端进行流量分发；
	2. 对于软负载Ribbon，手工设置老服务下线。



相关问题：
1. 走eureka的滚动发布/蓝绿发布/灰度发布，也就是客户端负载均衡的情况
2. 不走eureka的滚动发布/蓝绿发布/灰度发布，也就是服务器端负载均衡的情况
3. 如何定义一个发布单元：将需要打包发布的服务打包为一个发布单元，进行整体分布。定义依赖关系，自动检测循环依赖关系。
4. 滚动发布/蓝绿发布/灰度发布如何控制除了RPC之外的调用，比如Kafka消息通讯。也就是非Client/Server的负载均衡情况。
5. 如何解决新老服务之间同时运行期间造成的不一致。
6. 新服务不可用时，如何正确回滚到老服务，包括代码、数据库、MQ等。
7. 如何在引入流量期间能够快速全面的发现问题：包括更细粒度的业务健康度监控、DB层面的监控等；另外，线上自动化测试验证，也能帮助我们在引流阶段发现由于线上线下环境差异而带来的问题。
8. 大规模自动化应用部署能力：全应用并行发布，颠覆以往顺序发布的模式，对发布平台的资源分发等方面的性能也提出了较大挑战。
9. 如何提供更细粒度的流量调度能力。

Instrumentation:
	利用Java代码，即java.lang.instrument做动态Instrumentation是Java SE 5的新特性，它把Java的instrument功能从本地代码中解放出来，使之可以用Java代码的方式解决问题。使用Instrumentation,开发者可以构建一个独立于应用程序的代理程序(Agent)，用来监测和协助运行在JVM上的程序，甚至能够替换和修改某些类的定义。有了这样的功能，开发者就可以实现更为灵活的运行时虚拟机监控和Java类操作了，这样的特性实际上提供了一种虚拟机级别支持的AOP实现方式，使得开发者无需对JDK做任何升级和改动，就可以实现某些AOP的功能了。
	在Java SE6中，instrumentation包被赋予了更强大的功能；启动后的instrument、本地代码(native code)、以及动态改变classpath等等。这些改变，意味着具有了更强的动态控制、解释能力，它使得Java语言变得更加灵活多变。
	java.lang.instrument包的具体实现，依赖于JVMTI。JVMTI(Java Virtual Machine Tool Interface)是一套由Java虚拟机提供的，为JVM相关的工具提供的本地编程接口集合。JVMTI是从Java SE5开始引入，整合和取代了以前使用的Java Virtual Machine Profiler Interface(JVMPI)和Java Virtual Machine Debug Inteface(JVMDI)，而在Java SE6中，JVMPI和JVMDI已经消失了。JVMTI提供了一套“代理”程序机制，可以支持第三方工具程序以代理的方式连接和访问JVM，并利用JVMTI提供的丰富的编程接口，完成很多跟JVM相关的功能。

Java SE6新特性，获取Instrumentation接口的实例有两种方法：
	1. 当JVM以指示一个代理类的方式启动时，将传递给代理类的premain方法一个Instrumentation实例。
	2. 当JVM提供某种机制在JVM启动之后某一时刻启动代理时，将传递给代理代码的agentmain方法一个Instrumentation实例。


Kafka怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)
Lag即consumer offset lag。可以通过下列三种方式进行定制监控(当然可以使用其他现有工具):
	1. 利用官方类库:ConsumerOffsetChecker，适用于0.8.2.2版本，kafka_2.10-0.8.2.2-sources.jar!/kafka/tools/ConsumerOffsetChecker.scala; 缺点是该类是给命令行调用的，每调用一次，就new一次zkClient，对于监控来说，不太适合，需要改造一下，将zkClient抽取出来。
	2. 利用官方库：ConsumerGroupCommand，0.8.2.2以上版本使用ConsumerGroupCommand替代了ConsumerOffsetChecker，kafka_2.11-0.10.2.1-sources.jar!/kafka/admin/ConsumerGroupCommand.scala 
	3. 直接利用kafka本身写入JMX的数据。

对于Kafka的LEO和HW而言，这两个都是指最后一条的下一条的位置而不是指最后一条的位置。
LSO是指LastStableOffset，不是LogStartOffset，它与具体的kafka事务有关。
Kafka的消费端isolation.level，这个参数用来配置消费者的事务隔离级别。字符串类型，有效值为:read_uncommitted和read_committed，表示消费者所消费到的位置，如果设置为read_committed，那么消费者就会忽略事务未提交的消息，即只能消费到LSO(LastStableOffset)的位置，默认情况下为:read_uncommitted，即可以消费到HW(High Watermark)处的位置。注意: follower副本的事务隔离级别也为:read_uncommitted，并且不可修改。在开启Kafka事务时，生产者发送了若干消息（比如msg1、msg2、msg3）到broker中，如果生产者没有提交事务（执行commitTransaction），那么对于isolation.level = read_committed的消费者而言是看不到这些消息的，而isolation.level = read_uncommitted则可以看到。事务中的第一条消息的位置可以标记为firstUnstableOffset（也就是msg1的位置）。这个LSO还会影响Kafka消费滞后量(即Kafka Lag，也称为消息堆积量)的计算。
对每个分区而言，Lag等于HW-ConsumerOffset的值，其中ConsumerOffset表示当前的消费位移。当然这只是针对普通的情况。如果消息引入了事务，那么Lag的计算方式就会有所不同。
如果消费者客户端的isolation.level参数设置为read_uncommitted(默认情况)，那么Lag的计算方式不受影响；如果这个参数配置为read_committed，那么就要引入LSO来进行计算了。对于未完成的事务而言，LSO的值等于事务中第一条消息的位置(firstUnstableOffset)，对于已经完成的事务而言，它的值同HW相同，因此结论：LSO<=HW<=LEO。所以，对于分区中有未完成的事务，并且消费者客户端的isolation.level配置为read_committed的情况，它对应的Lag等于LSO-ConsumerOffset的值。

考虑情形：需要将静态内容（类似图片、文件）展示给用户。那么这个情形就意味着你需要先将静态内容从磁盘中拷贝出来放到一个内存buf中，然后将这个buf通过socket传输给用户，进而用户或者静态内容的展示。
在这个过程中，文件经历了4次Copy的过程：
	1. 首先调用read时，文件拷贝到内核空间；
	2. 之后CPU控制将内核空间的数据拷贝到用户空间；
	3. 调用write时，先将用户空间下的数据拷贝到内核空间下的socket的buffer中；
	4. 最后将内核空间下的socket buffer的数据copy到网卡设备中传送。
从上面的过程可以看到，数据白白从内核空间到用户空间走了一圈，浪费了2次copy(第一次，从内核空间拷贝到用户空间；第二次从用户空间再拷贝到内核空间，即上面的过程2和过程2).而且上面的过程中，内核空间和用户空间的上下文切换的次数是4次。
可用一种Zero-Copy的技术来节省无所谓的拷贝。应用程序可以用Zero-Copy来请求内核直接把磁盘的数据传输给socket，而不是经过应用程序传输。Zero-Copy大大提高了应用程序的性能，并且减少了内核和用户空间的上下文切换。	
Zero-Copy技术省去了将操作系统的read buffer拷贝到程序的buffer，以及从程序buffer拷贝到socket buffer的步骤，直接将read buffer拷贝到socket buffer。Java NIO中的FileChannel.transferTo()方法就是这样实现的，底层依赖操作系统的sendFile()。
使用了Zero-Copy技术之后，整个过程如下：
	1. transferTo()方法使得文件的内容直接拷贝到read buffer(内核空间)中；
	2. 然后数据拷贝到socket buffer中；
	3. 最后将socket buffer中的数据拷贝到网卡设备中传输。
	这显然是比较的进步：这里将上下文切换次数从4次减少到2次，同时也把数据拷贝的次数从4次降低到3次。
但这并不是Zero-Copy。在Linux2.1内核引入了sendfile(socket, file, len)函数，该函数通过一次系统调用完成了文件的传送，减少了原来的read/write的上下文切换。通过sendfile传输文件只需要一次系统调用，如下：
	1. 首先(通过DMA)将数据从磁盘读取到内核buffer中；
	2. 然后将内核buffer拷贝到socket buffer；
	3. 最后将socket buffer中的数据拷贝到网卡设备发送。
sendfiel与read/write模式相比，少了一次copy。但是从上述过程中也可以发现从kernel buffer中将数据copy到socket buffer是没有必要的。	
Linux2.4内核对sendfile()做了改进。改进后的处理过程如下：
	1. 将文件拷贝到内核buffer;
	2. 向socket buffer中追加当前要发生的数据在内核buffer中的位置和偏移量；
	3. 根据socket buffer中的位置和偏移量直接将内核buffer中的数据拷贝到网卡设备。
经过上述过程，数据只经过了2次拷贝就从磁盘传输出去了。这才是真正的Zero-Copy(这里的零拷贝是针对内核来说，数据在内核模式下是Zero-Copy)。正是Linux2.4的内核做了改进，Java中的TransferTo()实现了Zero-Copy。


Kafka的AR、ISR、OSR、LEO、HW这些元信息都保存在Zookeeper中。
最开始所有的副本都在ISR中，在Kafka工作的过程中，如果某个副本同步速度慢于replica.lag.time.max.ms指定的阈值，则被剔除ISR存入OSR，如果后续速度恢复可以重新加入ISR中。
HW的截断机制：如果leader宕机，选出了新的leader，而新的leader并不能保证已经完全同步了之前leader的所有数据，只能保证HW之前的数据是同步过的，此时所有的follower都要将数据截断到HW的位置，再和新的leader同步数据，来保证数据一致。当宕机的leader恢复，发现新的leader中的数据和自己持有的数据不一致，此时宕机的leader会将自己的数据截断到宕机之前的hw位置，然后同步新leader的数据。宕机的leader活过来也像follower一样同步数据，来保证数据的一致性。
	

