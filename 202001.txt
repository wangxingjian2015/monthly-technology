为什么Mongodb的索引用了B树，而mysql用B+树:
B树和B+树的最重要的一个区别：B+树只有叶子节点存放数据，其余节点用来索引。而B树每个索引节点都会有Data域。这就决定了B+树更适合用来存储外部数据，即磁盘数据。
从InnoDB的角度来看，B+树用来充当索引，一般来说索引非常大，尤其是关系型数据库索引能达到亿级，所以为了减少内存的占用，索引也会被存储在磁盘上。
MySQL如何衡量查询效率：磁盘IO次数。B树的特点就是每层节点数目非常多，层数很少，目的就是减少磁盘IO次数，当查询数据的时候，最好的情况就是很快找到目标索引，然后读取数据，使用B+树可以很好完成这个目的。但是B树的每个节点都有Data域，无疑增大了节点大小，即增加了磁盘IO次数(磁盘IO一次读出的数据量大小是固定的，单个数据变大，每次读出的就少，IO次数增多)，而B+树除了叶子节点其他节点都不存储数据，节点小，磁盘IO次数就少。这是优点之一。
另一个优点：B+树所有的Data域在叶子节点，一般会进行一个优化，将所有的叶子节点用指针串起来，这样遍历叶子节点就能获得全部数据，就能进行区间访问了。
数据库索引采用B+树的主要原因是B树在提高磁盘IO性能的同时，并没有解决元素遍历的效率低下问题。正是为了解决这个问题，B+树应运而生。B+树只要遍历叶子节点就可以实现整个树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作(或者说效率太底)。
至于MongoDB为什么使用B树而不是B+树，从它的设计角度来考虑，它不是传统的关系型数据库，而是以Json格式存储的NOSQL,目的是高性能、高可用、易扩展。首先它摆脱了关系模型，上面所说的优点二需求就没那么强烈了，其次MySQL由于使用B树，数据都在叶子节点上，每次查询都需要访问叶子节点，而MongoDB使用B树，所有节点都有Data域，只要找到指定索引就可以进行访问，无疑单次查询平均快于MySQL。
总体来说，MySQL选择B+树，MongoDB选择B树，都是以自己的设计需求来选择。
B树的两个明显特点：
	1. 树内的每个节点都存储数据；
	2. 叶子节点之间无指针相邻；
B+树的两个明显特点：
	1. 数据只出现在叶子节点；
	2. 所有叶子节点增加了一个链接指针。

针对上面的B+树和B树的特点，我们做一个总结
(1)B树的树内存储数据，因此查询单条数据的时候，B树的查询效率不固定，最好的情况是O(1)。我们可以认为在做单一数据查询的时候，使用B树平均性能更好。但是，由于B树中各节点之间没有指针相邻，因此B树不适合做一些数据遍历操作。

(2)B+树的数据只出现在叶子节点上，因此在查询单条数据的时候，查询速度非常稳定。因此，在做单一数据的查询上，其平均性能并不如B树。但是，B+树的叶子节点上有指针进行相连，因此在做数据遍历的时候，只需要对叶子节点进行遍历即可，这个特性使得B+树非常适合做范围查询。

因此，我们可以做一个推论:没准是Mysql中数据遍历操作比较多，所以用B+树作为索引结构。而Mongodb是做单一查询比较多，数据遍历操作比较少，所以用B树作为索引结构。

那么为什么Mysql做数据遍历操作多？而Mongodb做数据遍历操作少呢？
因为Mysql是关系型数据库，而Mongodb是非关系型数据。
-------------------------------------------------------------
Redis的数据结构：
	1. String;
	2. Hash;
	3. List;
	4. Set;
	5. SortedSet;
	6. HyperLogLog;
	7. GEO;
另外Redission扩展了很多功能：
A: SpringCache, TomcatSession, HibernateCache
B: SpringSession, BloomFilter, SocredSortedSet, SortedSet
C: Queue, BlockingQueue, LuaScript, BlockingDeque, Deque
D: MapCache, Map, BitSet, SetMultimap, SetCache, Set, List, ListMultimap
E: Lock, ReadWriteLock, Semaphore, CountDownLatch, Geo
F: LiveObjectService, ExecutorSerivce, SchedulerService, RemoteService, AtomicLong, Publish/Subscribe

Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务。其中包括(BitSet, Set, Multimap, SortedSet, Map, List, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, AtomicLong, CountDownLatch, Publish/Subscribe, Bloom filter, Remote service, Spring cache, Executor service, Live Object service, Scheduler service) Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。
Redisson底层采用的是Netty框架，支持Redis2.8以上版本，支持JDK1.6以上版本。

InnoDB目前有四种行格式: compact(简洁的), redundant(冗余的), dynamic(动态的), compress(压缩的)；

HTTP1.0和1.1的区别：
	1. 缓存处理：在Http1.0中主要使用header里的If-Modified-Since, Expires来做缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略。例如：Entity tag, If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。
	2. 带宽优化及网络连接的使用：Http1.0中，存在一些浪费带宽的现象，比如客户端只是需要某个对象的一部分，而服务器却将整个对象传输过来，不支持断点续传功能。Http1.1则在请求头引入了range头域，它允许只请求资源的某部分，即返回码是206(Partial Content)，方便开发者自由选择以便于充分利用带宽和连接。
	3. 错误通知的管理：在Http1.1中新增了24个状态响应命，如409(Conflict)表示请求的资源与资源当前状态冲突；410(Gone)表示服务器上的某个资源被永久性的删除。
	4. Host头处理：在Http1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名(hostname)。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）
	5. 长连接和流水线：HTTP1.1支持长连接(PersistentConnection)和流水线(Pipelining)处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。在HTTP1.1中默认开启:keep-alive，弥补了Http1.0每次请求都创建连接的缺点。请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。例如：一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。  HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容。

聚簇索引的优势：
	看上去聚簇索引的效率明显低于非聚簇索引，因为每次使用辅助索引检索都要经过两次B+树查找，多此一举。
	1. 由于行数据和叶子节点存储在一起，同一页中会有多行数据，访问同一数据页不同行记录时，已经把页加载到了Buffer中，再次访问的时候，会在内存中完成，不必访问磁盘。这样主键和行数据是一起载入内存的，找到叶子节点就可以立刻将行数据返回了，如果按照主键ID来组织数据，获得数据更快。
	2. 辅助索引使用主键作为指针，而不是使用地址值作为指针的好处是：减少了当出现行移动或者数据页分裂时辅助索引的维护工作，使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是InnoDB在移动行时无须更新辅助索引中的这个指针。也就是说行的位置(实现中通过16K的Page来定位)会随着数据库里数据的修改而发生改变(B+树节点分裂以及Page的分裂)，使用聚簇索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响。
	3. 聚簇索引适合用于在排序的场景，非聚簇索引不适合。
	4. 取出一定范围的时候，使用聚簇索引。
	5. 二级索引需要两次索引查找，而不是一次才能取到数据，因此存储引擎第一次需要通过二级索引找到索引的叶子节点，从而找到数据的主键，然后在聚簇索引中用主键再次查找索引，再找到数据。
	6. 可以把相关数据保存在一起。只需从磁盘读取少数的数据页就能获取相关数据。
聚簇索引的劣势：
	1. 维护索引很昂贵，特别是插入新行或者主键被更新导致分页(page split)的时候。建议在大量插入新行后，选择负载低的时间段，通过optimize table优化表，因为被移动的行数据可能造成碎片。使用独享表空间可以弱化碎片。
	2. 表因为使用UUID作为主键，使数据存储稀疏，这就会出现聚簇索引可能比全表扫描更慢。新插入的记录会插入到之前的记录中间，导致需要强制移动之前的记录。被写满且已经刷到磁盘上的页可能会被重新读取。建议使用int的auto_increment作为主键。主键的值是顺序的，所以 InnoDB 把每一条记录都存储在上一条记录的后面。当达到页的最大填充因子时（InnoDB 默认的最大填充因子是页大小的 15/16，留出部分空间用于以后修改），下一条记录就会写入新的页中。一旦数据按照这种顺序的方式加载，主键页就会近似于被顺序的记录填满（二级索引页可能是不一样的）。
	3. 如果主键比较大的话，那辅助索引将会变更大，因为辅助索引的叶子存储的是主键值；过长的主键值，会导致聚簇索引的非叶子节点占用更多的物理空间。

使用Http长连接之后，客户端、服务端怎么知道本次传输结束呢？两部分：1是判断传输数据是否达到了Content-Length指示的大小；2动态生成的文件没有Content-Length，它是分块传输（chunked），这时候就要根据chunked编码来判断，chunked编码的数据在最后有一个空chunked块，表明本次传输数据结束。

TCP的keep alive是检查当前TCP连接是否活着；HTTP的Keep-alive是要让一个TCP连接活久点。它们是不同层次的概念。
TCP keep alive的表现：当一个连接“一段时间”没有数据通讯时，一方会发出一个心跳包（Keep Alive包），如果对方有回包则表明当前连接有效，继续监控。这个“一段时间”可以设置。

HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。IP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠地传递数据包，使得网络上接收端收到发送端所发出的所有包，并且顺序与发送顺序一致。TCP协议是可靠的、面向连接的。

TCP三次握手的流程和状态流转：
	1. 客户端发送SYN报文，并设置发送序号为X(SYN=1, Ack=0, seq=X)；之后客户端状态变为SYN-SEND；
	2. 服务端收到之后，回复SYN+ACK报文，并置发送序号为Y(SYN=1, ACK=1, seq=Y, ack=X+1)；之后服务端状态为SYN-RECEIVED;
	3. 客户端收到之后，回复ACK报文(ACK=1,Seq=X+1, acK=Y+1)；客户端状态变为ESTABLISHED,服务端收到之后也变成ESTABLISHED。
TCP四次挥手的流程和状态流转：
	1. 主动发起方发起FIN=1,seq=u报文，发送之后主动发起方状态变为FIN-WAIT-1;
	2. 被动方接收到之后，回复ACK=1, seq=v,ack=u+1报文，之后被动方状态变为CLOSE-WAIT;
		主动发起方收到回复后，状态变为FIN-WAIT-2；之后等待被动方发起FIN报文；
	3. 被动方在发送完最后的报文后，发起FIN=1, ACK=1, seq=w, ack=u+1的报文，之后被动方状态变为LAST-ACK；
	4. 主动发起方收到之后，回复ACK=1,seq=u+1, ack=w+1，之后主动发起方状态变成TIME-WAIT。
		被动方收到回复后，状态从LAST-ACT变成CLOSED；
		主动方在变成TIME-WAIT状态后的2MSL时间之后，状态变成CLOSED。

TCP中的6个标志位：URG, ACK, PSH, RST, SYN, FIN；
在这6个标志中，TCP的三次握手和四次挥手用到了3个：
SYN：SYN=1表示这是一个连接请求或连接接收报文。在建立连接时用来同步序号(在建立连接的时候，提醒对方记录本方的起始序号)。当SYN=1而ACK=0时，表明这是一个连接请求报文段。对方若是同意建立连接，则响应的报文段中使SYN=1,ACK=1。因此SYN=1表示该报文是一个连接请求或者一个连接请求接收报文。
ACK：确认号只有在该位设置为1的时候才生效，当该位为0表示确认号无效。TCP规定，在TCP连接建立后所有传送的报文段ACK都必须设置为1.
FIN:当FIN=1时，表明该报文段的发送方的数据已经发送完毕，并要求释放连接。

此外，还需要序号和确认号：
	序号：占4个字节，它的范围在0-2^32-1，序号随着通信的进行不断的递增，当达到最大值的时候重新回到0在开始递增。TCP是面向字节流的，在一个TCP连接中传送的字节流中的每一个字节都按照顺序编号。整个要传送的字节流的起始号必须在连接建立时设置。首部中的序列号字段指的是本报文段所发送的数据的第一个字节的序号。例如，一个报文序号是301，而携带的数据共有100字节。则表示本次报文中的序号是301，下一个报文的序号是401.重复一下，每一个报文的序号是该报文包含的字节中第一个字节的编号。
	确认号：占4个字节，确认号，是对下一个想要接受的字节的期望，这里隐式确认了对上一个数据包的成功接收。如上例，在成功接收了序号为301的数据包，想要接收下一个数据包因为上个数据包包含100字节，所以此时的确认号应该是401，表示希望接收下一个序号是401的数据包。
-----------------------------------------
为什么需要进行三次握手：
为什么客户端还要发送确认呢？这主要是为了防止已失效的连接请求报文突然又传送到了服务端，导致错误。
所谓“已失效的连接请求报文段”是这样产生的。考虑一种正常情况。客户端发出连接请求，但因连接请求丢失而未收到确认。于是客户端再次重传一次连接请求。后来收到了确认建立了连接。数据传输完毕后，就释放了连接。客户端共发送了两个连接请求的报文段，其中第一个丢失，第二个到达了服务端。没有“已失效的连接请求报文段”。
假定出现一种异常情况，即客户端发出的第一个连接请求报文段并没有丢失，而是在某些网络节点长时间滞留了，以致延误到连接释放以后的某个时间才到服务端。本来这是一个已失效的报文段。但是服务端收到此失效的连接请求报文段后，就误认为是客户端有发出一次新的连接请求。于是就向客户端发出确认报文段，同意建立连接。假定不采用三次握手，那么只要服务端发出确认，新的连接就建立了。

由于现在客户端并没有发出建立连接的请求，因此不会理睬服务端的确认，也不会向服务端发送数据。但服务端却以为新的连接已经建立了，并一直等待客户端发来数据。服务端的许多资源就这样拜拜浪费了。

采用三次握手的办法可以防止上述现象的发生。例如在刚才的情况下，客户端不会向服务端的确认发出确认。服务端由于收不到确认，就知道客户端并没有要求建立连接。

另一种解释：
这个问题的本质是, 信道不可靠, 但是通信双发需要就某个问题达成一致. 而要解决这个问题, 无论你在消息中包含什么信息, 三次通信是理论上的最小值. 所以三次握手不是TCP本身的要求, 而是为了满足"在不可靠信道上可靠地传输信息"这一需求所导致的. 请注意这里的本质需求,信道不可靠, 数据传输要可靠. 三次达到了, 那后面你想接着握手也好, 发数据也好, 跟进行可靠信息传输的需求就没关系了. 因此,如果信道是可靠的, 即无论什么时候发出消息, 对方一定能收到, 或者你不关心是否要保证对方收到你的消息, 那就能像UDP那样直接发送消息就可以了”。这可视为对“三次握手”目的的另一种解答思路。
-----------------------------------------
为什么TIME-WAIT状态需要等2*MSL之后才能返回CLOSED状态：
	因为虽然双方都同意关闭连接了，而且挥手的4次报文都发送完毕，按理可以直接CLOSED状态，但是网络的不可靠性，无法保证最后发送的ACK报文一定被被动方收到，就是说对方处于LAST-ACK状态下的Socket可能会因为超时未收到ACK报文，而重发FIN报文，所以这个TIME-WAIT状态的作用是用来重发可能丢失的ACK报文。

TCP有哪些状态：共11种：
1. CLOSED：初始状态，表示TCP连接是“关闭着的”或“未打开的”。
2. LISTEN ：表示服务器端的某个SOCKET处于监听状态，可以接受客户端的连接。
3. SYN_RCVD ：表示服务器接收到了来自客户端请求连接的SYN报文。在正常情况下，这个状态是服务器端的SOCKET在建立TCP连接时的三次握手会话过程中的一个中间状态，很短暂，基本上用netstat很难看到这种状态，除非故意写一个监测程序，将三次TCP握手过程中最后一个ACK报文不予发送。当TCP连接处于此状态时，再收到客户端的ACK报文，它就会进入到ESTABLISHED 状态。
4. SYN_SENT ：这个状态与SYN_RCVD 状态相呼应，当客户端SOCKET执行connect()进行连接时，它首先发送SYN报文，然后随即进入到SYN_SENT 状态，并等待服务端的发送三次握手中的第2个报文。SYN_SENT 状态表示客户端已发送SYN报文。
5. ESTABLISHED ：表示TCP连接已经成功建立。
6. FIN_WAIT_1 ：其实FIN_WAIT_1 和FIN_WAIT_2 两种状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET进入到FIN_WAIT_1 状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2 状态。当然在实际的正常情况下，无论对方处于任何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1 状态一般是比较难见到的，而FIN_WAIT_2 状态有时仍可以用netstat看到。
7. FIN_WAIT_2 ：上面已经解释了这种状态的由来，实际上FIN_WAIT_2状态下的SOCKET表示半连接，即有一方调用close()主动要求关闭连接。注意：FIN_WAIT_2 是没有超时的（不像TIME_WAIT 状态），这种状态下如果对方不关闭（不配合完成4次挥手过程），那这个 FIN_WAIT_2 状态将一直保持到系统重启，越来越多的FIN_WAIT_2 状态会导致内核crash。
8. TIME_WAIT ：表示收到了对方的FIN报文，并发送出了ACK报文。 TIME_WAIT状态下的TCP连接会等待2*MSL（Max Segment Lifetime，最大分段生存期，指一个TCP报文在Internet上的最长生存时间。每个具体的TCP协议实现都必须选择一个确定的MSL值，RFC 1122建议是2分钟，但BSD传统实现采用了30秒，Linux可以cat /proc/sys/net/ipv4/tcp_fin_timeout看到本机的这个值），然后即可回到CLOSED 可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（这种情况应该就是四次挥手变成三次挥手的那种情况）
9. CLOSE_WAIT ：表示正在等待关闭。怎么理解呢？当对方close()一个SOCKET后发送FIN报文给自己，你的系统将会回应一个ACK报文给对方，此时TCP连接则进入到CLOSE_WAIT状态。接下来呢，需要检查自己是否还有数据要发送给对方，如果没有的话，那你也就可以close()这个SOCKET并发送FIN报文给对方，即关闭自己到对方这个方向的连接。有数据的话则看程序的策略，继续发送或丢弃。简单地说，当你处于CLOSE_WAIT 状态下，需要完成的事情是等待你去关闭连接。
10. LAST_ACK ：当被动关闭的一方在发送FIN报文后，等待对方的ACK报文的时候，就处于LAST_ACK 状态。当收到对方的ACK报文后，也就进入到CLOSED状态。
11. CLOSING:这种状态实际情况很少见。正常情况下，主动方发出FIN报文后，应该先收到对方的ACK报文，再收到被动方的FIN报文。但是CLOSING状态表示一方发送FIN报文后，并没有收到ACK报文，反而收到了FIN报文。什么情况下会出现这种情况呢？当双方同时close()时，就出现同时发送FIN报文，就会出现CLOSING状态。
UncaughtExceptionHandler

BIO:同步阻塞IO，服务器实现模式为一个连接一个线程，即客户端有连接请求时就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。
NIO:同步非阻塞IO，服务器实现模式为一个请求一个线程，即客户端发送的连接都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。
AIO(NIO2.0):异步非阻塞IO，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成再通知应用去启动线程进行处理。

NIO和BIO的区别：
	1. NIO以缓冲的方式处理数据，BIO是以最基础的字节流形式写入和读出的。在效率上，NIO效率比BIO效率会高。
	2. NIO不再是以BIO的方式用OutputStream和InputStream输入输出流来处理数据，而是采用了通道和缓冲区的形式处理数据。
	3. NIO的通道可以是双向的，但是IO中的流只能是单向的。
	4. NIO的缓冲区可以进行分片，可以建立只读缓冲区、直接缓冲区和间接缓冲区，直接缓冲区为加快IO速度以一种特殊的方式分配内存的缓冲区。
	5. NIO采用多路复用的IO模型，BIO采用阻塞IO。

NIO是一种同步非阻塞的IO模型，也是IO多路复用的基础，成为解决高并发与大量连接、IO处理问题的有效方式。

synchronized能防止指令重排序吗：能，java有序性根据happens-before原则，其中有一条解锁操作happen-before加锁操作。
单例模式的double check单例是否需要对实例使用volatile修饰？需要。
实际上由于第一个if没有synchronized，所以synchronized带来的有序性对第一个if是不生效的。于是就会出现一种情况：就是new Singleton()时，先将引用分配给了instance，后创建实例。这样在其他线程进入到第一个if的时候就会为false，使用未生成实例的引用。这个时候使用volatile实际上是保证了第一个if读的时候的有序性，对volatile变量的写happen-before读，从而禁止了new Singleton()时的重排序。
----------------------------------------------------------
volatile是如何实现可见性的：
用volatile修饰的共享变量进行写操作的时候会多出Lock前缀的指令。
Lock前缀的指令主要有两方面的影响：
	1. 将当前处理器缓存行的数据写回内存；
	2. 这个写回内存的操作回使得其他CPU里缓冲了该内存地址的数据无效。

为了提高处理速度，处理器不直接和内存进行通信，而是先将内存的数据读到内部缓冲(L1,L2等)后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回内存。但是，就算写回内存，如果其他处理器缓冲的值还是旧的，再只需计算操作还是会有问题。
所以，在多处理器下，为了保证各个处理器的缓冲是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置为无效，当处理器对这个数据进行修改操作的时候，会重新从系统内存把数据读到处理器缓存里。
因此，可以得出如下结论：
	1. Lock前缀的指令会引起处理器缓存写回内存；
	2. 一个处理器的缓存回写到内存会导致其他处理器的缓存失效；
	3. 当处理器发现本地缓存失效后，就会从内存重读该变量数据，即可以获取当前最新值。
----------------------------------------------------------
volatile如何阻止重排序：
	为了失效volatile内存语义，编译器会在生成字节码时，在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，一个最优布置来最小化插入屏障是几乎不可能的，为此JMM采取了保守策略：
	1. 在每个volatile写操作前面插入一个StoreStore屏障
	2. 在每个volatile写操作后面插入一个StoreLoad屏障
	3. 在每个volatile读操作前面插入一个LoadLoad屏障
	4. 在每个volatile读操作后面插入一个LoadStore屏障

synchronized的特性：原子性，可见性，有序性，可重入性。
每一个锁都对应一个monitor对象，在HotSpot虚拟机中它是由ObjectMonitor实现的(C++实现)。每个对象都存在着一个monitor与之关联，对象与其monitor之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个monitor被某个线程持有后，它便处于锁定状态。
ObjectMonitor() {
	_header       = NULL;
	_count        = 0;   //锁计数器
	_waiters      = 0;
	_recursions   = 0;
	_object       = NULL;
	_owner        = NULL;
	_WaitSet      = NULL;   //处于wait状态的线程，会被加入到_WaitSet
	_WaitSetLock  = 0;
	_Responsilbe  = NULL;
	_succ         = NULL;
	_cxq          = NULL;
	FreeNext      = NULL;
	_EntryList    = NULL;   //处于等待锁block状态的线程，会被加入到该列表
	_SpinFreq     = 0;
	_SpinClock    = 0;
	OwnerIsThread = 0;
}

锁消除：消除锁是虚拟机一种锁优化，这种优化更彻底，在JIT编译时，对运行上下文进行扫描，去除不可能存在竞争的锁。比如下面代码的method1和method2的执行效率是一样的，因为object锁是私有变量，不存在锁竞争关系。
锁粗化：是虚拟机对另外一种极端情况的优化处理，通过扩大锁的范围，避免反复加锁和释放锁。
---------------------------------
B+索引和Hash索引的区别，优缺点
	1. 如果是等值查询，哈希索引有明显优势。当然前提是键值是唯一的，如果键值不唯一，出现哈希冲突就具体分析；
	2. 如果是范围查询检索，哈希索引无用武之地。因为原先有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法利用索引完成范围查询检索；
	3. 哈希索引也没办法利用索引完成排序，以及like模糊查询；
	4. 哈希索引页不支持多列联合索引的最左匹配规则；
	5. B+树索引的关键字检索效率比较平均，在有大量重复键值情况下，哈希索引的效率是很低的，因此存在哈希碰撞问题。
	
---------------------------------
在MySQL中，只有Heap/Memory引擎才能显式支持哈希索引(NDB也支持)，InnoDB引擎的自适应哈希索引不在此列。
JDK7和JDK8中HashMap的区别：
	1. 在哈希碰撞时，JDK7使用头插入法，JDK8使用尾插入法。因为JDK7用单链表进行纵向延伸，当采用头插法时会容易出现逆序且链表死循环问题。JDK8因为加入了红黑树使用尾插入法，能够避免出现逆序且链表死循环问题。
	2. 扩容后数据存储位置计算方式不同。JDK7使用hash值和扩容后的容量&运算。JDK8使用hash&oldCap的值，如果0原来位置，否则原来位置+oldCap。
	3. hash值的计算方式不同：JDK7用了9次扰动处理=4次位运算+5次异或，而JDK8只用了2次扰动处理=1次位运算+1次异或。
	4. 扩容时机不同：JDK7先扩容再插入，JDK8先插入后扩容。
	5. JDK7使用数组+单链表的数据结构。JDK8是数组+链表+红黑树(当链表的深度达到8的时候，也就是默认阈值，就会自动扩容把链表转成红黑树的数据结构来把时间复杂度从O(n)变成O(logN)提高了效率）

)。
为什么HashMap中String、Integer这样的包装类适合作为key键:
	1. String, Integer等包装类的特性包装了hash值的不可变更性，保证计算准确性；
	2. 有效减少了发生hash碰撞的机率。
	
public class WeakHashMap<K, V> extends AbstractMap<K, V>
		implements Map<K, V> {
	...
	// Reference queue for cleared WeakEntires
	private final ReferenceQueu<Object> queue = new ReferenceQueue<>();
	...
	// The entries in this hash table extend WeakReference, using its main ref field as the key.
	private static class Entry<K,V> extends WeakReference<Object> implements Map.Entry<K,V> {
		V value;
		final int hash;
		Entry<K,V> next;
		
		Entry(Object key, V value, ReferenceQueue<Object> queue, int hash, Entry<K,V> next) {
			super(key, queue);
			this.value = value;
            this.hash  = hash;
            this.next  = next;
		}
	}
	
	//Returns the table after first expunging stale entries
	private Entry<K, V>[] getTables() {
		expungeStaleEntries();
		return table;
	}
	//Expunges stale entries from the table.
	private void expungeStaleEntries() {
		for (Object x;(x = queue.poll()) != null;) {
			synchronized(queue) {
				@SuppressWarnings("unchecked")
				Entry<K, V> e = (Entry<K, V>)x;
				int i = indexFor(e.hash, table.length);
				
				Entry<K, V> prev = table[i];
				Entry<K, V> p = prev;
				while (p != null) {
					Entry<K, V> next = p.next;
					if (p == e) {
						if (prev == e)
							table[i] = next;
						else 
							prev.next = next;
						// Must not null out e.next;
						// stale entries may be in use by HashIterator
						e.value = null;   //help GC
						size --;
						break;
					}
					prev = p;
					p = next;
				}
			}
		}
	}
}
JDK8中的WeakHashMap在发生哈希碰撞时，使用链表存储冲突元素，使用头插入法。		
HashMap和Weakhashmap的区别

如何安全发布对象：
	1. 在静态初始化函数中初始化一个对象引用；
	2. 将对象的引用保存到volatile类型域或者AtomicReference对象中;
	3. 将对象的引用保存到某个正确构造对象的final类型域中；
	4. 将对象的引用保存到一个由锁保护的域中。

Netty的零拷贝主要体现在三个方面：
	1. Netty的接收和发送ByteBuf采用Direct Buffer，使用堆外内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存(Heap buffer)进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存，然后才写入socket。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
	2. Netty提供了组合Buffer对象，可以聚合多个ByteBuff对象，用户可以像操作一个Buffer方便对组合Buffer进行操作，避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大Buffer。
	3. Netty的文件传输采用了transferTo方法，它可以直接将文件缓冲区的数据发送到目标Channel，避免传统通过循环write方式导致内存拷贝问题。

Zero Copy模式中，避免了数据在用户空间和内核空间之间的拷贝，从而提高了系统的整体性能。Linux中的sendfile以及Java NIO中的FileChannel.transferTo()方法都实现了零拷贝的功能，而在Netty中也通过在FileRegion中包装NIO的FileChannel.transferTo()方法实现了零拷贝。

在HTTP/1.1协议中，浏览器客户端在同一时间，针对同一域名下的请求有一定数量限制，超过限制数目的请求会被阻塞。
而HTTP/2的多路复用(Multiplexing)，则允许同时通过单一的HTTP/2连接发起多重的请求-响应消息。
因此HTTP/2可以很容易的实现多流并行而不用依赖建立多个TCP连接，HTTP/2把HTTP协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息，并行地在同一个TCP连接上双向交换消息。
在不改动HTTP/1.X的语义、方法、状态码、URI以及首部字段的情况下，HTTP/2如何做到突破HTTP1.1的性能限制，改进传输性能，实现低延迟和高吞吐量的？关键之一在应用层(HTTP/2)和传输层(TCP/UDP)之间增加了一个二进制分帧层。

多路复用：直白的说就是所有的请求都是通过一个 TCP 连接并发完成。HTTP/1.x 虽然通过 pipeline 也能并发请求，但是多个请求之间的响应会被阻塞的，所以 pipeline 至今也没有被普及应用，而 HTTP/2 做到了真正的并发请求。同时，流还支持优先级和流量控制。当流并发时，就会涉及到流的优先级和依赖。优先级高的流会被优先发送。图片请求的优先级要低于 CSS 和 SCRIPT，这个设计可以确保重要的东西可以被优先加载完。
Server Push：服务端能够更快的把资源推送给客户端。例如服务端可以主动把 JS 和 CSS 文件推送给客户端，而不需要客户端解析 HTML 再发送这些请求。当客户端需要的时候，它已经在客户端了。

索引下推优化是MySQL5.6版本中新加的功能。
索引条件下推优化：Index Condition Pushdown Optimization是MySQL使用索引从表中检索行的情况的优化。如果没有ICP，存储引擎会遍历索引以查找表中的行，并将它们返回给MySQL服务器，由server层再做一波筛选。启用ICP后，如果只使用索引中的列来评估where条件的某些部分，MySQL服务器会将where条件推送到存储引擎。然后，存储引擎使用索引条目评估推送的索引条件，并且仅当满足该条件时才从表中读取行。
ICP可以减少存储引擎必须访问基表的次数以及MySQL服务器必须访问存储引擎的次数。
ICP的适用性受以下条件限制：
	1. 当需要访问全表行时，ICP用于range, ref, eq_ref和ref_or_null访问方法。
	2. ICP可用于InnoDB和MyISM表。(MySQL5.6中的分区表不支持ICP；MySQL5.7解决了这个问题)
	3. 对于InnoDB表，ICP仅用于二级索引。ICP的目标是减少全行读取的数量，从而减少IO操作。对于InnoDB聚簇索引，完整记录已经读入InnoDB缓冲区，这种情况下使用ICP，不会降低IO。
	4. 引用子查询的条件无法下推。
	5. 无法下推涉及存储函数的条件。存储引擎无法调用存储的函数。
	6. 触发条件无法下推。
默认情况下，启用索引条件下推。可以用optimizer_switch系统变量设置index_condition_pushdown设置
set optimizer_swith = "index_condition_pushdown=on/off";
EXPLAIN时，使用ICP的查询会在Extra列出现 Using index condition关键字

MySQL5.6对索引做了哪些优化:
	1. MRR: Mulit-Range Read Optimization;
	2. ICP: Index Condition Pushdown Optimization(索引下推)
	3. 覆盖索引
	4. BKA(Batched Key Access)
-----------------------
MRR是优化器将随机IO转化为顺序IO，以降低IO开销的手段。
二级索引中存储的是索引列和主键值，当查询列不都存在与索引列中时（即不是覆盖索引的情况），需要回表操作。然而回表获取完整用户记录可能回产生随机IO（当数据量较多且比较分散时，随机IO性能较低），为减少这种随机IO，MySQL首先只在二级索引中查询，统计关联行的主键，然后根据主键值排序， 最后从聚簇索引中按照主键排序获取完整记录。

使用 MRR 时的查询过程：
	1. 优化器将从二级索引中查询到的记录放到缓冲区中；
	2. 如果缓冲区已满，或者扫描到二级索引文件末尾，使用快排对缓冲区的数据按照主键排序；
	3. 用户线程根据缓冲区的内容，从聚簇索引中获取数据；
	3. 当缓冲区内容读取完毕时，重复上述过程，直到扫描结束
如何查看一条SQL是不是MRR呢？我们EXPLAIN执行一条SQL时，使用MRR的查询会在Extra列出现Using MRR关键字。
用optimizer_switch变量控制是否开启MRR，默认是开启的，关闭的话set optimizer_switch = 'mrr=off'
MRR优化的几个好处：
	1. 使数据访问由随机变为顺序访问，查询辅助索引时，首先把查询结果按照主键进行排序，按照主键顺序进行回表查找；
	2. 减少缓冲池中页被替换的次数；
	3. 批量处理对键值的操作。
-----------------------
where条件可以分为三大类：Index Key(First Key, Last Key)，Index Filter以及Table Filter。
----------------------------------
HTTP/2的特点/优势：
	1. 多路复用的单一长连接
		1.1 单一长连接
			在HTTP/2中，客户端向某个域名的服务器请求页面的过程中，只会创建一条TCP连接，即使这页面包含上百个资源。单一的连接应该是HTTP/2的主要优势，单一的连接能减少TCP握手带来的时延。HTTP/2中用单一的长连接，避免了创建多个TCP连接带来的网络开销，提高了吞吐量。
		1.2 多路复用 
			HTTP/2虽然只有一条TCP连接，但是在逻辑上分成了很多stream。
			HTTP/2把要传输的信息分割成一个个二进制帧，首部信息会被封装到Header Frame，相应的request body就放在Data Frame，一个帧把不同的http请求或响应区分开来了。但是，这里要求同一个请求或者响应必须是有序的，要保证FIFO，但是不同的请求或响应帧可以互相穿插。这就是HTTP/2的多路复用，充分利用了网络带宽，提高了并发度。
	2. 头部压缩和二进制格式
		HTTP/1.x一直都是plain text,便于阅读和调试。但是对于HTTPS把plain text变成了二进制，这个优点没有了。
		HTTP/2使用HPACK压缩来压缩头部，减少报文大小。
	3. 服务端推送Server Push 
		主要思想是：当一个客户端请求资源X，而服务器知道它很可能需要资源Z的情况下，服务器可以在客户端发送请求前，主动将资源Z推送给客户端。
----------------------------------
HTTP2， 为解决以上问题而生。
	1. 允许多个request/response在同一个tcp链接上发送
	2. 高效压缩头部（http header）
	3. 二进制协议，真正的多路复用
	4. 还有自己的流量控制，保证各个 stream不被互相干扰；
	5. 支持请求分优先级发送，优先级越高如核心 css、html，优先发给客户端
	6. 支持服务器预测并推送客户端可能需要的资源，让客户端先做缓存（server push），榨干服务器
	7. 兼容 HTTP1.1 的语义，尽可能一致。
-----------------------------------
HTTP/2的Stream有流量控制功能，HTTP/2的接收方通过WINDOW_UPDATE帧告诉对方字节准备接收多少字节的数量，注意只有DATA帧才会受限制，因为其他帧都不大，而且也比较重要。

Netty高性能的原因：
	1. 基于IO多路复用模型；
	2. 零拷贝；
	3. 基于NIO的Buffer;
	4. 基于内存池的缓冲区重用机制；
	5. 无锁化的串行设计理念；
	6. IO操作的异步处理；
	7. 提供对protobuf等高性能序列化协议支持；
	8. 支持对TCP进行更加灵活的配置。

Netty中的零拷贝与操作系统层面上的零拷贝不完全一样，Netty的零拷贝完全是在用户态(Java层面)的，更多的是数据操作的优化。Netty的零拷贝主要体现在5方面：
	1. Netty的接收和发送ByteBuf使用直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。如果使用JVM的堆内存进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才写入Socket中。相比于使用直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。
	2. Netty的文件传输调用FileRegion包装的transferTo方法，可以直接将文件缓冲区的数据发送到目标Channel，避免通过循环while方式导致的内存拷贝问题。
	3. Netty提供CompositeByteBuff类，可以将多个ByteBuf合并为一个逻辑上的ByteBuf，避免了各个ByteBuf之间的拷贝。
	4. 通过wrap操作，可以将byte[]数组、ByteBuf、ByteBuffer等包装成一个Netty ByteBuf对象，进而避免拷贝操作。
	5. ByteBuf支持slice操作，可以将ByteBuf分解为多个分享同一个存储区域的ByteBuf，避免内存的拷贝。
----------------------------------
Batched Key Access(BKA)和Block Netsted-Loop(BNL)
Batched Key Access(BKA)提高表join性能的算法。当被join的表能够使用索引时，就先排好序，然后再去检索被join的表，和MRR类似，实际上MRR也可以想象成二级索引和primary key的join，如果被join的表上没有索引，则使用老版本的的BNL策略(Block Netsted-Loop)。

BKA原理
	对于多表join语句，当MySQL使用索引访问第二个join表的时候，使用一个join buffer来收集第一操作对象生成的相关列值。BKA构建好key后，批量传给引擎层做索引查找。key是通过MRR接口提交给引擎的(MRR目的是为了顺序)MRR使得查询更有效率。
	大致过程如下：
		1. BKA使用join buffer保存由join的第一个操作产生的符合条件的数据；
		2. 然后BKA算法构建key来访问被连接的表，并批量使用MRR接口提交keys到数据库存储引擎去查找；
		3. 提交keys之后，MRR使用最佳的方式来获取行并反馈给BKA。
BNL和BKA都是批量的提交一部分行给被join的表，从而减少访问的次数，它们之间的区别如下：
	1. BNL比BKA出现的早，BKA直到5.6才出现，而BNL在5.1就存在；
	2. BNL主要用于当被join的表上无索引；
	3. BKA主要是指被join表上有索引可以利用，那么就在行提交给被join的表之前，对这些行按照索引字段进行排序，因此减少了随机IO，排序才是两者最大的区别，但是如果被join的表没有索引，就使用BNL。
Using join buffer(Batched Key Access)和Using join buffer(Block Nested Loop)
相关参数：
	BAK使用了MRR,要想使用BAK必须打开MRR功能，而MRR基于mrr_cost_based的成本估算并不能包装总是使用MRR，官方推荐设置mrr_cost_based=off来总是开启MRR功能。打开BAK功能：
	set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
	BKA使用join buffer size来确定buffer的大小，buffer越大，访问被join的表/内部表就越顺序。
	BNL默认是开启的，设置BNL相关参数：
		set optimizer_switch='block_nested_loop';
支持inner join, outer join, semi-join operations, including nested outer joins.
BKA主要适用于join的表上有索引可利用，无索引只能使用BNL。 