从生效入口开始看，@EnableAsync注解上标注了@Import(AsyncConfigurationSelector.class)
@Import的作用是把后面的@Configuration类、ImportSelector类或者ImportBeanDefinitionRegistrar类中import的内容自动注册到ApplicationContext中。
对于@Async：上面注册进去的advisor类型是AsyncAnnotationAdvisor。其中包括了PointCut, 类型是AnnotationMatchingPointcut，指定了只有@Async标记的方法或者此AOP增强器才生效。还有一个Advice，用于增强@Async标记的方法，转换为异步，类型是AnnotationAsyncExecutionInterceptor，其中的invoke方法是真正调用真实方法的地方。
DynamicAdvisedInterceptor
------------------------------
解决this调用的几个替代方法：
	1. 通过ApplicationContext来获得动态代理对象；
	2. 通过AopContext获取动态代理对象(前提是exposeProxy为true)；
	3. 对于exposeProxy为false时，在某个切入时机，手动执行AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry)静态方法，前提是有一个BeanDefinitionRegistry，且时机要在BeanDefinition已经创建且动态代理对象还没有生成时调用；
	4. 手动修改各种BeanPostProcessor的属性。以@Async为例，其通过AsyncAnnotationBeanPostProcessor来生成动态代理类，只要在合适时机即该BPP已创建，但是还未被使用时，修改其中的exposeProxy属性，使用AsyncAnnotationBeanPostProcessor.setExposeProxy(true)即可。
------------------------------
/* Enhance #Configuration classes by generating a CGLIB subclass which interacts with 
	the Spring container to respect bean scoping semantics for @Bean methods. Each such 
	@Bean method will be overridden in the generated subclass, only delegating to the 
	actual @Bean method implementation if the container actually requests the construction 
	of a new instance. Otherwise, a call to such an @Bean method servs as a reference back 
	to the container, obtaining the corresponding bean by name. 
*/
class ConfigurationClassEnhancer {
	...
}
/* BeanFactoryPostProcessor used for bootstrapping processing of @Configuration classes.
	Registered by default when using <context:annotation-config/> or <context:component-scan/>.
	Otherwise, may be declared manually as with any other BeanFactoryPostProcessor.
	This post processor is priority-ordered as it is important that any #Bean methods declared in @Configuration classes have their corresponding bean definitions registered before any other BeanFactoryPostProcessor executes.
*/
public class ConfigurationClassPostProcesser implements BeanDefinitionRegistryPostProcessor,
	PriorityOrdered, ResourceLoaderAware, BeanClassLoaderAware, EnvironmentAware {
	...
}

更新缓存的Design Pattern有四种：Cache aside, Read through, Write through, Write behind caching。
-------------------------------------------------
双1和binlog,redolog的完整性
binlog的写入机制
当一个事务执行，先把日志写到binlog cache，事务提交的时候，其实是redo log prepare/commit的时候，再把binlog cache写到binlog 文件中，清空binlog cache。
如果当binlog的size大于binlog_cache_size的时候，就要从内存中写入到磁盘上。
从内存binlog cache写入磁盘分为两个动作， 即binlog写入page cache还是持久化到磁盘分别在write和fsync先后进行。控制这两个动作的发生的是一个叫sync_binlog的参数：
	如果参数为0，那么只write ；
	如果参数为1 ，那么只fsync ；
	如果参数为 N(N>1) 那么，write到了N才会fsync；
一般这个值被设置为100-1000，既可以较快的处理，减少IO次数，也可以一定程度的防止实际业务中丢失数据的可能性（除非主机掉电）。
redo log写入机制
redo log同样是有三种存储状态和存储媒介：
	1. redo log buffer：MySQL进程内存
	2. 写磁盘write：文件系统page cache
	3. 持久化磁盘fsync：硬盘
控制参数innodb_flush_log_at_trx_commit：
	0:事务提交，写入binlog的时机，redo log是留在redo log buffer中；
	1:事务提交，redo log持久化到磁盘
	2:事务提交，redo log写入page cache

Redo log持久化到磁盘的几个场景：
InnoDb引擎每秒会把redo log buffer的日志，写到文件系统的page cache，再fsync
redo log size >= redo_log_buffer_size ，会写盘page cache
innodb_flush_log_at_trx_commit 1会并行的把redo log fsync
双1 ：sync_binlog 和 innodb_flush_log_at_trx_commit都设置为1 。通过上面的介绍，我们已经知道，在一个事务提交之前，会进行两次刷盘，一次刷盘（fsync）是binlog ，一次是redo log的prepare 阶段。

主从延迟：
	1. 主备机器性能不一致，往往备库会比主库机器配置差
		Solve：对称部署
	2. 备库上随意的无压力控制的操作，影响同步操作
		Solve：一主多从、统计类查询交给Hadoop 、Elastic等系统处理，从库更多解决的是A高可用，高并发的问题，并不适合在Mysql底层完全解决。
	3. 大事务运行，从主从一致性的原理主从同步流程看到，一个事务在主库执行完成才会写入binlog ，传递给Slave ，Slave写入relay log，最后写入从库，如果这个事务有10分钟，从库至少延迟10分钟

解决/优化主从延迟
	可以把Slave的双1关闭，innodb_flush_log_at_trx_commit和sync_binlog ，这样binlog不会fsync
	第二种思路就是减少从库查询负载，有两种办法，0：增加Slave服务器 1:Slavel只作为备份
可以看到Slave 的优化和高并发的情况是存在一些冲突的，一个是减少查询，一个是增加查询，个人觉得Slave在请求并发很高的时候，可以考虑转向分布式缓存，例如redis等，这肯定是比单纯数据库能扛住更大的压力的。
--------------------------------------------------
public class CompletableFuture<T> implements Future<T>, CompletionStage<T> {
	...
}
在JDK8中，CompletableFuture提供了非常强大的Future的扩展功能，可以简化异步编程的复杂性，并且提供了函数式编程的能力，可以通过回调的方式处理计算结果，也提供了转换和组合CompletableFuture的方法。
它能代表一个明确完成的Future，也可能代表一个完成阶段(CompletionStage)，它支持在计算完成以后触发一些函数或执行某些动作。它实现了Future和CompletionStage接口。
------------------------------------------------
redis-cluster的缺点/限制条件：
Client实现复杂，驱动要求实现Smart Client，缓存slots mapping信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅JedisCluster相对成熟，异常处理部分还不完善，比如常见的"max redirect exception"。
节点会因为某些原因发生阻塞(阻塞时间大于cluster-node-timeout)，被判断下线，这种failover是没有必要的。
数据通过异步复制，不保证数据的强一致性。
多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现互相影响的情况。
Slave在集群中充当冷备，不能缓解读压力，当然可以通过SDK的合理设计来提高Slave资源的利用率。
Key批量操作限制，如使用mset,mget目前只支持具有相同slot值的key执行批量操作。对于映射为不同slot值的key由于keys不支持跨slot查询，所以执行mset,mget,sunion等操作支持不友好。
key事务操作支持有限，只支持key在同一个节点上的事务操作，当多个key分布于不同的节点上时无法使用事务功能。
key作为数据分区的最小粒度，不能将一个很大的键值对对象如hash,list等映射到不同的节点。
不支持多数据库空间，单机下的redis可以支持16个数据库，集群模式下只能使用1个数据库空间，即db0。
复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。
避免产生hot-key，导致主库节点称为系统短板。
避免产生big-key，导致网卡撑爆、慢查询等。
重试时间应大于cluster-node-time时间。
Redis Cluster不建议使用pipeline和multi-key操作，减少max redirect产生的场景。
------------------------------------------------
Kafka在高并发情况下，如何避免消息丢失和消息重复：
消息丢失解决方案：首先对Kafka进行限速，其次启用重试机制，重试间隔时间设置长一些，最后Kafka设置acks=all，即需要ISR分区都确认收到消息后，才算发送成功。
消息重复解决方案：消息使用唯一ID标识；生产者ack=all；消费者offset手动提交，业务成功后，提交offset；落表；业务逻辑处理(选择唯一主键存储到Redis或者MongoDB中，先查询是否存在，若存在则不处理；若不存在，先插入Redis/MongoDB，再进行业务处理)；
------------------------------------------------
实际上，leader选举的算法非常多，比如Zookeeper的Zab, Raft和ViewStamped Replication，而Kafka所使用的leader选举算法更像是微软的PacificA算法。

幂等性时，Producer的发送流程如下：
	1. 调用KafkaProducer的send方法将数据添加到RecordAccumulator中，添加时会判断是否需要新建一个ProducerBatch,这时这个ProducerBatch还是没有PID和sequence number信息的；
	2. Producer后台发送线程Sender，在run()方法中，会先根据TransactionManager的shouldResetProducerStateAfterResolvingSequences()方法判断当前的PID是否需要重置，重置的原因是因为：如果有topic-partition的batch已经超时还没有处理完，此时可能会造成sequence number不连续。因为sequence number有部分已经分配出去了，而kafka服务端没有收到这部分sequence number的序号，kafka服务端为了保证幂等性，只会接受同一个PID的sequence number等于服务器缓存sequence number+1的消息，所以这时候需要重置PID来保证幂等性。
	3. Sender线程调用maybeWaitForProducerId()方法判断是否要申请PID，如果需要，会阻塞直到成功申请到PID。
	4. 最后调用sendProduceRequest方法将消息发送出去。

Kafka实现幂等性的类：
KafkaProducer, RecordAccumulator, Sender,TransactionManager, ProducerIdAndEpoch, ProducerBatch,BatchMetadata,ProducerStateEntry,ProducerAppendInfo,ProducerStateManager,

Future模式的缺点：Future虽然可以实现获取异步执行结果的需求，但是它没有提供通知的机制，无法得知Future什么时候完成。要么使用阻塞，在Future.get()地方等待future返回结果，这时又变成了同步操作。要么使用isDone(0轮询判断Future是否完成，这样会耗费CPU的资源。

Netty,Guava分别扩展了Java的Future接口，方便异步编程。
JDK8新增的CompletableFuture类正是吸收了所有Google Guava中ListenableFuture和SettableFuture的特征，还提供了其他强大的功能，让Java拥有了完整的非阻塞编程模型：Future, Promise和Callback(在JDK8之前，只要无Callback的Future).
CompletableFuture能够将回调放在与任务不同的线程中执行，也能将回调作为继续执行的同步函数，在与任务相同的线程中执行。它避免了传统回调最大的问题，那就是能够将控制流分离到不同的事件处理器中。
CompletableFuture弥补了Future模式的缺点。在异步的任务完成后，需要用其结果继续操作时，无需等待。可以直接通过thenAccept, thenApply, thenCompose等方式将前面异步处理的结果交给另外一个异步事件处理线程来处理。
--------------------------------------------
双亲委派模型破坏史：
第一次破坏：由于双亲委派模型是在JDK1.2之后才被引入的，而类加载器和抽象类java.lang.ClassLoader则在JDK1.0时代就已经存在，面对已经存在的用户自定义类加载器的实现代码，Java设计者引入双亲委派模型时不得不做出一些妥协。在此之前，用户去继承java.lang.ClassLoader的唯一目的就是为了重新loadClass()方法，因为虚拟机在进行类加载的时候会调用加载器的私有方法loadClassInternal()，而这个方法唯一逻辑就是去调用自己的loadClass()。
第二次破坏：双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷所导致的，双亲委派很好地解决了各个类加载器的基础类的同一问题（越基础的类由越上层的加载器进行加载），基础类之所以称为“基础”，是因为它们总是作为被用户代码调用的API，但世事往往没有绝对的完美。
如果基础类又要调用用户的代码，怎么办？一个典型的例子是JNDI服务。
有了线程上下文加载器，JNDI服务就可以使用它去加载所需要的SPI代码，也就是父类加载器请求子类加载器去完成类加载的动作，这种行为实际上就是打通了双亲委派模型层次结构来逆向使用类加载器，实际上已经违背了双亲委派模型的一般性原则，但这也是无可奈何的事情。Java中所有涉及SPI的加载动作基本上都采用这种方式，例如JNDI、JDBC、JCE、JAXB和JBI等。
第三次破坏：双亲委派的第三次被破坏是由于用户对程序动态性的追求导致的，这里所说的动态性是指：代码热替换、模块热部署等。
--------------------------------------------
BASE理论主要是解决CAP理论中分布式系统的可用性和一致性不可兼得的问题。BASE理论包括以下三个要素：
BA: Basically Available, 基本可用
S：Soft State，软状态，状态可以有一段时间不同步
E：Eventually Consistent,最终一致，最终数据是一致的就可以了，而不是实时保持强一致。
BASE模型与ACID不同，满足CAP理论，通过牺牲强一致性来保证系统可用性。

2PC的缺点：
	1. TM通过XA接口与RM之间进行数据交互，从第一阶段的准备阶段，业务所涉及的数据就被锁定，并且锁定跨越整个提交流程。在高并发和涉及业务模块较多的情况下对数据库的性能影响较大。
	2. 二阶段是反伸缩模式的，业务规模越大，涉及模块越多，局限性越大，系统可伸缩越差。
	3. 在技术栈比较杂的分布式应用中，存储组件有很多不支持XA协议。

可靠消息最终一致性
消息状态确认：可靠消息服务定时监听消息的状态，如果存在状态为待确认并且超时的消息，则表示上游应用和可靠消息交互出现异常。此时，可靠消息则携带消息体内的信息向上游应用发起请求查询该业务是否已执行。上游应用提供一个可查询接口供可靠消息追溯业务执行状态，如果业务执行成功则更改消息状态为已发送，否则删除此消息确保数据一致性。
通过消息状态确认和消息重发两个功能，可以确保上游应用、可靠消息和下游应用数据的最终一致性。
实际接入过程中，需要引入人工干预功能。比如引入重发次数限制、超过重发次数的消息发送到死信队列，等待人工干预。

最大努力通知模式

Guava中的RateLimiter的两种模式: SmoothBursty和SmoothWarmingUp。
GateLimiter基于漏桶算法，但它参考了令牌桶算法。

Semaphore用来控制同时访问某个资源的并发数量。而RateLimiter是用来控制访问资源的速率(rate)，它强调的是控制速率。比如每秒只能有100个请求通过，比如允许每秒发送1MB的数据。它的构造方法指定一个permitPerSecond参数，代表每秒钟产生多少个permits。RatLimiter允许预占未来的令牌，比如每秒产生5个permits,可以单次请求100个，这样紧接着的下一个请求需要等待大概20秒才能获取到permits。
SmoothBursty可以处理突发请求，因为它会缓存最多1秒的permits，而SmoothWarmingUp是完全不同的设计。
SmoothWarmingUp适用于资源需要预热的场景，比如某个接口业务，需要使用到数据库连接，由于连接需要预热才能进入到最佳状态，如果系统长时间处于低负载或零负载状态，当然，应用刚启动也是一样的），连接池中的连接慢慢释放掉了，此时我们认为连接池是冷的。

当调用线程的interrupt方法，有两个作用：
	1. 如果此线程处于阻塞状态(比如调用了wait,io等待)，则会马上退出阻塞，并抛出InterruptedException异常，线程可以通过捕获InterruptedException来做一定的处理，然后让线程退出。
	2. 如果此线程处于运行之中，则线程不受任何影响，继续运行。仅仅是线程的中断标记为true。所以线程要在适当的位置通过调用isInterrupted方法来查看是否被中断，并做退出操作。
--------------------------------------------------------------
高并发下如何投递消息才能不丢失：
在生产端高并发写入MQ的场景下，会面临两个问题：
1、你每次写一条消息到MQ，为了等待这条消息的ack，必须把消息保存到一个存储里。
并且这个存储不建议是内存，因为高并发下消息是很多的，每秒可能都几千甚至上万的消息投递出去，消息的ack要等几百毫秒的话，放内存可能有内存溢出的风险。
2、绝对不能以同步写消息 + 等待ack的方式来投递，那样会导致每次投递一个消息都同步阻塞等待几百毫秒，会导致投递性能和吞吐量大幅度下降。

针对这两个问题，相对应的方案其实也呼之欲出了。
首先，用来临时存放未ack消息的存储需要承载高并发写入，而且我们不需要什么复杂的运算操作，这种存储首选绝对不是MySQL之类的数据库，而建议采用kv存储。kv存储承载高并发能力极强，而且kv操作性能很高。
其次，投递消息之后等待ack的过程必须是异步的，也就是类似上面那样的代码，已经给出了一个初步的异步回调的方式。
消息投递出去之后，这个投递的线程其实就可以返回了，至于每个消息的异步回调，是通过在channel注册一个confirm监听器实现的。
收到一个消息ack之后，就从kv存储中删除这条临时消息；收到一个消息nack之后，就从kv存储提取这条消息然后重新投递一次即可；也可以自己对kv存储里的消息做监控，如果超过一定时长没收到ack，就主动重发消息。
--------------------------------------------------------------
可靠事件通知模式
	- 同步事件
	- 异步事件
		- 本地事件服务
		- 外部事件服务

事件服务(此处指消息服务)与业务服务过于耦合，如果消息服务不可用，会导致业务不可用。应该 将事件服务与业务解耦，独立出来异步执行，或者在业务执行后先尝试发送一次消息，如果消息发送失败，则降级为异步发送。
--------------------------------------------------------------
Redis中的底层编码quicklist:
ziplist是整个Redis中为了节省内存，而quicklist是更高级的数据结构。是在Redis3.2版本之后新加的，在3.2版本之前dict是最复杂的底层数据，而3.2版本之后quicklist是非常复杂的。
以ziplist为节点的，双端链表结构。宏观上，quicklist是一个链表，微观上，链表中的每个节点都是一个ziplist。
quicklist有自己的优点，也有缺点，对于使用者来说，其使用体验类似于线性数据结构，list作为最传统的双链表，节点通过指针持有数据，指针字段会耗费大量内存。ziplist解决了耗费内存这个问题，但引入了新问题：每次写操作整个ziplist的内存都需要重分配。quicklist在两者之间做了一个平衡，并且使用者可以通过自定义quicklist.fill，根据实际业务情况，调优。

Redis中的zipmap:dict作为字典结构, 优点很多, 扩展性强悍, 支持平滑扩容等等, 但对于字典中的键值均为二进制数据, 且长度都很小时, dict的中的一坨指针会浪费不少内存, 因此Redis又实现了一个轻量级的字典, 即为zipmap.

Note PriorityQueue is not synchronized. Multiple threads should not access a PriorityQueu instance concurrently if any of the threads modifies the queue. Instead, use the thread-safe java.util.concurrent.PriorityBlockingQueue class. 

WebSocket的优点：
	1. 较少的控制开销。在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小。在不包含扩展的情况下，对于服务器到客户端的内容，此头部大小只有2至10字节（和数据包长度有关）；对于客户端到服务器的内容，此头部还需要加上额外的4字节的掩码。相对于HTTP请求每次都要携带完整的头部，此项开销显著减少了。
	2. 更强的实时性。由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少；即使是和Comet等类似的长轮询比较，其也能在短时间内更多次地传递数据。
	3. 保持连接状态。与HTTP不同的是，Websocket需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。而HTTP请求可能需要在每个请求都携带状态信息（如身份认证等）。
	4. 更好的二进制支持。Websocket定义了二进制帧，相对HTTP，可以更轻松地处理二进制内容。
	5. 可以支持扩展。Websocket定义了扩展，用户可以扩展协议、实现部分自定义的子协议。如部分浏览器支持压缩等。
	6. 更好的压缩效果。相对于HTTP压缩，Websocket在适当的扩展支持下，可以沿用之前内容的上下文，在传递类似的数据时，可以显著地提高压缩率。
	7. 没有同源限制，客户端可以与任意服务器通信。
	8. 协议标识符是ws(如果加密是wss)，请求的地址就是后端支持websocket的API。

DMA是指外部设备不通过CPU而直接与系统内存交换数据的接口及时。要把外设的数据读入内存或把内存的数据传送到外设，一般都要通过CPU控制完成，如CPU程序查询或中断方式。利用中断进行数据传送，可以大大提高CPU的利用率。但是采用中断传送有它的缺点，对于一个高速IO设备，以及批量交换数据的情况，只能采用DMA方式，才能解决效率和速度问题。DMA在外设与内存间直接进行数据交换，而不通过CPU，这样数据传送的速度就取决于存储器和外设的工作速度。

在RocketMQ中生产者有三种角色NormalProducer(普通)、OrderProducer(顺序)、TransactionProducer(事务)
Resilence4J提供了一系列增强微服务的可用性功能：
	1. 断路器
	2. 限流
	3. 基于信号量的隔离
	4. 缓存 
	5. 限时
	6. 请求重试
	
对于Kafka的多集群同步方案：
	1. 社区MirrorMaker:好处是社区自带，不过MirrorMaker运维成本很高，特别是主题的管理非常不便捷，同时很难实现管道化(pipelining)。
	2. Uber的uReplicator:针对MirrorMaker弊端自研的多集群同步方案。
	3. Confluent公司的Replicator:需要使用Confluent Kafka，而且是收费的。Replicator是目前宣称的最强大的Kafka多集群(甚至多DC)同步方案。
	4. 社区MirrorMaker2：社区针对MirrorMaker研发的新版MirrorMaker。目前在开发中，要在Kafka2.4完成。

Kafka多集群高可用的客户端方案：建立两个Kafka集群，不用同步，封装一个框架，生产者发双发，消费者双读，自动去重，是比较稳定的高可用方案。

WebSocket是一种通信协议，可在单个TCP连接上进行全双工通信。WebSocket使得客户端和服务器之间的数据交换变得更加简单，运行服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者就可以建立持久性的连接，并进行双向数据传输。

RocketMQ分布式事务的每个阶段：
	1. 生产者向MQ服务器发送half消息。
	2. half消息发送成功后，MQ服务器返回确认消息给生产者。
	3. 生产者开始执行本地事务。
	4. 根据本地事务执行结果(unknow, commit, rollback)向MQ Server发送提交或回滚消息。
	5. 如果错过了(可能因为网络异常、生产者突然宕机等异常情况)提交/回滚消息，则MQ服务器将同一组中的每个生产者发送回查消息以获取事务状态。
	6. 回查生产者本地事务状态。
	7. 生产者根据本地事务状态发送提交/回滚消息。
	8. MQ服务器将丢弃回滚的消息，但已提交(进行过二次确认的half消息)的消息将投递给消费者进行消费。
从上述流程可以知道，RocketMQ事务消息其实只是保证了生产者本地事务和发送消息的原子性
消费者在消费事务消息时，broker处理事务消息的消费与普通消息是一样的，若消费不成功，则broker会重复投递该消息16次，若仍然不成功则需要人工介入。

DMA，全称叫Direct Memory Access，一种可让某些硬件子系统去直接访问系统主内存，而不用依赖CPU的计算机系统的功能。听着是不是很厉害，跳过CPU，直接访问主内存。传统的内存访问都需要通过CPU的调度来完成。

传统的文件传输有多次用户态和内核态之间的切换，而且文件在多个buffer之间要复制多次最终才被发送到网卡。
DMA是一种硬件直接访问系统主内存的技术。
多种硬件都已使用了DMA技术，其中就包括网卡（NIC）。
DMA技术让CPU得到解放，让CPU可以不用一直守着来完成文件传输。
零拷贝技术减少了用户态与内核态之间的切换，让拷贝次数降到最低，从而实现高性能。
Kafka使用零拷贝技术来进行文件的传输。

@Configuration
@EnableWebMvc
@EnableWebSocket
public class SpringWebSocketConfig extends WebMvcConfigurerAdapter implements WebSocketConfigurer {
	...
}

HttpSessionHandshakeInterceptor
Kafka使用磁盘速度快的原因：
	1. 顺序读写；
	2. 零拷贝；
	3. mmap文件映射；

MappedByteBuffer, FileChannel.transferTo(),
PriorityQueue通过二叉小顶堆实现。PriorityQueue实现了Queue接口，不允许放入null元素；

Leader Epoch与高水位
正是有与Kafka复制协议分为两个阶段，导致使用高水位HW会出现数据丢失和数据不一致的问题。
数据丢失:High Watermark truncation followed by immediate Leader Election.
数据不一致：Replica divergence on restart after multiple hard failures.

Resilience4j provides higher-order functions(decorators) to enhance any functional interface, lambda expression or method reference with a Circuit Breaker, Rate Limiter, Retry or Bulkhend. You can stack more than one decorator on any functional interface, lambda expression or method reference. The advantege is that you have the choice to select the decorators you need and nothing else. 

Resilience4j provides several core modules:
	resilience4j-circuitbreaker: Circuit breaking
	resilience4j-ratelimiter: Rate limiting
	resilience4j-bulkhead: Bulkheading
	resilience4j-retry: Automatic retrying (sync and async)
	resilience4j-timelimiter: Timeout handling
	resilience4j-cache: Result caching
当新的 controller 当选时，会触发 KafkaController.onControllerFailover 方法，在该方法中完成如下操作：
1、 读取并增加Controller Epoch。 
2、 在reassignedPartitions Patch(/admin/reassign_partitions)上注册watcher。 
3、 在preferredReplicaElection Path(/admin/preferred_replica_election)上注册watcher。 
4、 通过partitionStateMachine在broker Topics Patch(/brokers/topics)上注册watcher。 
5、 若delete.topic.enable=true（默认值是 false），则partitionStateMachine在Delete Topic Patch(/admin/delete_topics)上注册watcher。 
6、 通过replicaStateMachine在Broker Ids Patch(/brokers/ids)上注册Watch。 
7、 初始化ControllerContext对象，设置当前所有topic，“活”着的broker列表，所有partition的 leader及ISR等。 
8、 启动replicaStateMachine和partitionStateMachine。 
9、 将brokerState状态设置为RunningAsController。 
10、 将每个partition的Leadership信息发送给所有“活”着的broker。 
11、 若auto.leader.rebalance.enable=true（默认值是true），则启动partition-rebalance线程。 
12、 若delete.topic.enable=true 且Delete Topic Patch(/admin/delete_topics)中有值，则删除相应的Topic。

实现一个分布式消息中间件，整体架构如何设计实现
	1. 分布式事务；
	2. 延迟功能；
	3. 高可用：多副本；
	4. 高并发：内存/分片；
	5. 持久化：存储；
	6. 清理机制：过期数据的清理；
	7. 协议：通信协议和存储协议；
	8. 一致性协议：依赖中间件/自己实现；
	9. 元数据；
	10. 线程模型；
	11. 监控机制:消息积压/磁盘空间等
	12. 微内核+插件化；

kafka碰到的问题
	1. 重复消费;
	2. 不支持分布式事务；
	3. 不支持延迟队列；
	4. 原生不支持Json序列化；
--------------------------------------------
两种IO多路复用模式：Reactor和Proactor
一般地，IO多路复用机制都依赖于一个事件多路分离器(Event Demultiplexer)。分离器对象可将来自事件源的IO事件分离出来，并分发到对应的read/write事件处理器(Event Handler)。开发人员预先注册需要处理的事件及其事件处理器(或回调函数)；事件处理器将请求事件传递给事件处理器。
两个事件分离器有关的模式是Reactor和Proactor。Reactor模式采用同步IO，而Proactor采用异步IO

在Reactor中，事件分离器负责等待文件描述符或socket为读写操作准备就绪，然后将就绪事件传递给对应的处理器，最后由处理器负责完成实际的读写工作。
而在Proactor模式中，处理器-或者兼任处理器的事件分离器，只负责发起读写操作。IO操作本身由操作系统来完成。传递给操作系统的参数需要包括用户定义的数据缓冲区地址和数据大小，操作系统才能从中得到写出操作所需数据，或写入从socket读到的数据。事件分离器捕获IO操作完成事件，然后将事件传递给对应处理器。比如，在windows上，处理器发起一个异步IO操作，再由事件分离器等待IOCompletion事件。典型的异步模式实现，都建立在操作系统支持异步API的基础之上，将这种实现称为系统级异步或真异步，因此应用程序完全依赖操作系统执行真正的IO工作。
两个模式的相同点，都是对某个IO事件的事件通知(即告诉某个模块，这个IO操作可以进行或完成)。在结构上，两者也有相同点：demultiplexor负责提交IO操作(异步)、查询设备是否可操作(同步)，然后当条件满足时，就回调handler；不同点在于，异步情况下(proactor)，当回调handler时，表示IO操作已经完成；同步情况下(Reactor)，回调handler时，表示IO设备可以进行某个操作(可读/可写)。
使用Proactor框架和Reactor框架都可以极大的简化网络应用的开发，但它们的重点却不同。Reactor框架中用户定义的操作是在实际操作之前调用的。比如你定义了操作是要向一个SOCKET写数据，那么当该SOCKET可以接收数据的时候，你的操作就会被调用；而Proactor框架中用户定义的操作是在实际操作之后调用的。比如你定义了一个操作要显示从SOCKET中读入的数据，那么当读操作完成以后，你的操作才会被调用。Proactor和Reactor都是并发编程中的设计模式。在我看来，他们都是用于派发/分离IO操作事件的。这里所谓的IO事件也就是诸如read/write的IO操作。"派发/分离"就是将单独的IO事件通知到上层模块。两个模式不同的地方在于，Proactor用于异步IO，而Reactor用于同步IO。
支持Proactor: boost, iocp
--------------------------------------------
MyISAM和Memory存储引擎采用的是表级锁，BDB存储引擎采用的是页面锁，但也支持表级锁。InnoDB存储引擎支持行级锁，也支持表级锁，但默认情况下是采用行级锁。
页面锁：开销和加锁时间介于表锁和行锁之间，会出现死锁；锁粒度介于表锁和行锁之间，并发度一般。

Epoll网络架构模型解决了c10k问题
C10K:单机1万个并发连接问题。
Epoll就成为C10K killer、高并发、高性能、异步非阻塞这些技术的代名词了。FreeBSD推出了kqueue，Linux推出了epoll，Windows推出了IOCP，Solaris推出了/dev/poll。这些操作系统提供的功能就是为了解决C10K问题。epoll技术的编程模型就是异步非阻塞回调，也可以叫做Reactor，事件驱动，事件轮循（EventLoop）。Nginx，libevent，node.js这些就是Epoll时代的产物。
由于epoll, kqueue, IOCP每个接口都有自己的特点，程序移植非常困难，于是需要对这些接口进行封装，以让它们易于使用和移植，其中libevent库就是其中之一。跨平台，封装底层平台的调用，提供统一的 API，但底层在不同平台上自动选择合适的调用。按照libevent的官方网站，libevent库提供了以下功能：当一个文件描述符的特定事件（如可读，可写或出错）发生了，或一个定时事件发生了，libevent就会自动执行用户指定的回调函数，来处理事件。目前，libevent已支持以下接口/dev/poll, kqueue, event ports, select, poll 和 epoll。Libevent的内部事件机制完全是基于所使用的接口的。因此libevent非常容易移植，也使它的扩展性非常容易。目前，libevent已在以下操作系统中编译通过：Linux，BSD，Mac OS X，Solaris和Windows。使用libevent库进行开发非常简单，也很容易在各种unix平台上移植。


MyISAM存储引擎:在用lock tables给表显式加表锁时，必须同时取得所有涉及到表的锁，并且MySQL不支持锁升级。也就是说，在执行lock tables后，只能访问显式加锁的这些表，不能访问未加锁的表；同时，如果加的是读锁，那么只能执行查询操作，而不能执行更新操作。其实，在自动加锁的情况下也是一样的，MyISAM总是一次获得SQL语句所需要的全部锁。这正是MyISAM表不会出现死锁的原因。当使用LOCK TABLES时，不仅需要一次锁定用到的所有表，而且，同一个表在SQL语句中出现多少次，就要通过与SQL语句中相同的别名锁定多少次，否则也会出错。

在一定条件下，MyISAM表也支持查询和插入操作的并发进行。 
MyISAM存储引擎有一个系统变量concurrent_insert，专门用以控制其并发插入的行为，其值分别可以为0、1或2。
	1. 当concurrent_insert设置为0时，不允许并发插入。
	2. 当concurrent_insert设置为1时，如果MyISAM表中没有空洞（即表的中间没有被删除的行），MyISAM允许在一个进程读表的同时，另一个进程从表尾插入记录。这也是MySQL的默认设置。
	3. 当concurrent_insert设置为2时，无论MyISAM表中有没有空洞，都允许在表尾并发插入记录。
可以利用MyISAM存储引擎的并发插入特性，来解决应 用中对同一表查询和插入的锁争用。例如，将concurrent_insert系统变量设为2，总是允许并发插入；同时，通过定期在系统空闲时段执行 OPTIMIZE TABLE语句来整理空间碎片，收回因删除记录而产生的中间空洞。
-------------------------------------------------------
MyISAM的锁调度：
MyISAM存储引擎的读锁和写锁是互斥的，读写操作是串行的。一个进程请求某个 MyISAM表的读锁，同时另一个进程也请求同一表的写锁，MySQL如何处理呢？答案是写进程先获得锁。不仅如此，即使读请求先到锁等待队列，写请求后 到，写锁也会插到读锁请求之前！这是因为MySQL认为写请求一般比读请求要重要。这也正是MyISAM表不太适合于有大量更新操作和查询操作应用的原 因，因为，大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。这种情况有时可能会变得非常糟糕！幸好我们可以通过一些设置来调节MyISAM 的调度行为。

	- 通过指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。
	- 通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低。
	- 通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。
虽然上面3种方法都是要么更新优先，要么查询优先，但还是可以用其来解决查询相对重要的应用（如用户登录系统）中，读锁等待严重的问题。 
另外，MySQL也提供了一种折中的办法来调节读写冲突，即给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会。

上面已经讨论了写优先调度机制带来的问题和解决办法。强调一点：一些需要长时间运行的查询操作，也会使写进程“饿死”！因此，应用中应尽量避免出现长时间运行的查询操作，不要总想用一条SELECT语 句来解决问题，因为这种看似巧妙的SQL语句，往往比较复杂，执行时间较长，在可能的情况下可以通过使用中间表等措施对SQL语句做一定的“分解”，使每 一步查询都能在较短时间完成，从而减少锁冲突。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行。
-------------------------------------------------------
当前读：特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。
通过检查InnoDB_row_lock状态变量来分析DB上的行锁的争夺情况:
>show status like 'innodb_row_lock%';
为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB有两种内部使用的意向锁(Intention Locks)，这两种意向锁都是表锁。
意向共享锁IS：事务在给一个数据行加共享锁前必须先取得该表的IS锁。
意向排它锁IX:事务在给一个数据行加排它锁前必须先取得该表的IX锁。
用SELECT ... IN SHARE MODE获得共享锁，主要用在需要数据依存关系时来确认某行记录是否存在，并确保没有人对这个记录进行UPDATE或者DELETE操作。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用SELECT… FOR UPDATE方式获得排他锁。
即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决 定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，检查SQL的执行计划，以确认是否真正使用了索引。
----------------------------------------
1. memory引擎表数据只存放在内存中，插入数据后，文件也只有表结构文件，没有表数据文件，重启后，数据丢失 ，但是表结构还在，表结构文件也还在
2. memory引擎表，一个会话修改了数据，其他会话可以立即看到修改后的数据
3. 要清空memory引擎表，delete、truncate、drop、重启都可以;
4. memory引擎表最大大小受参数max_heap_table_size的限制
5. momory引擎的表，除了这两点，表数据放在内存中、重启后数据丢失，其他一切都和普通表一样。
6. 生产环境不建议使用memory引擎，因为它有两个最大的缺点，其一它只有表锁没有行锁，这样一旦表有更新操作，就会堵塞其他会话对这张表的读写。其二它的数据存放在内存中，一旦在M-S架构中，S从库重启，S从库数据就会丢失，但是M主库数据还在，继而影响主从同步，因为重启后如果收到一条update语句后，主库正常执行，把该语句发送到从库就会报错找不到更新的行，导致主从同步停止。
7. 如果非要用memory引擎的优点，把数据存放在内存中，可以使用memory引擎临时表，正好可以避免上面6的两个缺点。
8. MEMORY默认使用哈希索引。速度比使用B型树索引快。当然如果你想用B型树索引，可以在创建索引时指定。
----------------------------------------
Reactor模型中定义的三种角色：
Reactor：负责监听和分配事件，将I/O事件分派给对应的Handler。新的事件包含连接建立就绪、读就绪、写就绪等。
Acceptor：处理客户端新连接，并分派请求到处理器链中。
Handler：将自身与事件绑定，执行非阻塞读/写任务，完成channel的读入，完成处理业务逻辑后，负责将结果写出channel。可用资源池来管理。
Proactor操作系统支持，Windows下通过IOCP实现了真正的异步 I/O，而在Linux系统下，Linux2.6才引入，并且异步I/O使用epoll实现的，所以还不完善。

双亲委派机制的作用
	1. 防止重复加载同一个类，通过委托父类加载器确保没有加载过，才加载；
	2. 保证核心类库的安全，不被篡改。

java文件编译成.class文件的过程：
	1. 源代码 
	2. 词法分析器
	3. Token流
	4. 语法分析器
	5. 语法树/抽象语法树
	6. 语义分析器
	7. 注解抽象语法树
	8. 字节生成器
	9. JVM字节码 
MyCat:将字典表或者符合字典表的一些表定义为全局表，从另外一方面，很好的解决了数据join的难题。
数据冗余是解决跨分片数据join的一种很好的思路，也是数据切分规划的另外一条重要规则。
MyCat有对全局表的一致性检测。
MyCat目前版本支持跨分片的join，主要实现方式有四种：全局表，ER分片，catletT(人工智能)和ShareJoin, ShareJoin在开发版中支持，前面三种方式1.3.0支持。

redis集群脑裂问题的解决方法：配置文件中存在两个参数：
min-replicas-to-write 3
min-replicas-max-lag 10
min-replicas-to-write表示连接到master的最少slave数量。
min-replicas-max-lag表示slave连接到master的最大延迟时间。
按照上面的配置，要求至少3个slave节点，且数据复制和同步的延迟不能超过10秒，否则的话master就会拒绝写请求，配置了这两个参数之后，如果发生集群脑裂，原先的master节点接收到客户端的写入请求会拒绝，就可以减少数据同步之后的数据丢失。
Redis不保证强一致性。

public interface SmartInitializingSingleton {
	/* Invoked right at the end of the singleton pre-instantiation phase, 
		with a guarantee that all regular singleton beans have been created already.
		ListableBeanFactory#getBeansOfType calls within this method won't trigger 
		side effects during bootstrap. NOTE: This callback won't be triggered for 
		singleton beans lazily initialized on demand after #BeanFacory bootstrap,
		and not for any other bean scope either. Carefully use it for beans with 
		the intended bootstrap semantices only. 
	*/
	void afterSingletonsInstantiated();
}
Spring Cloud Gateway本身集成了限流功能，限流需要使用Redis。其中filters.name=RequestRateLimiter

1. XmlBeanFactory继承AbstractBeanDefinitionReader, 使用ResourceLoader将资源文件路径转换为对应的Resouce文件。
2. 通过DocumentLoader对Resouce文件进行转换，将Resource文件转换为Document。
3. 通过实现接口BeanDefintionDocumentReader的DefaultBeanDefintionDocumentReader类对Document进行解析，并且使用BeanDefinitionParserDelegate对Element进行解析。

BeanDefinitonHolder, GenericBeanDefinition, RootBeanDefintion, BeanDefinitionBuilder, AbstractBeanDefinition,ChildBeanDefintion,BeanDefinitionRegistry,
--------------------------------------------------------
Dubbo并发控制:
在服务消费方设置接口中每个方法并发请求数，通过设置actives参数。
在服务消费方设置接口中的某个方法的并发请求数，通过设置actives参数。
在服务提供方设置接口中每个方法的并发请求数，通过设置executes参数。
在服务提供方设置接口的某个方法的并发请求数，通过设置executes参数。
消费端并发限制：ActiveLimitFilter
服务端并发限制：ExecuteLimitFilter
--------------------------------------------------------
使用表级锁的主要是MyISAM, Memory, CSV等一些非事务型存储引擎；
使用行级锁的主要是InnoDB存储引擎。
使用页级锁的主要是BerkeleyDB存储引擎。
行级锁定不是MySQL自己实现的锁定方式，而是由存储引擎实现的，如InnoDB存储引擎和MySQL的分布式存储引擎NDBCluster等都是实现了行级锁。

SmartInitializingSingleton是spring 4.1中引入的新特效，与InitializingBean的功能类似，都是bean实例化后执行自定义初始化，都是属于spring bean生命周期的增强。但是，SmartInitializingSingleton的定义及触发方式方式上有些区别，它的定义不在当前的bean中（a bean's local construction phase），它是回调接口（针对非lazy单例Bean），回调的操作是由spring事件ContextRefreshedEvent触发。
Ribbon使用SmartInitializingSingleton定制化RestTemplate.
@Configuration
@ConditionalOnClass(RestTemplate.class)
@ConditionalOnBean(LoadBalancerClient.class)
@EnableConfigurationProperties(LoadBalancerRetryProperties.class)
public class LoadBalancerAutoConfiguration {
	@LoadBalanced
	@Autowired(required = false)
	private List<RestTemplate> restTempaltes = Collections.emptyList();
	
	@Bean 
	public SmartInitializingSingleton loadBalancedRestTemplateInitializer(final 
				List<RestTemplateCustomizer> customizers) {
		return new SmartInitializingSingleton() {
			@Override
			public void afterSingletonsInstantiated() {
				for (RestTemplate restTemplate : LoadBalancerAutoConfiguration.this.restTemplates) {
					for (RestTemplateCustomizer customizer : customizers) {
						customizer.customize(restTemplate);
					}
				}
			}
		}
	}
	...
}
MyCat的：全局表，ER分片表
常见的除了主键之外的其他可能分片字段有订单创建时间、店铺类别或所在省等。当找到某个合适的业务字段作为分片字段以后，不必纠结于"牺牲了按主键查询记录的性能"，因为在这种情况下，MyCAT提供了"主键到分片"的内存缓存机制，热点数据按照主键查询，不损失性能。
对于非主键分片的table，填写属性primaryKey，此时MyCAT会将你根据主键查询的SQL语句的第一次执
行结果进行分析，确定该Table的某个主键在什么分片上，并进行主键到分片ID的缓存。第二次或后续查询
mycat会优先从缓存中查询是否有id–>node 即主键到分片的映射，如果有直接查询，通过此种方法提高了非主
键分片的查询性能
-----------------------
Databus是一个低延迟、可靠的、支持事务的、保持一致的数据变更抓取系统。由LinkedIn于2013年开源。Databus通过挖掘数据库日志的方式，将数据库变更实时、可靠的从数据库拉取出来，业务可以通过定制化client实时获取变更并进行业务处理。
Databus有以下特点：
	1. 数据源和消费者之间隔离；
	2. 数据传输能保证顺序性和至少一次交付的高可用性；
	3. 从变化流的任意时间点进行消费，包括通过bootstrap获取所有数据；
	4. 分区消费；
	5. 源一致性保存，消费不成功会一直消费到消费成功。
功能&特性
	来源独立：Databus支持多种数据来源的变更抓取，包括Oracle和MySQL。
	可扩展、高度可用：Databus能扩展到支持数千消费者和事务数据来源，同时保持高度可用性。
	事务按序提交：Databus能保持来源数据库中的事务完整性，并按照事务分组和来源的提交顺寻交付变更事件。
	低延迟、支持多种订阅机制：数据源变更完成后，Databus能在毫秒级内将事务提交给消费者。同时，消费者使用Databus中的服务器端过滤功能，可以只获取自己需要的特定数据。
	无限回溯：对消费者支持无限回溯能力，例如当消费者需要产生数据的完整拷贝时，它不会对数据库产生任何额外负担。当消费者的数据大大落后于来源数据库时，也可以使用该功能。
Databus for MySQL:
	实现原理：通过解析mysql的binlog日志来获取变更事件，解析过程利用开源工具OpenReplicator，OpenReplicator首先连接到MySQL(类似于普通的MySQL Slave)，然后接收和分析binlog，最终将分析得出binlog events以回调的方式通知应用，所有的Event实现了BinlogEventV4接口。
	binlog格式：Databus设计为针对Row格式日志进行解析
		Statement:基于SQL语句的复制(statement-based replication, SBR)
		Row: 基于行的复制(row-based replication RBR)
		Mixed: 混合模式复制(mixed-based replication, MBR)
	SCN(System change number)的确定：64bits，高32位表示binlog的文件序号，低32位代表event在binlog文件的offset。
-----------------------
Canal工作原理：
	1. Canal模拟MySQL Slave的交互协议，伪装自己为MySQL slave，向MySQL发送dump协议；
	2. MySQL master收到dump请求，开始推送binary log给Slave(即Canal)；
	3. Canal解析binary log对象(原始为byte流).
Canal特别设计了client-server模式，交互协议使用protobuf 3.0, client端可采用不同语言实现不同的消费逻辑.
Canal作为MySQL binlog增量获取和解析工具，可将变更记录投递到MQ系统中，比如kafka/rocketMQ。
-----------------------
通过show engine innodb status命令查看死锁日志，结合异常代码，可定位原因。

死锁分析
等待锁分析
查看死锁日志，显示事务T1的insert语句在等待插入意向锁，lock_mode X locks gap before rec insert intention waiting;事务T2持有a=4的gap lock，同时也在等待插入意向锁。另外，T1能执行delete，说明它也拿到了gap lock，所以，两个事务都持有gap lock，导致循环等待插入意向锁而发生死锁。

加锁分析
	1. delete的where子句没有满足条件的记录，而对于不存在的记录 并且在RR级别下，delete加锁类型为gap lock，gap lock之间是兼容的，所以两个事务都能成功执行delete；这里的gap范围是索引a列(3,5)的范围。
	2. insert时，其加锁过程为先在插入间隙上获取插入意向锁，插入数据后再获取插入行上的排它锁。又插入意向锁与gap lock和 Next-key lock冲突，即一个事务想要获取插入意向锁，如果有其他事务已经加了gap lock或 Next-key lock，则会阻塞。
	3. 两个事务都持有gap lock，然后又申请插入意向锁，此时都被阻塞，循环等待造成死锁。
/*Intercepts client-side HTTP requests. Implementations of this interface can be 
RestTemplate#setInterceptors registered with RestTemplate, as to modify the outgoing 
ClientHttpRequest and/or the incoming ClientHttpResponse.
The main entry point for interceptors is intercept(HttpRequest, byte[],
 ClientHttpRequestExecution).
*/
@FunctionalInterface
public interface ClientHttpRequestInterceptor {
	ClientHttpResponse intercept(HttpRequest request, byte[] body,
				ClientHttpRequestExecution execution) throw IOException;
}
------------------------------------
MethodInterceptor
AOP中使用到的类/接口：
	1. AopProxyFactory接口: AopProxy代理工厂类，用于生成代理对象AopProxy。
	2. AopProxy:代表一个AopProxy代理对象，可以通过这个对象构造代理对象实例。
	3. Advised接口：代表被Advice增强的对象，包括添加advisor的方法、添加advice等方法；
	4. ProxyConfig类：一个代理对象的配置信息，包括代理的各种属性，如基于接口还是基于类构造代理。
	5. AdvisedSupport类：对Advised的构建提供支持，Advised的实现类以及ProxyConfig的子类。
	6. ProxyCreatorSupport类：AdvisedSupport的子类，创建代理对象的支持类，内部包括AopProxyFactory工厂成员，可直接使用工厂成员创建Proxy。
	7. ProxyFactory类：ProxyCreatorSupport的子类，用于生成代理对象实例的工厂类。
	8. Advisor接口：代表一个增强器提供者的对象，内部包含getAdvice方法获取增强器。
	9. AdvisorChainFactory接口：获取增强器链的工厂接口。提供方法返回所有增强器，以数组返回。
	10. Pointcut接口：切入点，用于匹配类与方法，满足切入点的条件才插入advice。相关接口：ClassFilter, MethodMatcher.
代理对象实例最终是使用AopProxy.getProxy()得到的，它的调用是在AopProxyFactory.createAopProxy(AdvisedSupport config), createAopProxy有两个结果。一个是基于接口的JDK动态代理JdkDynamicAopProxy,一个是基于Cglib的生成类代理ObjenesisCglibAopProxy。