@Aync注意：如果异步方法变成阻塞的同步方法，可能原因是异步方法和普通的调用方法在同一个类中，解决方法是将异步方法单独放到一个类中。产生原因：spring对@Transactional注解时也有类似问题，spring扫描时具有@Transactional注解方法的类时，是生成一个代理类，由代理类去开启关闭事务，而在同一个类中，方法调用是在类体内执行的，spring无法截获这个方法调用。

Consule: 是由HashiCorp公司提供的商业产品，不过有一个开源基础版本提供。它于服务发现的基础功能之外还提供了多数据中心的部署能力等一众出色的特性。

尽管传统的DNS系统不适用于微服务环境中的服务发现，但SkyDNS项目(后来称为kubedns)是一个有趣的实现，它结合古老的DNS技术和GO语言、Raft算法并构建于etcd存储系统之上，为Kubernetes系统实现了一种服务发现机制。Service资源为Kubernetes提供了一个较为稳定的抽象层，这有点类似于服务端发现的方式，也就不存在DNS服务的时间窗口问题。
Kubernetes自1.3版本开始，其用于服务发现的DNS更新为kubeDNS，而类似的另一个基于较新的DNS的服务发现项目是由CNCF孵化的CoreDNS，它基于GO语言开发，通过串接一组实现DNS功能的插件的插件链进行工作。自Kubernetes1.11版本起，CoreDNS取代kubeDNS成为默认的DNS附近。不过Kubernetes依然支持使用环境变量进行服务发现。

k8s的版本 : 1.8.3


Kubernetes的使用问题：
	1. 使用不规范问题：
		CD部署比较慢；
		docker registry拉取比较慢；
		重复重启: Readiness Probe, Liveness Probe;
		资源限制：Resources: Memory
		Replicas:副本的自动Autosacaling
		Termination Grase Period: 默认30秒，需要大于Eureka的最迟发现周期
	2. V1.8.3不能根据使用内存进行自动扩容/缩容，有些属于IO密集型的。
	3. Pod始终处于Pending状态，无法被正常调度到节点；原因如下：
		3.1 系统没有足够的资源;特别是内存，增加更多内存密集型的节点
		3.2 指定了hostPort: 通过hostPort用户能够将服务暴露到指定的主机端口上，会限制Pod能够调度执行的节点。
	4. Pod处于CrashLoopBackOff状态。CrashLoopBackOff状态说明容器曾经启动了，但又异常退出了。此时Pod的RestartCounts通常是大于0
		4.1 容器进程退出；
		4.2 健康检查失败退出；
		4.3 OOMKilled;
	5. K8s证书过期
	6. dial tcp: getsockopt: no route to host；在部署Kubernetes服务时，出现kube-dns服务反复重启现象；
		很可能是iptables规则乱了，执行下面命令即可：
			systemctl stop kubelet
			systemctl stop docker 
			iptables --flush
			iptables -tnt --flush 
			systemctl start kubelet 
			systemctl start docker;

系统幂等性：
	1. 数据库乐观锁；(两种实现方式：通过版本号实现；通过待改变的条件实现)
	2. 前端控制一部分：表单重复提交、按钮置灰、隐藏、不可点击等；
	3. Token机制：每次重要操作前，由服务器返回token，在操作时带上token，设置有效期，有效期内只允许一次操作；业务操作完毕后删除token。
	4. 在数据库中设置唯一标识作为去重表。
	5. Redis保存唯一标识字段，为了保证Redis的可用性和空间使用，需要设置合理的有效期；
	6. 状态机：
	7. 悲观锁： select * from xx for update;
MySQL提供的三种可以防止重复插入数据的方式：
	1. Replace
	2. on duplicate key update
	3. insert ignore
Java中double类型比较大小或相等的方法：
	1. 使用Double.toString()，然后比较字符串。这种方法只适用于比较精度相同的数据，并且只能比较是否相等，不能判断大小。
	2. 使用new BigDecimal(Double.toString(xx));
	3. 使用sun提供的Double.doubletoLongBits()方法将double转换成long型数据。
	4. 允许特定的阈值范围内；Math.abs(d1 - d2) < 0.00000000...1



2PC和TCC的区别：
	1. 2PC是依赖数据库层面的XA实现的。TCC是业务层面实现的,属于业务逻辑处理；
	2. TCC使用了加锁粒度较小的柔性事务，不保证各个数据源的数据强一致性。TCC追求的是最终一致性；符合BASE理念。
	3. 2PC性能比较差(阻塞协议，锁时间。需要数据库支持)，依赖中间件支持。

CAT: Central Application Tracking, 是基于Java开发的分布式实时监控系统。CAT在基础存储、高性能通信、大规模在线访问、服务治理、实时监控、容器化及集群智能调度等领域提供业界领先的、统一的解决方案。CAT 目前在美团的产品定位是应用层的统一监控组件，基本接入了美团所有核心应用，在中间件（RPC、数据库、缓存、MQ 等）框架中得到广泛应用，为各业务线提供系统的性能指标、健康状况、实时告警等。

/* A BlockingQueue blocking queue in which each insert operation must wait for a corresponding remove operation by another thread, and vice versa. A synchronous queue does not hava any internal capacity, not event a capacity of one. You cannot peek at a synchronous queue because an element is only present when you try to remove it; you cannot insert an element (using any method) unless another thread is trying to remove it; you cannot iterate as there is nothing to iterate. The head of the queue is the element that first queued inserting thread is trying to add to the queue; if there is no such queued thread then no element is available for removal and poll() will return null. For purposes of other Collection methods (for example contains), a SynchronousQueue acts as an empty collection. This queue does not permit null elements. 
Synchronous queues are similar to rendezvous channels used in CSP and Ada. They are well suited for handoff designs, in which an object running in one thread must sync up with an object running in another thread in order to hand it some information, event, or task.
This class supports an optional fairness policy for ordering waiting producer and consumer threads.  By default, this ordering is not guaranteed. However, a queue constructed with fairness set to {@code true} grants threads access in FIFO order.
This class and its iterator implement all of the <em>optional</em> methods of the {@link Collection} and {@link Iterator} interfaces.
*/
public class SynchronousQueue<E> extends AbstractQueue<E> 
	implements BlockingQueue<E>, java.io.Serializable {
	
}

SynchronousQueue是一个队列和栈算法实现，在SynchronouseQueue中双队列FIFO提供公平模式，而双栈LIFO提供的则是非公平模式。对于SynchronouseQueue来说，put和take方法都被抽象成统一方法进行操作，通过抽象出内部类Transferer，来实现不同的操作。
---------------------------------------------------
基于Kafka的一种事务消息分布式事务的最终一致性方案：
1. DB操作+消息记录
	kafka线程异步发送消息，并删除消息记录或者更新消息记录。
2. 消费者，kafka本身不支持事务。
	拉取消息，插入消息记录，DB操作，提交事务。
	kafka线程异步发送offset，在异步的通知里并删除消息记录或更新消息记录。

由于offset是有序的，怎么保证一个卡住，后面的可以继续进行。
导致offset一直没有更新。
根据offset进行去重，发现重复N次拉取后，直接发往特殊的topic。
强制提交offset，不阻挡后续的消息。
理论只会卡住一个分区。
无法保证分区的有序性。
kafka是分区的。

特点：
	1. 会进行异步化；
	2. 存在大量中间状态，业务逻辑复杂；
	3. 多了消息记录。
	4. 不具备通用性。
---------------------------------------------------
分布式配置的拉的模式怎么实现？
	1. 后台异步线程按指定时间去拉取配置;
	2. 在/refresh的URL进行拦截，记录每次更新的时间；并进行锁的控制，来保证只有一个进行更新。
	3. 后台异步线程在拉取时，判断和上次时间进行比对，确保有足够的间隔；
	4. 每次异步拉取记录内容的MD5值，和上次进行比对，如果不同，才进行更新；并更新时间。
---------------------------------------------------
public class Collections {
	...
	@SuppressWarnings("unchecked")
	public static <T extends Comparable<? super T>> void sort(List<T> list) {
		list.sort(null);
	}
	@SuppressWarnings({"unchecked", "rawtypes"})
	public static <T> void sort(List<T> list, Comparator<? super T> c) {
		list.sort(c);
	}
	...
}

public interface List<E> extends Collection<E> {
	...
	@SuppressWarnings({"unchecked", "rawtypes"})
	default void sort(Comparator<? super E> c) {
		Object[] a = this.toArray();
		Arrays.sort(a, (Comparator)c);
		ListIterator<E> i = this.listIterator();
		for (Object e : a) {
			i.next();
			i.set((E) e);
		}
	}
	...
}

public class ArrayList<E> extends AbstractList<E> 
	implements List<E>, RandomAccess, Cloneable, java.io.Serializable {
	...
	@Override
	@SuppressWarnings("unchecked")
	public void sort(Comparator<? super E> c) {
		final int expectedModCount = modCount;
		Arrays.sort((E[]) elementData, 0, size, c);
		if (modCount != expectedModCount) {
			throw new ConcurrentModificationException();
		}
		modCount ++;
	}
}


public class Arrays {
	...
	public static void sort(int[] a) {
		DualPivotQuicksort.sort(a, 0, a.length - 1, null, 0, 0);
	}
	public static void sort(int[] a, int fromIndex, int toIndex) {
		rangeCheck(a.length, fromIndex, toIndex);
		DualPivotQuicksort.sort(a, fromIndex, toIndex - 1, null, 0, 0);
	}
	public static void sort(long[] a) {
        DualPivotQuicksort.sort(a, 0, a.length - 1, null, 0, 0);
    }
	//基础类型的排序都是DualPivotQuicksort
	
	public static void sort(Object[] a) {
		if (LegacyMergeSort.userRequested) {
			legacyMergeSort(a);
		} else {
			ComparableTimSort.sort(a, 0, a.length, null, 0, 0);
		}
	}
	
	// To be removed in a future release.
	private static void legacyMergeSort(Object[] a) {
		Object[] aux = a.clone();
		mergeSort(aux, a, 0, a.length, 0);
	}
	...
}

Kafka中有那些地方需要选举？这些地方的选举策略又有哪些
	1. 控制器, ControllerManager;
	2. 优先副本, perferred replica
	3. 消费者协调器和消费组协调器，ConsumerCoordinator, ConsumerGroupCoordinator
	4. 事务协调器, TransactionCoordinator

/* This class implements the Dual-Pivot Quicksort algorithm by Vladimir Yaroslavskiy, Jon Bentley, and Josh Bloch. The algorithm offers O(n log(n)) performance on many data sets that cause other quicksorts to degrade to quadratic performance, and is typically faster than traditional (one-pivot) Quicksort implementations. 
All exposed methods are package-private, designed to be invoked from public methods(in class Arrays) after performing any necessary array bounds checks and expanding parameters into the required forms. 
*/
final class DualPivotQuicksort {
	...
}


/* A stable, adaptive, iterative mergesort that requires far fewer than n*lg(n) comparisons when running on partially sorted arrays, while offering performance comparable to a traditional mergesort when run on random arrays. Like all proper mergesots, this sort is stable and runs O(n*log(n)) time (worst case). In the worst case, this sort requires temporary storage space for n/2 object references; in the best case, it requires only a small constant amount of space. 
While the API to this class consists solely of static methods, it is (privately) instantiable; a TimSort instance holds the state of an ongoing sort, assuming the input array is large enough to warrant the full-blown TimSort. Small arrays are sorted in place, using a binary insertion sort. 
*/
class TimSort<T> {
	...
}

/* This is a near duplicate of TimSort, modified for use with arrays of objects that implement Comparable, instead of using explicit comparators.
If you are using an optimizing VM, you may find that ComparableTimSort offers no performance benefit over TimSort in conjunction with a comparator that simply return ((Comparable)first).compareTo(second). If this is the case, you are better off deleting ComparableTimSort to eliminate the code duplication. (See Arrays.java for details.)
*/
class ComparableTimSort {
	...
}

CAS原理：调用Unsafe类的相关函数。底层又调用JNI的代码，C++代码。再底层调用汇编代码。
// Adding a lock prefix to an instruction on MP machine
// VC++ doesn't like the lock prefix to be on a single line 
// so we can't insert a label after the lock prefix.
// By emitting a lock prefix, we can define a label after it. 
#define LOCK_IF_MP(mp) __asm cmp mp, 0  \
                       __asm je L0      \
                       __asm _emit 0xF0 \
                       __asm L0:

inline jint     Atomic::cmpxchg    (jint     exchange_value, volatile jint*     dest, jint     compare_value) {
  // alternative for InterlockedCompareExchange
  int mp = os::is_MP();
  __asm {
    mov edx, dest
    mov ecx, exchange_value
    mov eax, compare_value
    LOCK_IF_MP(mp)
    cmpxchg dword ptr [edx], ecx
  }
}
程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果是多处理器，就为cmpxchg指令加上lock前缀(lock cmpxchg)。反之，如果在单处理器上，就省略lock前缀。单处理器自身会维护单处理器内的顺序一致性，不需要lock前缀提供的内存屏障效果。



CAS有什么缺陷，如何解决
	1. ABA问题; AtomicStampedReference, AtomicMarkableReference;
	2. 只能保证一个共享变量的原子性；当对一个共享变量进行操作时，可以使用循环CAS保证原子性；但是对于多个共享变量，无法保证原子性；这个时候可以用锁。或者另外一个技巧：把多个共享变量合并成一个共享变量来操作。可以使用AtomicReference类来保证引用对象之间的原子性，把多个变量放在一个对象里来CAS.
	3. 自旋消耗资源，循环时间长开销大。竞争条件比较激烈时，自旋CAS一直不成功的话，会给CPU带来非常大的开销。解决方法：超过一定阈值后，退出，改用重量级锁。使用其他替代：LongAdder, ConcurrentHashMap等。

常见负载均衡算法：
	1. 轮询: Round Robin
	2. 加权轮询：Weighted Round Robin 
	3. 最小连接数：Least Connection
	4. 最小连接数慢启动时间：Least Connection Slow Start Time
	5. 加权最小连接：Weighted Least Connection 
	6. 基于代理的自适应负载均衡：Agent Based Adaptive Balancing
	7. 固定权重：Fixed Weighted 
	8. 加权响应：Weighted Response
	9. 源IP哈希：Sorce IP Hash 
	10. 随机：Random 
	11. 一致性Hash: ConsistentHash

Ribbon是客户端提供负载均衡功能，内部提供一个ILoadBalancer接口代表负载均衡器的操作，比如addServers(List<Server>), chooseServer(key), markServerDown(Server), getReachableServers(), getAllServers()。ILoadBalancer的继承关系如下：
ILoadBalancer
	- AbstractLoadBalancer
		- BaseLoadBalancer
			- DynamicServerListLoadBalancer
				- ZoneAwareLoadBalancer
		- NoOpLoadBalancer
负载均衡器是从EurekaClent(EurekaClient的实现类DiscoveryClient)获取服务信息，根据IRule去路由，并且根据IPing判断服务的可用性。

/* Interface that defines a "Rule" for a LoadBalancer. A Rule can be thought of as a Strategy for loadbalacing. Well known loadbalancing strategies include Round Robin, Response Time based etc. 
*/
public interface IRule {
	public Server choose(Object key);
	public void setLoadBalancer(ILoadBalancer lb);
	public ILoadBalancer getLoadBalancer();
}

IRule的继承关系如下：
IRule 
	- AbstractLoadBalancerRule
		- ClientConfigEnabledRoundRobinRule
			- BestAvailableRule
			- PredicateBasedRule
				- AvailabilityFilteringRule
				- ZoneAvoidanceRule
		- RandomRule
		- RetryRule
		- RoundRobinRule
			- ResponseTimeWeightedRule
			- WeightedResponseTimeRule

MySQL不同的存储引擎支持不同的锁机制：MyISM和Memory存储引擎采用的是表级锁；BDB存储引擎采用的是页面锁；InnoDB存储引擎既支持行级锁也支持表级锁，默认情况下采用行级锁。
InnoDB使用间隙锁的目的：
	一方面是为了防止幻读，以满足相关隔离级别的要求；
	另外一方面是为了满足其恢复和复制的需要。

MySQL提供了两种事务型的存储引擎：InnoDB和NDB Cluster。另外还有第三方存储引擎也支持事务，比如XtraDB和PBXT。

什么场景下用表锁：
InnoDB默认采用行锁，在未使用索引字段查询时升级为表锁。MySQL这样设计并不是给你挖坑。它有自己的设计目的。
即便你在条件中使用了索引字段，MySQL会根据自身的执行计划，考虑是否使用索引(所以explain命令中会有possible_key 和 key)。如果MySQL认为全表扫描效率更高，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。
	第一种情况：全表更新。事务需要更新大部分或全部数据，且表又比较大。若使用行锁，会导致事务执行效率低，从而可能造成其他事务长时间锁等待和更多的锁冲突。
	第二种情况：多表级联。事务涉及多个表，比较复杂的关联查询，很可能引起死锁，造成大量事务回滚。这种情况若能一次性锁定事务涉及的表，从而可以避免死锁、减少数据库因事务回滚带来的开销。

------------------------------------------------------
Kafka is used as Schema Registry storage backend. The special Kafka topic <kafkastore.topic>(default _schemas), with a single partition, is used as a high available write ahead log. All schemas, subject/version and ID metadata, and compatibility settings are appended as messages to this log. A Schema Registry instance therefore both produces and consumes messages under the _schemas topic. It produces message to the log when, for example, new schemas are registered under a subject, or when updates to compatibility settings are registered. Schema Registry consumes from the _schemas log in a background thread, and updates its local caches on consumption of each new _schemas message to reflect the newly added schema or compatibility setting. Updating local state from the Kafka log in this manner ensures durability, ordering, and easy recoverability. 
Tip:
The Schema Registry topic is compacted and therefore the latest value of every key is retained forever, regardless of the Kafka retention policy. You can validate this with kafka-configs:
$ kafka-configs --zookeeper localhost:2181 --entity-type topics --entity-name _schemas --describe 
Configs for topic '_schemas' are cleanup.policy=compact
---------------------MySQL---------------------------------
show [SESSION|GLOBAL] variables;
show [SESSION|GLOBAL] status;
information_schema;
explain
show processlist;
show index from <table>;
show status like '%lock%';
kill <session_id>; 停止有问题的session
vmstat : reports information about processes, memory, paging, block IO, traps, disks and cpu activity.
show variables like 'max_connections';
set global max_connections = 5000;
------------------------------------------------------
EventLoopGroup
EventLoop
Channel
ChannelFuture
ChannelHandler
ChannelPipeline
ChannelInitializlizer
ChannelOutboundHandler
Bootstrap
ServerBootstrap
ChannelInboundHandler
------------------------------------------------------
-XX:+HeapDumpBeforeFullGC
jvisualvm
mat 
Keep unreachable objects 
jstat -gcutil <pid> 3000 每隔三秒钟输出GC的统计信息
-XX:+UseConcMarkSweepGC 
-XX:+UseParNewGC 
-XX:+CMSFullGCsBeforeCompaction=5
-XX:+UseCMSCompactAtFullCollection 
jstat -gccause <pid> 查看gc的详细原因 (System.gc(), Allocation Failure)
首先通过top查看java进程的占用CPU是否高，如果高记录下进程ID
使用top -Hp <Java进程ID>， 查看每个线程的运行情况
找出占用CPU最高的线程ID，将这个线程ID转换成十六进制。
使用jstack dump出线程堆栈，根据上面的线程十六进制查找正在执行的代码。
对于不定期/偶尔出现接口耗时的现象，排查手段：找到此接口后，在测试环境压测，并周期性记录jstack堆栈，通过查看jstack日志，找出阻塞点，定位代码。
jstat -J-Djstat.showUnsupported=true -snap 5496

------------------------------------------------------
死锁的4个必要条件：
	1. 互斥:当资源被一个线程使用/占用时，其他线程不能使用；
	2. 不可抢占：资源请求者不能强制从资源占用者中抢占资源，资源只能由资源占有者主动释放；
	3. 占有和保持：即资源请求者在请求其他资源的同时保持对原有资源的占有；
	4. 循环等待：即存在一个等待队列：P1占有P2的资源，P2占有P3的资源，P3占有P1的资源。这样形成一个等待环路
如何检测死锁：
	1. Jconsole里面的“线程” -> "检测死锁"
	2. jstack
	3. jcmd <pid> Thread.print
	4. 使用ThreadMXBean协助查找死锁，效果和jstack类似。做一个后台异步周期看门狗线程，
		ThreadMXBean tmx = ManagementFactory.getThreadMXBean();
		long[] ids = tmx.findDeadlockedThreads();
		if (ids != null) {
			ThreadInfo[] infos = tmx.getThreadInfo(ids, true, true);
			for (ThreadInfo : infos) {
				StackTraceElement[] stack = info.getStackTrace();
				//打印信息
			}
		}
	5. 对于锁由于某些原因没有执行unlock，再次执行lock时，这种死锁是没有办法使用工具进行检测的，可考虑下面的手段：
		5.1 如果能够控制资源死锁的情况：
			1. 死锁前dump线程快照
			2. 死锁后dump线程快照
			3. 两者比较；
		5.2 如果已经死锁：
			1. 每隔一段时间dump出线程快照
			2. 对比找到没有改变的那些线程再排查问题
		
如何避免死锁：
	1. 超时放弃，使用ReentractLock.tryLock(long time, TimeUnit)
	2. 使用Semaphore
	3. 银行家算法
	4. 以确定的顺序获得锁
	5. 超时放弃
	6. 一次性申请所有的资源

为什么要hashCode进行spread: 充分使用key.hashCode()的高16位信息，保证hash分布更分散。
JDK7中数组的容量是在HashMap初始化时就已经赋予；而在JDK8是在put第一个元素时才会赋予数组容量。

HashMap的JDK7为什么先扩容再插入，而JDK8是先插入再扩容?
	对JDK7来说，是先扩容再插入if ((size >= threshold) && (null != table[bucketIndex]))，当发现插入的桶不为空，说明发生了hash冲突，那么必须进行扩容。如果桶为空，说明没有发生hash冲突，那就等下次发生hash冲突的时候再进行扩容。但是如果以后没有发生hash冲突，就不会扩容了，减少了无用的扩容，也减少了内存的使用。

HashMap在JDK8引入了红黑树，若桶中链表元素个数大于等于8时，链表转换成数结构；若桶中元素个数小于等于6时，数结构还原成链表。因为红黑树的平均查找长度是log(N)，长度为8时，平均查找长度为3；如果继续使用链表，平均查找长度为8/2=4，这才有转换为树的必要。链表长度如果小于等于6，6/2=3，虽然速度也很快，但是转化成树结构和生成树的时间并不会短。
还有选择6和8，中间有个差值7可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。

参数: innodb_flush_log_at_trx_commit用来控制重做日志redo log刷新到磁盘的策略，有三个值：
	0：表示事务提交时不进行redo log file的操作，这个操作仅在master thread中完成，每隔1秒一次fsync操作；
	1: 默认值，表示每次事务提交时进行redo log file的操作；
	2：表示事务提交时redo log写入文件，不过仅写入文件缓存，不进行fsync操作。

innodb事务日志包括redo log和undo log。redo log是重做日志，提供前滚操作，undo log是回滚日志，提供回滚操作。
undo log不是redo log的逆向过程。
	1. redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成什么，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置).
	2. undo用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。

innodb_flush_log_at_trx_commit : 


/* A package-local class holding common representation and mechanics for classes supporting dynamic striping on 64bit values. The class extends Number so that concrete subclasses must publicly do so. 
*/
@SuppressWarnings("serial")
abstract class Striped64 extends Number {
	
}

Striped64在ConcurrentHashMap中的应用：
	Striped64的计数方法在JDK8的ConcurrentHash中也有使用，在addCount方法中实现细节。在ConcurrentHash的size方法如下：
	public int size() {
		long n = sumCount();
		return (n < 0L) ? 0 :
						(n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);
	}
	final long sumCount() {
		CounterCell[] as = counterCells;
		CounterCell a;
		long sum = baseCount;
		if (as != null) {
			for (int i = 0;i < as.length; ++ i) {
				if ((a = as[i]) != null)
					sum += a.value;
			}
		}
		return sum;
	}
ConcurrentHashMap中的baseCount对应着Striped64中的base变量，而counterCells则对应着Striped64中的cells数组，它们的实现是一样的。

/* One or more variables that together maintain a running long value updated using a supplied function. When updates (method accumulate) are contended across threads, the set of variables may grow dynamically to reduce contention. Method get (or equivalently, longValue) returns the current value across the variables maintaining updates.
This class is usually preferable to AtomicLong when mulitiple threads update a common value that is used for purposes such as collecting statistics, not for fine-grained synchronization control. Under low update contention, the two classes have similar characteristics. But under high contention, expected throughput of this class is significantly higher, at the expense of higher space consumption.
The order of accumulation within or across thread is not guranteed and cannot be depended upon, so this class is only applicable to functions for which the order of accumulation does not matter. The supplied accumulator function should be side-effect-free, since it may be re-applied when attempted updates fail due to contention among threads. The function is applied with the current value as its first argument, and the given update as the second argument. For example, to maintain a running maximum value, you could supply Long::max along with Long.MIN_VALUE as the identity.
Class LongAdder provides analogs of the functionality of this class for the common special case of maintaining counts and sums. The call new LongAdder() is equivalent to new LongAccumulator((x, y) -> x + y, 0L);
This class extends Number, but does not define methods such as equals, hashCode, and compareTo because instances are expected to be mutated, and so are not useful as collection keys.
*/
public class LongAccumulator extends Striped64 implements Serializable {
	
}


开源排查消耗CPU最高的前N个线程: show-busy-java-threads 
# 在项目模块目录下执行，拷贝依赖jar到目录target/dependency下
$ mvn dependency:copy-dependencies -DincludeScope=runtime 

开发可伸缩系统必须遵守的11条软件设计原则：
	1. 简单；
	2. 低耦合；
	3. 不要重复造轮子；
	4. 基于约定编程；
	5. 画架构图；
	6. 单一职责；
	7. 开闭原则；
	8. 依赖注入；
	9. 控制反转；
	10. 为伸缩而设计；
	11. 自愈设计；

两种IO多路复用模式：Reactor和Proactor.
一般地，IO多路复用机制都依赖于一个事件多路分离器(Event Demultiplexer)。分离器对象可将来自事件源的IO事件分离出来，并分发到对应的read/write事件处理器(Event Handler)。开发人员预先注册需要处理的事件及其事件处理器(或回调函数)；事件分离器负责将请求事件传递给事件处理器。两个与事件分离器有关的模式是Reactor和Proactor。Reactor模式采用同步IO，而Proactor采用异步IO。
在Reactor中，时间分离器负责等待文件描述符或socket为读写操作准备就绪，然后将就绪事件传递给对应的处理器，最后由处理器负责完成实际的读写工作。
而在Proactor中，处理器或者兼任处理器的时间分离器，只负责发起异步读写操作。IO操作本身由操作系统来完成。传递给操作系统的参数需要包括用户定义的数据缓冲区地址和数据大小，操作系统才能从中得到写出操作所需数据，或写入从socket读到的数据。时间分离器捕获IO操作完成实际，然后将事件传递给对应处理器。比如，在Windows上，处理器发起一个异步IO操作，再由时间分离器等待IOCompletion事件。典型的异步模式实现，都建立在操作系统支持异步API的基础之上，这种实现称为"系统级"或"真异步". 因为应用程序完全依赖操作系统执行真正的IO工作。

举个例子，将有助于理解Reactor与Proactor二者的差异，以读操作为例。
在Reactor中实现读：
	- 注册读就绪事件和相应的事件处理器
	- 事件分离器等待事件
	- 事件到来，激活分离器，分离器调用事件对应的处理器。
	- 事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。
在Proactor中实现读：
	- 处理器发起异步读操作（注意：操作系统必须支持异步IO）。在这种情况下，处理器无视IO就绪事件，它关注的是完成事件。
	- 事件分离器等待操作完成事件
	- 在分离器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分离器读操作完成。
	- 事件分离器呼唤处理器。
	- 事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分离器。

可以看出，两个模式的相同点，都是对某个IO事件的事件通知(即告诉某个模块，这个IO操作可以进行或已经完成)。在结构上，两者也有相同点：demultiplexor负责提交IO操作(异步)、查询设备是否可操作(同步)，然后当条件满足时，就回调handler；不同点在于，异步情况下(Proactor)，当回调handler时，表示IO操作已经完成；同步情况下(Reactor)，回调handler时，表示IO设备可以进行某个操作(can read or can write)。

使用Proactor框架和Reactor框架都可以极大的简化网络应用的开发，但它们的侧重点不同。
	1. Reactor框架中用户定义的操作是在实际操作之前调用的。比如定义了操作是向socket写数据，那么当该socket可以接收数据的时候，操作就会被调用；而Proactor框架中用户定义的操作是在实际操作之后调用的，比如定义了一个操作要从socket中读入数据，那么当读操作完成以后，操作才会被调用。
	2. Proactor和Reactor都是并发编程中的设计模式。它们都是用于派发/分离IO操作事件的。这里所谓的IO事件也就是read/write的IO操作。派发/分离就是将单独的IO事件通知到上层模块。两个模式不同的地方在于，Proactor用于异步，Reactor用于同步。

Kotlin中的协程：一般程序会有主进程，主进程中可能含有多个线程。而协程，是线程中的，也就是说一个线程中可能包含多个协程，协程与协程之间是可以嵌套的。
协程的作用：当线程要执行可能会阻塞的任务时，一般情况下会开启一个子线程来完成，如果阻塞任务过多，就需要开启多个子线程(线程池)，协程可以帮助我们完成的是，将可能会阻塞的任务放在线程的协程中来完成，多个任务就创建多个协程。线程直接维持数据准确性需要消耗很多资源，而协程消耗的会少很多。注：协程是可以直接运行在进程中的，不是一定要依赖于线程，只不过限制支持协程的Kotlin,Python,Go等语言都会以主线程的方法开启程序的运行。总结：通过提升CPU利用率，减少线程切换进而提升程序运行效率。
协程的特性：
	- 可控制：协程能做到可被控制的发起子任务(协程的启动和停止都由代码控制，不像java)
	- 轻量级：协程非常小，占用资源比线程还少
	- 语法糖：使多任务或多线程切换不再使用回调语法。

并行流内部使用了默认的ForkJoinPool，默认的线程数量就是处理器的数量(包括虚拟内核):
	- 通过:Runtime.getRuntime().availableProcessors()得到；
	- 通过：System.setProperty("java.util.concurrent.ForkJoniPool.common.parallism", "12")来改变线程池大小。

SynchronousQueue主要有如下的特点：
	1. SynchronousQueue的容量为0，因此它是无法用于数据存储。
	2. 每一次向队列中执行写操作时，写线程都会等待；直到另一个线程去执行读操作，写线程才会返回；反之亦然，并且写入的元素不允许为NULL。
	3. 由于SynchronousQueue的容量为0，没有存储任何数据，因此执行peek方法返回队列中的元素时，总是返回Null；如果执行迭代操作，同样也是没有任何元素可以迭代；
	4. SynchronousQueue将put,take两个截然不同的方法，统一抽象成一个transfer方法来进行处理，主要是根据方法的参数来判断是执行take操作还是put操作；
	5. SynchronousQueue和ReentrantLock类似，提供了公平与非公平两种策略的处理实现，其分别是基于队列与栈来实现，一个是TransferQueue，另一个是TransferStack，都分别实现了Transfer接口，然后实现transfer方法。

Spring Bean的加载过程(简单)：
	1. 获取配置文件资源：通过ResourceLoader来完成资源文件位置的定位，DefaultResourceLoader是默认的实现，同时上下文本身给出了ResourceLoader的实现，可以从类路径、文件系统、URL等方式来定位资源位置；
	2. 对Bean定义信息的解析：容器通过BeanDefinitionReader来完成Bean定义信息的解析，使用XmlBeanDefinitionReader来解析Bean的xml定义文件，实际的处理过程是委托给BeanDefinitionParserDelegate来完成的，从而得到Bean的定义信息，这些信息在Spring中使用BeanDefinition对象来表示；
	3. 加载提取Bean并注册(添加到beanDefinitionMap中): IOC容器解析得到Bean以后，需要在IOC容器中注册，这由BeanDefinitionRegistry接口来实现。注册过程就是在IOC容器内部维护的一个HashMap来保存得到BeanDefinition的过程。这个HashMap是IOC容器持有Bean信息的场所，以后对Bean的操作都是围绕这个HashMap来实现的。
	4. Bean的初始化：通过DefaultListableBeanFactory的getBean()方法去初始化，实际由AbstractAutowireCapableBeanFactroy的doCreateBean()去完成。一个是创建Bean实例的createBeanInstance方法，一个是依赖注入的populateBean方法，还有就是回调方法initializeBean。BeanPostProcessor两个方法：postProcessBeforeInitialization和postProcessAfterInitialization,两个方法分别在Bean初始化之前和之后得到执行。

import org.springframework.beans.factory.support.DefaultListableBeanFactory;
import org.springframework.beans.factory.xml.XmlBeanDefinitionReader;
import org.springframework.core.io.ClassPathResource;
import org.springframework.core.io.Resource;
public class Main {
	public static void main(String[] args) {
		Resource resource = new ClassPathResource("spring-context.xml");
		DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory();
		XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(beanFactory);
		reader.loadBeanDefinitions(resource);
		User user = beanFactory.getBean(User.class);
		...
	}
}
Resource继承了InputStreamSource，这个接口定义了IO流的基本操作。常用的如ClassPathResource，FileSystemResource，FileUrlResource等等，详细就不介绍了，通过名字都可以看的出来只是加载资源的方式不同而已。

/* Generic registry for shared bean instances, implementing the SingletonBeanRegistry. Allows for registering singleton instances that should be shared for all callers of the registry, to be obtained via bean name.
Also supports registration of DisposableBean instances, (which might or might not correspond to registered singletons), to be destroyed on shutdown of the registry. Dependencies between beans can be registered to enforce an appropriate shutdown order.
This class mainly servers as base class for BeanFactory implementations, factoring out the common management of singleton bean instances. Note that the ConfigurableBeanFactory interface extends the SingletonBeanRegistry interface.
Note that this class assumes neither a bean definition concept nor a specific creation process for bean instances, in contrast to AbstractBeanFactory and DefaultListableBeanFactory (which inherit from it). Can alternatively also be used as a nested helper to delegate to. 
*/
public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry {
	private final Map<String, Object> singletonObjects = new ConcurrentHashMap<>(256);
	private final Map<String, ObjectFactory<?>> singletonFactories = new HashMap<>(16);
	private final Map<String, Object> earlySingletonObjects = new HashMap<>(16);
	private final Set<String> registeredSingletons = new LinkedHashSet<>(256);
	private final Set<String> singletonsCurrentlyInCreation = new Collections.newSetFromMap(new ConcurrentHashMap<>(16));
	private final Set<String> inCreationCheckExclusions = new Collections.newSetFromMap(new ConcurrentHashMap<>(16));
	private Set<Exception> suppressedExcetions;
	private boolean singletonsCurrentlyInDestruction = false;
	private final Map<String, Object> disposableBeans = new LinkedHashMap<>();
	private final Map<String, Set<String>> containedBeanMap = new ConcurrentHashMap<>(16);
	private final Map<String, Set<String>> depenentBeanMap = new ConcurrentHashMap<>(64);
	private final Map<String, Set<String>> dependenciesForBeanMap = new ConcurrentHashMap<>(64);
	...
}
--------------------------------------------------------------------
在SpringBoot的jar包里的META-INF里的MANIFEST.MF文件中:
Main-Class: org.springframework.boot.loader.JarLauncher 
Start-Class: com.hzphfin.fund.tjj.server.FundTjjServerApplication
可以看到jar的启动类为:org.springframework.boot.loader.JarLauncher，而不是业务代码的入口类，应用程序入口类标记为了Start-Class。
jar启动并不是通过应用程序入口类，而是通过JarLauncher代理启动。其中SpringBoot有3个不同的Launcher:JarLauncher, WarLauncher, PropertiesLauncher。
相关的类层次结构如下：
Launcher
	- ExecutableArchiveLauncher
		- JarLauncher
		- WarLauncher 
	- PropertiesLauncher 
在不同的应用场景下，SpringBoot应用的ClassLoader是不同的：
	1. 在IDE里，直接run main函数：ClassLoader是sun.misc.Launcher.AppClassLoader；
	2. 以fat jar运行：ClassLoader是LaunchedURLClassLoader，它的parent是AppClassLoader;
	3. 将jar解压后，运行 java org.springframework.boot.loader.PropertiesLauncher ：ClassLoader是LaunchedURLClassLoader，它的parent是AppClassLoader。
另外还有两种运行方式: mvn spring-boot:run 和 mvn spring-boot:run -Dfork=true 
--------------------------------------------------------------------
/* Holder class to expose the web request in the form of a thread-bound RequestAttributes object. The request will be inherited by any child threads spawned by the current thread if the inheritable flag is set to true;
Use RequestContextListener or org.springframework.web.filter.RequestContextFilter to expose the current web request. Note that DispatcherServlet already exposes the current request by default. 
*/
public abstract class RequestContextHolder {
	...
}
/**
 * One or more variables that together maintain an initially zero
 * {@code double} sum.  When updates (method {@link #add}) are
 * contended across threads, the set of variables may grow dynamically
 * to reduce contention.  Method {@link #sum} (or, equivalently {@link
 * #doubleValue}) returns the current total combined across the
 * variables maintaining the sum. The order of accumulation within or
 * across threads is not guaranteed. Thus, this class may not be
 * applicable if numerical stability is required, especially when
 * combining values of substantially different orders of magnitude.
 *
 * <p>This class is usually preferable to alternatives when multiple
 * threads update a common value that is used for purposes such as
 * summary statistics that are frequently updated but less frequently
 * read.
 *
 * <p>This class extends {@link Number}, but does <em>not</em> define
 * methods such as {@code equals}, {@code hashCode} and {@code
 * compareTo} because instances are expected to be mutated, and so are
 * not useful as collection keys.
 */
public class DoubleAdder extends Striped64 implements Serializable {
	/* Note that we must use "long" for underlying representations, because there is no compareAndSet for double, due to the fact that the bitwise equals used in any CAS implementation is not the same as double-precision equals. However, we use CAS only to detect and alleviate contention, for which bitwise equals works best anyway. In principle, the long/double conversions used here should be essentially free on most platforms since they just re-interpret bits.
	*/
	...
	public void add(double x) {
		Cell[] as; long b, v;int m; Cell a;
		if ((as = cells) != null || 
			!casBase(b = base, 
					Double.doubleToRawLongBits(Double.longBitsToDouble(b) + x))) {
			boolean uncountended = true;
			if (as == null || (m = as.length - 1) < 0 ||
				(a = as[getProbe() & m] == null || 
				!(uncontended = a.cas(v = a.value, Double.doubleToRawLongBits(Double.longBitsToDouble(V) + x)))))
				doubleAccumulate(x, null, uncontended);
		}
	}
	...
}

