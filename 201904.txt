Consul与Eureka的不同点：
	1. 最大的区别是Eureka保证AP，Consul为CP；
	2. Consul强一致性(C)带来的是：服务注册相比Eureka会稍慢一些。因为Consul的Raft协议要求必须过半的节点都写入成功才认为注册成功。Leader挂掉时，重新选举期间整个Consul不可用。保证了强一致性但牺牲了可用性；
	3. Eureka保证高可用(A)和最终一致性：服务注册相对要快，因为不需要等注册信息replicate到其他节点，也不保证注册信息是否replicate成功。当数据出现不一致时，虽然A，B上的注册信息不完全相同，但每个Eureka节点依然能够正常对外提供服务，这会出现查询服务信息如果请求A查不到，但请求B就能查询到。如此保证了可用性但牺牲了一致性；
	4. 服务的健康检查：Eureka使用时需要显式配置健康检查支持；ZK, Etcd则在失去了和服务进程的连接情况下不健康，而Consul相对更为详细，必然内存是否已经使用了90%，文件系统的空间是否快不足了。
	5. 多数据中心支持：Consul通过WAN的Gossip协议，完成跨数据中心的同步；而且其他的产品则需要额外的开发工作来失效；
	6. KV存储服务：除了Eureka，其他几款都能够对外支持KV存储服务，所以其他几款都追求高一致性的重要原因。而提供存储服务，也能够较好的转化为动态配置服务。

SSL是Secure Sockets Layer，即安全套接层协议，是为网络通信提供安全及数据完整性的一种安全协议。
HTTPS为了兼顾安全与效率，同时使用了对称加密和非对称加密。数据是被对称加密传输的，对称加密过程需要客户端的一个密钥，为了确保能把该密钥安全传输到服务器端，采用非对称加密对该密钥进行加密。总的来说，对数据进行对称加密，对称加密所用的密钥是通过非对称加密传输。

Https协议考虑的几个问题：
	1. 兼容性；
	2. 可扩展性；
	3. 保密性(防泄密)；
	4. 完整性(防篡改)；
	5. 真实性(防假冒)；
	6. 性能；

Http版本的发展历史：
版本		产生时间			内容													发展现状
Http/0.9	1991年	不涉及数据包传输，规定客户端和服务器之间通信格式，只能Get请求		没有作为正式标准
Http/1.0	1996年	传输内容格式不限制，增加put,patch,head, options,delete命令			正式作为标准
Http/1.1	1997年	持久连接(长连接),节约带宽,Host域,管道机制,分块传输编码				2015年前最广泛
Http/2.0	2015年		多路复用，服务器推送，头信息压缩，二进制协议等					逐渐覆盖市场

针对Http的无状态的解决策略：
	1. 通过Cookie/Session技术；
	2. Http/1.1持久连接(Http keep-alive)方法，只要任意一端没有明确提出断开连接，则保持TCP连接状态，在请求首部字段中的Connection: keep-alive即为表明使用了持久连接。

为什么需要三次握手呢？为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。比如：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段，但是server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求，于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了，由于client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据，但server却以为新的运输连接已经建立，并一直等待client发来数据。所以没有采用“三次握手”，这种情况下server的很多资源就白白浪费掉了。

为什么需要四次挥手呢？TCP是全双工模式，当client发出FIN报文段时，只是表示client已经没有数据要发送了，client告诉server，它的数据已经全部发送完毕了；但是，这个时候client还是可以接受来server的数据；当server返回ACK报文段时，表示它已经知道client没有数据发送了，但是server还是可以发送数据到client的；当server也发送了FIN报文段时，这个时候就表示server也没有数据要发送了，就会告诉client，我也没有数据要发送了，如果收到client确认报文段，之后彼此就会愉快的中断这次TCP连接。

----------------------------------------------------
Https建立的过程：
	1. client向server发送请求https://baidu.com，然后连接到server的443端口，发送的信息主要是随机值1和客户端支持的加密算法。
	2. server接收到信息之后给client响应握手信息，包括随机值2和匹配好的协商加密算法，加密算法一定是client发送给server加密算法的子集。
	3. 随即server给client发送第二个响应报文是数字证书。服务端必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面，这套证书其实就是一对公钥和私钥。传送证书，这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间、服务端的公钥，第三方证书认证机构(CA)的签名，服务端的域名信息等内容。
	4. 客户端解析证书，这部分工作是由客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随机值（预主秘钥）。
	5. 客户端认证证书通过之后，接下来是通过随机值1、随机值2和预主秘钥组装会话秘钥。然后通过证书的公钥加密会话秘钥。
	6. 传送加密信息，这部分传送的是用证书加密后的会话秘钥，目的就是让服务端使用秘钥解密得到随机值1、随机值2和预主秘钥。
	7. 服务端解密得到随机值1、随机值2和预主秘钥，然后组装会话秘钥，跟客户端会话秘钥相同。
	8. 客户端通过会话秘钥加密一条消息发送给服务端，主要验证服务端是否正常接受客户端加密的消息。
	9. 同样服务端也会通过会话秘钥加密一条消息回传给客户端，如果客户端能够正常接收的话表明SSL层连接建立完成了。
----------------------------------------------------
Apache ServiceComb是业界第一个Apache微服务顶级项目，是一个开源微服务解决方案。

ServiceComb目前拥有三个主要子项目：
	1. Java chassis:开箱即用JAVA语言微服务SDK，含服务契约、编程模型、运行模式与通信模型四个部分，具备负载均衡、容错熔断、限流降级、调用链追踪等全面微服务治理能力，服务治理能力与业务逻辑隔离。
	2. Service Center：服务注册中心；基于Etcd的高性能、高可用、无状态的Golang版分布式服务注册与发现中心，可实时服务实例注册、实时服务实例推送和服务间契约测试等；
	3. Saga:分布式事务解决方案；ServiceComb Saga提供了分布式事务最终一致性解决方案，用户只需要通过注解方式定义事务的执行方法以及撤销方法，Saga框架会自动保证分布式事务执行的最终一致性。

--------------------------------------------------------------------------------
ConcurrentHashMap中类似于LongAdder的机制：

public class ConcurrentHashMap<K, V> extends AbstractMap<K, V>
	implements ConcurrentMap<K, V>, Serializable {
	...
	
	/* Base counter value, used mainly when there is no contention,
		but also as a fallback during table initialization races.
		Updated via CAS.
	*/
	private transient volatile long baseCount;
	
	/* Table initialization and resizing control. When negative, the table is being 
		initialized or resized: -1 for initialization, else -(1 + the number of active 
		resizing threads). Otherwise, when the table is null, holds the initial table size to use upon
		creation, or 0 for default. After initialization, holds the next element count value upon 
		which to resize the table.
	*/
	private transient volatile int sizeCtl;
	
	/* Spinlock (locked via CAS) used when resizing and/or creating CounterCells.
	*/
	private transient volatile int cellsBusy;
	
	/* Table of counter cells. When non-null, size is a power of 2.
	*/
	private transient volatile CounterCell[] counterCells;
	...
	
	/* -------------- Counter support ------------------*/
	/*
	/* A padded cell for distributing counts. Adapted from LongAdder and Striped64.
		See their internal docs for explanation.
	*/
	@sun.misc.Contended 
	static final class CounterCell {
		volatile long value;
		CounterCell(long x) { value = x;}
	}
	
	final long sumCount() {
		CounterCell[] as = counterCells;
		CounterCell a;
		long sum = baseCount;
		if (as != null) {
			for (int i = 0;i < as.length; ++i) {
				if ((a = as[i]) != null) {
					sum += a.value;
				}
			}
		}
		return sum;
	}
	
	// See LongAdder version for explanation
	private final void fullAddCount(long x, boolean wasUncontended) {
		int h;
		if ((h = ThreadLocalRandom.getProbe()) == 0) {
			ThreadLocalRandom.localInit();   // force initialization
			h = ThreadLocalRandom.getProbe();
			wasUncontended = true;
		}
		
		boolean collide = false;   // True if last slot nonempty
		for (;;) {
			CounterCell[] as;
			CounterCell a;
			int n;
			long v;
			
			if ((as = counterCells) != null && (n = as.length) > 0) {
				if ((a = as[(n - 1) & h]) == null) {
					if (cellsBusy == 0) {   // Try to attach new Cell
						CounterCell r = new CounterCell(x);   //Optimistic create 
						if (cellsBusy == 0 && U.compareAndSwapInt(this, CELLBUSY, 0, 1) {
							boolean created = false;
							try {   // Recheck under lock
								CounterCell[] rs;
								int m, j;
								if ((rs = counterCells) != null && 
									(m = rs.length) > 0 && 
									rs[j = (m - 1) & h] == null) {
									rs[j] = r;
									created = true;
								}
							} finally {
								cellsBusy = 0;
							}
							if (created)
								break;
							continue;
						}
					}
					collide = false;
				} else if (!wasUncontended) {   //CAS already known to fail
					wasUncontended = true;   // Continue after rehash
				} else if (U.compareAndSwapLong(a, CELLVALE, v = a.value, v + x)) {
					break;
				} else if (counterCells != as || n > NCPU) {
					collide = false;   // At max size or stale
				} else if (!collide) {
					collide = true;
				} else if (cellsBusy == 0 && U.compareAndSwapInt(this, CELLBUSY, 0, 1)) {
					try {
						if (counterCells == as) {   // Expand table unless stale 
							CounterCell[] rs = new CounterCell[n << 1];
							for (int i = 0;i < n;i ++)
								rs[i] = as[i];
							counterCells = rs;
						}
					} finally {
						cellsBusy = 0;
					}
					collide = false;
					continue;   // Retry with expanded table
				}
				h = ThreadLocalRandom.advanceProbe(h);
			} else if (cellsBusy == 0 && counterCells == as 
					&& U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
				boolean init = false;
				try {   // Initialize table
					if (counterCells == as) {
						CounterCell[] rs = new CounterCell[2];
						rs[h & 1] = new CounterCell(x);
						counterCells = rs;
						init = true;
					}
				} finally {
					cellsBusy = 0;
				}
				if (init) {
					break;
				}
			} else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v+x)) {
				break;   //Fall back on using base
			}
		}
	}
	...
}

ConcurrentHashMap中@sun.misc.Contended的应用:
    /* ---------------- Counter support -------------- */

    /**
     * A padded cell for distributing counts.  Adapted from LongAdder
     * and Striped64.  See their internal docs for explanation.
     */
    @sun.misc.Contended static final class CounterCell {
        volatile long value;
        CounterCell(long x) { value = x; }
    }
--------------------------------------------------------------------------------
从简单的生产者消费者模式设计到如何高效健壮实现：
	1. 多生产者的竞争: 参考LongAdder的实现
	2. 模拟偏向锁，每个子容器的线程占用，升级到重量级锁，然后适当时机增加子容器数目；
	3. 多消费者
	4. 提供带超时机制的poll, peek, offer;
	5. Condition notEmpty = lock.newCondition();
		Condition notFull = lock.newCondition();
	6. Object.notifyAll(), Object.wait()
	7. try*类似接口
	8. 分布式的解决方案: MQ

notify/notifyAll()执行后，并不立即释放锁，而是等到执行完临界区中代码后，再释放。所以在实际编程中，应该尽量在线程调用notify/notifyAll()后，立即退出临界区。即不要在notify/notifyAll()后面再写一些耗时的代码。

Consul的四大核心特性：
	1. 服务发现：可以方便的实现服务注册通过DNS或者HTTP应用程序可以很容易的找到它所依赖的服务；
	2. KV存储：使用Key/Value进行数据存储；
	3. 多数据中心：Consul支持开箱即用的多数据中心。这意味着用户不需要担心建立额外的抽象层让业务扩展到多个区域；
	4. 健康检查：可以对指定服务进行健康检查例如Response Status是否为200避免将流量转发到不健康的服务上。

由程序产生的地址称为虚拟地址，它们构成了一个虚拟地址空间。在没有虚拟内存的计算机上，系统直接把虚拟地址送到内存总线上，读写操作使用具有相同地址的物理内存地址；而在使用虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是被送到内存管理单元(Memory Management Unit, MMU)， MMU把虚拟地址映射为物理内存地址。
虚拟地址空间按照固定大小划分为称为页面Page的若干单元。在物理内存中对应的单元称为页框。页面和页框的大小通常是一样的。实际系统中的页面大小从512字节到1GB.

虚拟地址被分成虚拟页号（高地址）和偏移量（低地址）两部分。不同的划分对应了不同的页面大小。
    虚拟页号可作为页表的索引，以找到该虚拟页面对应的页表项。由页表项可以找到对应的页框。然后把页框号拼接到偏移量的高位端，以替换调虚拟页号，形成送往内存的物理地址。
    页表的目的是把虚拟页面映射为页框，把虚拟地址中的虚拟页面域替换成页框域，从而形成物理地址（本篇博客讨论的情况均不涉及虚拟机，每个虚拟机都需要有自己的虚拟内存，因此页表组织变得很复杂，包括影子页表和嵌套页表）。

--------------转换检测缓冲区-------------------
       大多数程序总是对少量的页面进行多次的访问，只有很少的页表项会被反复读取，而其他大的页表项很少被访问。利用这种特性有一种解决方案：为计算机设计一个小型的硬件设备，将虚拟地址直接映射到物理地址，而不必再访问页表。这种设备称为转换检测缓冲区（Translation Lookaside Buffers，TLB），有时又称为相联存储器或快表。它通常在MMU中，包含少量的表项，在实际中很少会超过256个。每个表项记录了一个页面的相关信息，包括虚拟页号、页面的修改位、保护码和该页所对应的物理页框，还有另外一位用来记录这个表项是否有效（即是否在使用）。
       TLB的工作过程：将一个虚拟地址放入MMU中进行转换时，硬件首先通过将该虚拟页号与TLB中所有表项同时（并行）进行匹配，判断虚拟页面是否在其中。如果发现在，并且不违反保护码，则将页框号直接从TLB中取出而不必再访问页表。如果违反了保护码，则会产生一个保护错误，就像对页表进行非法操作一样。如果虚拟页号不在TLB中，此时就会去进行正常的页表查询。接着从TLB中淘汰掉一个表项，然后用找到的页表项代替它。当一个表项被清除除TLB时，将修改位复制到内存中的页表项，而除了访问位，其他的值不变。当页表项中从页表中装入TLB中时，所有的值都来自内存。
---------------------------------
Vert.x最大的特点就在于异步(底层基于Netty)，通过事件循环(EventLoop)来调起存储在异步队列(CallBackQueue)中的任务，大大降低了传统阻塞模型中线程对于操作系统的开销。因此相比传统的阻塞模型，异步模型能够很大程度的提高系统的并发量。
Vert.x除了异步之外，还提供了非常多的技术，比如EventBus，通过EventBus可以非常简单的实现分布式消息，进而为分布式系统调用、微服务奠定基础。除此之外，还提供了对多种客户端的支持，比如Redis、RabbitMQ、Kafka等等。
Vert.x异步也带来了编码上的复杂性，想要编写优美的异步代码，就需要对lambda表达式、函数式编程、Reactive等技术非常熟悉才行，否则很容易导致代码糟糕，完全没有可读性。另外，异步模型的性能调优、异常处理与同步模型有很大差。
Vert.x运行在JVM虚拟机上，支持多种编程语言，Vert.x是高度模块化的，同一个应用，可以选择多种编程语言同时开发。在Vert.x 2版本基于JDK7，没有lambda表达式，一般来讲使用javascript作为开发语言相对较多，到Vert.x3时代，因为JDK8的出现，Java已经作为Vert.x主流开发语言，而Vert.x也被更多开发者接受。

Vert.x可以做的事情：Java能做的，Vert.x都能做。
（1）Web开发，Vert.x封装了Web开发常用的组件，支持路由、Session管理、模板等，可以非常方便的进行Web开发。不需要容器！不需要容器！不需要容器！
（2）TCP/UDP开发，Vert.x底层基于Netty，提供了丰富的IO类库，支持多种网络应用开发。不需要处理底层细节（如拆包和粘包），注重业务代码编写。
（3）提供对WebSocket的支持，可以做网络聊天室，动态推送等。
（4）Event Bus（事件总线）是Vert.x的神经系统，通过Event Bus可以实现分布式消息，远程方法调用等等。正是因为Event Bus的存在，Vert.x可以非常便捷的开发微服务应用。
（5）支持主流的数据和消息的访问;redis mongodb rabbitmq kafka等
（6）分布式锁，分布式计数器，分布式map的支持
---------------------------------
根据一个项目，如果量级扩大1000倍，会怎么做？有哪些优化措施？高性能&高可用措施？
	1. 冷热数据分离；
	2. 冷数据提前做好归总汇集，按查询维度、指标做好汇总表；
	3. 将查询量大的热数据放在缓存中，并做好数据分片；每日对账清结算后，将增量数据更新到缓存；
	4. 分库分表：注意数据一致性，特别是主从库的延迟。通过缓存30分钟的数据来覆盖延迟时间差；
	5. 微服务的拆分，分布式处理；
	6. 动态扩容/缩容；
	7. 降级熔断保护系统不被压垮；
	8. 部分不可变数据的多级缓存：分布式缓存+本地缓存；
	9. 部分高并发逻辑，并且不要求实时处理的，进行异步处理，使用Kafka来做削峰填谷，避免压垮系统；
	10. 为了防止压垮别的系统，也会对部分高并发业务且不要求实时处理的，直接异步处理；
	11. 如果再有高并发请求：不直接落库DB，双写到分布式缓存和Kafka，从分布式缓存的从库慢慢写入数据库，用Kafka来进行兜底保障；
	12. 分库分表，读写分离；
	13. 合理的索引，合理的数据表结构；
	14. Java更加合理是算法和数据结构：LongAdder，CopyOnWriteArrayList, 分布式锁的合理使用，分布式事务的最终一致性，无锁化设计；
	15. 网络连接内部改为长连接，比如使用Netty；
	16. 性能测试，找出热点函数，进行优化；
	17. JVM相关的优化；
	18. 多数据中心部署；
	19. 部分请求的CDN
	20. 海量数据的查询、统计考虑用ElasticSearch来支持高并发；
	21. 
---------------------------------
ConcurrentHashMap最耗时的操作是扩容resize, 所以对扩容操作进行优化可以很大程度上提高性能，而这个优化手段就是让并发执行put操作的线程协助搬运bin中的Node，把数据项从老数组转移到新数组，从而加速resize操作。具体方案是：在执行put操作的线程中，第一个发现需要扩容的线程负责分配新数组、开始转移部分Node，每次处理一个bin；此后，其他发现有resize正在进行中的线程参与到转移Node工作；其他也在执行put操作但不参与转移工作的线程继续执行原来的put操作(先在原数组中找到bin，如果遇到FowardingNode，则在新数组中插入)；执行get操作的线程不参与转移工作，遇到FordwardingNode则到新数组查询。
具体怎么迁移：参与迁移的线程通过transferIndex字段声明自己要迁移哪些bin。同时，为了防止这些线程所迁移的bin有重叠的，迁移线程会在sizeCtl变量中保存一个stamp提供区分的作用。为了不影响正在对ConcurrentHashMap进行遍历操作的线程，迁移工作从最后一个bin开始(table.length - 1)，逐步往前处理，直到处理完第一个。每迁移完成一个bin或正在迁移当前bin，这里的位置就被放入一个FordwardingNode。因为迁移Node操作需要较长时间，FordwardingNode让其他执行put/get遍历操作的线程可以继续访问。

SSL: Secure Socket Layer 安全套接层
TLS: Transport Layer Security 传输层安全

notify/notifyAll信号丢失问题；执行等待的线程都需要一个等待条件，为了避免出现丢失的信号，仍然需要对条件变量进行while循环的判断。

关于等待通知机制的几点要求：
	1. 每当在等待一个条件时，一定要确保在条件变量变为真的时候才发出唤醒的通知；
	2. 在调用wait/notify/notifyAll方法时，必须首先获得锁；
	3. 每次调用完wait方法，获得锁就会自动释放；
	4. 调用notify时，JVM从等待队列中的一个线程进行唤醒；notifyAll将等待队列中的所有线程都唤醒；
	5. 只有同时满足两个条件才能使用notify:
		一是所有等待线程的类型都相同，这就是说，等待队列只与一个条件变量相关，并且所有的线程在唤醒后执行的都是相同的操作；
		二是单进单出，也就是说在条件变量的每个通知，要求只能最多唤醒一个线程。
	
假唤醒：假唤醒就是在没有线程调用notify或notifyAll方法的情况下被唤醒。为了防止假唤醒，保存的条件变量需要在while循环中进行检测，而不是在if表达式里。这样的一个while循环叫做自旋锁（校注：这种做法要慎重，目前的JVM实现自旋会消耗CPU，如果长时间不调用doNotify方法，doWait方法会一直自旋，CPU会消耗太大）。被唤醒的线程会自旋直到自旋锁(while循环)里的条件变为false。
-------------------------------------
Consul的机制，和其他注册中心的对比(ZK, Eureka)

主流注册中心产品的比对矩阵：
					Nacos						Eureka			Consul				CoreDNS		Zookeeper
一致性协议			CP+AP						AP				CP					-			CP
健康检查 			TCP/HTTP/MySQL/Client Beat	Client Beat		TCP/HTTP/gRPC/Cmd	-			Keep Alive
负载均衡策略		权重/metadata/Selector		Ribbon			Fabio				RoundRobin	-
雪崩保护			有							有 				无 					无 			无
自动注销实例		支持 						支持 			不支持 				不支持 		支持
访问协议 			HTTP/DNS					HTTP			HTTP/DNS 			DNS			TCP
监听支持			支持  						支持  			支持 				不支持 		支持 
多数据中心 			支持 						不支持 			支持 				不支持 		不支持
跨注册中心同步		支持   						支持 			支持 				不支持 		不支持
SpringCloud集成		支持 						支持 			支持 				不支持		支持 
Dubbo集成			支持						不支持 			不支持 				不支持   	支持
K8S集成				支持 						不支持 			支持 				支持 		不支持
-------------------------------------
一旦一个线程被唤醒，不能立刻就退出wait()的方法调用，直到调用notify()的线程退出了自己的同步块。换句话说：被唤醒的线程必须重新获得监视器对象的锁，才可以退出wait()的方法调用，因为wait方法调用运行在同步块里面。如果多个线程被notifyAll()唤醒，那么同一时刻将只有一个线程可以退出wait()方法，因为每个线程在退出wait()前必须获得监视器对象的锁。

丢失的信号: Missed Signals.
伪唤醒/假唤醒

RPC的主要功能目标是让构建分布式计算(应用)更容易，在提供强大的远程调用能力时不损失本地调用的语义简洁性。为实现该目标，RPC框架需提供一种透明调用机制让使用者不必显式的区分本地调用和远程调用。

RPC服务方通过RPCServer去导出(export)远程接口方法，而客户方通过RPCClient去引入(import)远程接口方法。客户方像调用本地方法一样调用远程接口方法，RPC框架提供接口的代理实现，实际的调用将委托给代理RPCProxy。代理封装调用信息并将调用转交给RPCInvoker去实际执行。在客户端的RPCInvoker通过连接器RPCConnector去维护与服务端的通道RPCChannel，并使用RPCProtocol执行协议编码(encode)并将编码后的请求消息通过通道发送给服务方。
RPC服务端接收器RPCAcceptor接收客户端的调用请求，同样使用RPCProtocol执行协议解码(decode)。解码后的调用信息传递给RPCProcessor去控制处理调用过程，最后再委托调用给RPCInvoker去实际执行并返回调用结果。

调用过程的控制需要考虑哪些因素，RPCProcessor需要提供什么样的调用控制服务呢？需要考虑几点：
	1. 效率提升：每个请求应该尽快被执行，因此不能每个请求来时再创建线程去执行，需要提供线程池服务；
	2. 资源隔离：当我们导出多个远程接口时，如何避免单一接口调用占据所有资源，而引发其他接口阻塞；
	3. 超时控制：当某个接口执行缓慢，而Client端已经超时放弃等待后，Server端的线程继续执行显得无意义；

Dubbo的RPC流程：服务引用、服务暴露、服务调用三个部分；
在Dubbo中有两个核心概念：
	1. Invoker:Dubbo的核心模型，其他模型都向他靠拢，或转换成它，它代表一个可执行体，可向他发起invoke调用；
	2. Protocol:是Invoker暴露和引用的主功能入口，它负责Invoker的生命周期；

Dubbo基于扩展点的自适应机制(SPI),会自动识别URL中的协议类型，并调用合适的Protocol实现类，默认用的是Dubbo协议，因此会调用DubboProtocol进行服务引用；
ProxyFactory同样是扩展点，默认使用了JavassitProxyFactory的实现。可以看到创建的代理，把对接口的调用交给了InvokerInvocationHandler这个类去处理。

Zookeeper和Consul保证的是CP，而Eureka则是AP，Nacos不仅支持CP也支持AP。

Eureka还有一种自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现几种情况：
	1. Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务；
	2. Eureka仍然能够接收服务的注册和查询请求，但是不会被同步到其他节点上(即保证当前节点依然可用);
	3. 当网络稳定时，当前实例新的注册信息被同步到其他节点；

缓存行是处理器高速缓存中最小的存储单位，一般是64字节。内存中的连续64字节会被加载到一个缓存行。内存中的连续64字节会被加载到一个缓存行中。如果访问一个long数组，当数组中的一个值被加载到缓存中，它会额外加载另外7个；其实Java对象的相邻成员变量会加载到同一缓存行中。

伪共享：如果多个线程操作不同的成员变量，但是这些变量存储在同一个缓存行，如果有处理器更新了缓存行的数据并刷新到主存后根据缓存一致性原则，其他处理器将失效缓存行(I状态)导致缓存未命中，需要重新去内存中读取最新数据，这就是伪共享问题。特别是不同的线程操作同一个缓存行，需要发出RFO(Request for Owner)信号锁定缓存行，保证写操作的原子性，此时其他线程不能操作这个缓存行，这将对效率有极大的影响。

越靠近CPU的缓存越快也越小。所以L1缓存很小但很快，并且紧靠在使用它的CPU内核。L2大一些，也慢一些，并且仍然只能被一个单独的CPU核使用。L3在现代多核机器中更普遍，仍然更大、更慢，并且被单个插槽上的所有CPU核共享。最后是一块主存，由全部插槽上的所有CPU核共享。

JDK6解决伪共享：缓存行填充Padding无用的字段。
JDK7解决伪共享：缓存行填充Padding，在JDK7已经不适用了，因为JDK7会优化掉无用的字段。需要使用继承的办法来避免填充被优化掉。把Padding放在父类中，可以避免优化。
JDK8解决伪共享：被原生支持，添加@Contended注解。需要添加JVM参数：-XX:-RestrictContended

AKKA是Java虚拟机平台上构建高并发、分布式和容错应用的工具包和运行时。AKKA用Scala语言开发，同时提供了Scala和Java的开发接口。AKKA处理并发的方法基于Actor模型，Actor之间通信的唯一机制就是消息传递。
AKKA特点：
	1. 对并发模型进行了更高的抽象；
	2. 是异步、非阻塞、高性能的事件驱动编程模型；
	3. 是轻量级事件处理(1GB内存可容纳百万级别个Actor)；
	4. 提供了一种称为Actor的并发模型，其粒度比线程更小，可以在系统中启用大量的Actor；
	5. 它提供了一套容错机制，允许在Actor出现异常时进行一些恢复或重置操作；
	6. AKKA既可以在单机上构建高并发程序，也可以在网络中构建分布式程序，并提供位置透明的Actor定位服务；
	
因此，企业IT所面临的首要挑战就是整合企业中大量竖桶型(silo-ed)的IT系统，支撑日益复杂的业务流程，进行高效的业务决策和支撑业务快速变化。
在这种背景下，IBM等公司提出了SOA(面向服务的架构)理念，将应用系统抽象成一个个粗粒度的服务，构建松耦合服务架构，可以通过业务流程对服务进行灵活组合，提升企业IT资产复用，提高了系统的适应性、灵活性和扩展性，解决"信息孤岛"问题。

微服务架构首先要面对分布式架构的内生复杂性。微服务框架需要能够解决服务通信和服务治理的复杂性，比如服务发现、熔断、限流、全链路追踪等挑战。

SOA采用中心化的服务总线架构，解耦了业务逻辑和服务治理逻辑；微服务架构回归了去中心化的点对点调用方式，在提升敏捷性和可伸缩性的同时，也牺牲了业务逻辑和服务治理逻辑解耦所带来的灵活性。
为了解决上述挑战，社区提出了ServiceMesh(服务网格)架构。它重新将服务治理能力下沉到基础设施，在服务的消费者和提供者两侧以独立进程的方式部署。
这样既达到了去中心化的目的，保障了系统的可伸缩性；也实现了服务治理和业务逻辑的解耦，二者可以独立演进不互相干扰，提升了整体架构演进的灵活性。同时服务网格架构减少了对业务逻辑的侵入，降低了多语言支持的复杂性。

Istio提供了一系列高阶的服务治理能力，比如：服务发现和负载均衡，渐进式交付(灰度发布)，混沌注入与分析，全链路追踪，零信任网络安全等，可以供上层业务系统将其编排到自己的IT架构和发布系统之中。
但Service Mesh不是银弹，其架构选择是通过增加部署复杂性(sidecar)和损失性能(增加两跳),来换取架构的灵活性和系统的可演化性。

以上就是传统架构和现代架构的一个简单比对，现在架构上整个消息的同步、存储和索引流程，并没有变复杂太多。现代架构的实现本质上是把传统架构内本地存储和索引都搬到云上，最大挑战是需要集中管理全量消息的存储和索引，带来的好处是实现多端同步、消息漫游以及在线检索。可以看到现代架构中最核心的就是两个消息库“消息同步库”和“消息存储库”，以及对“消息存储库”的"消息索引"的实现。

Survivor的存在意义就是减少被送到老年代的对象，进而减少MajorGC的发生。Survivor的预筛选保证，只有经历一定次数MinorGC还能在新生代中存活的对象，才会被送到老年代。

Future接口代表了一个异步任务的结果，提供了相应方法判断任务是否完成或者取消。RunnableFuture同时继承了Future和Runnable，是一个可运行、可知结果的任务，FutureTask是具体的实现类。

public class FutureTask<V> implements RunnableFuture<V> {
	private volatile int state;
	//The underlying callable; nulled out after runing
	private Callable<V> callable;
	//The result to return or exception to throw from get()
	private Object outcome;
	//The thread running the callable; CASed during run();
	private volatile Thread runner;
	//Treiber stack of waiting threads
	private volatile WaitNode waiters;
	
	...
}

Future模式之CompletableFuture

public class CompletableFuture<T> implements Future<T>, CompletionStage<T> {
	...
}

CompletableFuture是JDK8新增的API，该类实现Future和CompletionStage两个接口，提供了非常强大的Future的扩展功能，可以简化异步编程的复杂性，提供了函数式编程的能力，可以通过回调的方式处理计算结果，并且提供了转换和组合CompletableFuture的方法。

JWarmup的基本原理：根据前一次程序运行的情况，记录下热点方法、类编译顺序等信息，在应用下一次启动的时候积极加载相关的类，并积极编译相关的方法，进而应用启动后可以直接运行编译好的Java代码(C2编译)。
JWarmup典型的用法：
	1. 在Beta灰度环境，进行应用压测，记录下热点方法、类编译顺序等信息；
	2. 在Production环境，使用提前记录的profiling data提前编译热点方法；

-------------------------------------------------------------
什么是Gossip协议：
Gossip Protocol利用一种随机的方式将信息散播到整个网络中。正如Gossip本身的含义一样，Gossip协议的工作流程即类似于绯闻的传播，或者流行病的传播。具体而言Gossip Protocol可以分为Push-based和Pull-based两种。
Push-based Gossip Protocol的具体工作流程如下：
	1. 网络中的某个节点随机的选择其他b个节点作为传输对象。
	2. 该节点向其选中的b个节点传输相应的信息
	3. 接收到信息的节点重复完成相同的工作

Pull-based Gossip Protol的协议过程刚好相反：
	1. 某个节点v随机的选择b个节点询问有没有最新的信息
	2. 收到请求的节点回复节点v其最近未收到的信息
当然，为了提高Gossip协议的性能，还有基于Push-Pull的混合协议。同时需要注意的是Gossip协议并不对网络的质量做出任何要求，也不需要loss-free的网络协议。Gossip协议一般基于UDP实现，其自身即在应用层保证了协议的robustness。

仅需要O(log(N))个回合，Gossip协议即可将信息传递到所有的节点。根据分析可得，Gossip协议具有以下的特点：
	- 低延迟；仅仅需要O(log(N))个回合的传递时间；
	- 非常可靠；仅有1/ncb - 2个节点不会收到信息；
	- 轻量级；每个节点传送了cblog(N)次信息；

memberlist是HashiCorp公司开源的Gossip库，这个库被Consul(也是HashiCorp公司开源)所引用。
-------------------------------------------------------------
InnoDB为了让表锁和行锁共存而使用了意向锁。
如果没有意向锁，事务B为了获取表级锁，需要进行下列步骤：
	step1：判断表是否已被其他事务用表锁锁表
	step2：判断表中的每一行是否已被行锁锁住。

注意step2中通过遍历查询，这样的判断方法效率实在不高，因为需要遍历整个表。

于是就有了意向锁。在意向锁存在的情况下，事务A必须先申请表的意向共享锁，成功后再申请一行的行锁。

在意向锁存在的情况下，上面的判断可以改成
	step1：不变
	step2：发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。
结论：
	1. 申请意向锁的动作是数据库完成的，就是说，事务A申请一行的行锁的时候，数据库会自动先申请表的意向锁，不需要显式申请；
	2. IX(意向排他锁)，IS(意向共享锁)是表级锁，不会和行级的X，S锁发生冲突。只会和表级的X,S发生冲突。
意向锁的存在是为了协调行锁和表锁的关系，支持多粒度(行锁和表锁)的锁并存。	
例子：事务A修改user表的记录r，会给记录r上一把行级的排他锁（X），同时会给user表上一把意向排他锁（IX），这时事务B要给user表上一个表级的排他锁就会被阻塞。意向锁通过这种方式实现了行锁和表锁共存且满足事务隔离性的要求。

注意：上了行级X锁后，行级X锁不会因为有别的事务上了IX而阻塞，MySQL允许多个行级X锁同时存在，只要不是同一行的锁就可以。

间隙锁可用于防止幻读，保证索引间不会被插入数据。

查看事务、锁的SQL:
select * from information_schema.innodb_locks;
select * from information_schema.innodb_lock_waits;
select * from information_schema.innodb_trx;	

public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer
	implements java.io.Serializable {
	...
	/* Condition implements for a AbstractQueuedSynchronizer serving as the basis of a Lock implementation.
	
	Method document for this class describes mechanics, not behavioral specifications from the point of view of Lock and Condition users. Exported versions of this class will in general need to be accompanied by documentation describing condition semantics that rely on those of the associated AbstractQueuedSynchronizer.
	This class is Serializable, but all fields are transient, so deserialized conditions have no waiters.
	*/
	public class ConditionObject implements Condition, java.io.Serializable {
		private static final long serialVersionUID = *L;
		private transient Node firstWaiter;
		private transient Node lastWaiter;
		
	}
	...
}

