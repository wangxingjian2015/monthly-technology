@SuppressWarnings("serial")
public class DefaultAopProxyFactory implements AopProxyFactory, Serializable {
	@Ovrride
	public AopProxy createAopProxt(AdvisedSupport config) throws AopConfigException {
		if (config.isOptimize() || config.isProxyTargetClass() 
				|| hasNoUserSuppliedProxyInterfaces(config)) {
			Class<?> targetClass = config.getTargetClass();
			if (targetClass == null) {
				throw new AopConfigException("TargetSource cannot determine target class:" 
					+ "Either an interface or a target is required for proxy creation.");
			}
			if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) {
				return new JdkDynamicAopProxy(config);
			}
			return new ObjenesisCglibAopProxy(config);
		} else {
			return new JDKDynamicAopProxy(config);
		}
	}
}

final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable {
	...
	// Config used to configure this proxy 
	private final AdvisedSupport advised;
	// Is the equals mehtod defined on the proxied interfaces?
	private boolean equalsDefined;
	// Is the hashCode method defined on the proxied interfaces?
	private boolean hashCodeDefined;
	...
	// Implementation of InvocationHandler.invoke. Callers will see exactly the 
	// exception thrown by the target, unless a hook method throws an exception. 
	@Ovrride 
	@Nullable
	public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
		MethodInvocation invocation;
		Object oldProxy = null;
		boolean setProxyContext = false;

		TargetSource targetSource = this.advised.targetSource;
		Object target = null;

		try {
			if (!this.equalsDefined && AopUtils.isEqualsMethod(method)) {
				// The target does not implement the equals(Object) method itself.
				return equals(args[0]);
			}
			else if (!this.hashCodeDefined && AopUtils.isHashCodeMethod(method)) {
				// The target does not implement the hashCode() method itself.
				return hashCode();
			}
			else if (method.getDeclaringClass() == DecoratingProxy.class) {
				// There is only getDecoratedClass() declared -> dispatch to proxy config.
				return AopProxyUtils.ultimateTargetClass(this.advised);
			}
			else if (!this.advised.opaque && method.getDeclaringClass().isInterface() &&
					method.getDeclaringClass().isAssignableFrom(Advised.class)) {
				// Service invocations on ProxyConfig with the proxy config...
				return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args);
			}

			Object retVal;

			if (this.advised.exposeProxy) {
				// Make invocation available if necessary.
				oldProxy = AopContext.setCurrentProxy(proxy);
				setProxyContext = true;
			}

			// Get as late as possible to minimize the time we "own" the target,
			// in case it comes from a pool.
			target = targetSource.getTarget();
			Class<?> targetClass = (target != null ? target.getClass() : null);

			// Get the interception chain for this method.
			List<Object> chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);

			// Check whether we have any advice. If we don't, we can fallback on direct
			// reflective invocation of the target, and avoid creating a MethodInvocation.
			if (chain.isEmpty()) {
				// We can skip creating a MethodInvocation: just invoke the target directly
				// Note that the final invoker must be an InvokerInterceptor so we know it does
				// nothing but a reflective operation on the target, and no hot swapping or fancy proxying.
				Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);
				retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse);
			}
			else {
				// We need to create a method invocation...
				invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain);
				// Proceed to the joinpoint through the interceptor chain.
				retVal = invocation.proceed();
			}

			// Massage return value if necessary.
			Class<?> returnType = method.getReturnType();
			if (retVal != null && retVal == target &&
					returnType != Object.class && returnType.isInstance(proxy) &&
					!RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) {
				// Special case: it returned "this" and the return type of the method
				// is type-compatible. Note that we can't help if the target sets
				// a reference to itself in another returned object.
				retVal = proxy;
			}
			else if (retVal == null && returnType != Void.TYPE && returnType.isPrimitive()) {
				throw new AopInvocationException(
						"Null return value from advice does not match primitive return type for: " + method);
			}
			return retVal;
		}
		finally {
			if (target != null && !targetSource.isStatic()) {
				// Must have come from TargetSource.
				targetSource.releaseTarget(target);
			}
			if (setProxyContext) {
				// Restore old proxy.
				AopContext.setCurrentProxy(oldProxy);
			}
		}
	}
	...
}

// A simple but definitive way of working out an advice chain for a Method,
// given an #Advised object. Always rebuilds each advice chain; caching can be provided by subclasses.
@SuppressWarnings("serial")
public class DefaultAdvisorChainFactory implements AdvisorChainFactory, Serializable {
	@Ovrride 
	public List<Object> getInterceptorsAndDynamicInterceptionAdvice(Advised config, Method method, 
							@Nullable Class<?> targetClass) {
		// This is somewhat tricky... We have to process introductions first,
		// but we need to preserve order in the ultimate list.
		AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance();
		Advisor[] advisors = config.getAdvisors();
		List<Object> interceptorList = new ArrayList<>(advisors.length);
		Class<?> actualClass = (targetClass != null ? targetClass : method.getDeclaringClass());
		Boolean hasIntroductions = null;

		for (Advisor advisor : advisors) {
			if (advisor instanceof PointcutAdvisor) {
				// Add it conditionally.
				PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor;
				if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) {
					MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher();
					boolean match;
					if (mm instanceof IntroductionAwareMethodMatcher) {
						if (hasIntroductions == null) {
							hasIntroductions = hasMatchingIntroductions(advisors, actualClass);
						}
						match = ((IntroductionAwareMethodMatcher) mm).matches(method, actualClass, hasIntroductions);
					} else {
						match = mm.matches(method, actualClass);
					}
					if (match) {
						MethodInterceptor[] interceptors = registry.getInterceptors(advisor);
						if (mm.isRuntime()) {
							// Creating a new object instance in the getInterceptors() method
							// isn't a problem as we normally cache created chains.
							for (MethodInterceptor interceptor : interceptors) {
								interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm));
							}
						} else {
							interceptorList.addAll(Arrays.asList(interceptors));
						}
					}
				}
			} else if (advisor instanceof IntroductionAdvisor) {
				IntroductionAdvisor ia = (IntroductionAdvisor) advisor;
				if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) {
					Interceptor[] interceptors = registry.getInterceptors(advisor);
					interceptorList.addAll(Arrays.asList(interceptors));
				}
			} else {
				Interceptor[] interceptors = registry.getInterceptors(advisor);
				interceptorList.addAll(Arrays.asList(interceptors));
			}
		}

		return interceptorList;
	}
}

@SuppressWarnings("serial")
class CglibAopProxy implements AopProxy, Serializable {
	...
	//General purpose AOP callback. Used when the target is dynamic or when the 
	// proxy is not frozen.
	private static class DynamicAdvisedInterceptor implements MethodInterceptor, Serializable {
		private final AdvisedSupport advised;
		public DynamicAdvisedInterceptor(AdvisedSupport advised) {
			this.advised = advised;
		}

		@Override
		@Nullable
		public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) 
			throw Throwable {
			Object oldProxy = null;
			boolean setProxyContext = false;
			Object target = null;
			TargetSource targetSource = this.advised.getTargetSource();
			try {
				if (this.advised.exposeProxy) {
					// Make invocation available if necessary.
					oldProxy = AopContext.setCurrentProxy(proxy);
					setProxyContext = true;
				}
				// Get as late as possible to minimize the time we "own" the target, in case it comes from a pool...
				target = targetSource.getTarget();
				Class<?> targetClass = (target != null ? target.getClass() : null);
				List<Object> chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);
				Object retVal;
				// Check whether we only have one InvokerInterceptor: that is,
				// no real advice, but just reflective invocation of the target.
				if (chain.isEmpty() && Modifier.isPublic(method.getModifiers())) {
					// We can skip creating a MethodInvocation: just invoke the target directly.
					// Note that the final invoker must be an InvokerInterceptor, so we know
					// it does nothing but a reflective operation on the target, and no hot
					// swapping or fancy proxying.
					Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);
					retVal = methodProxy.invoke(target, argsToUse);
				}
				else {
					// We need to create a method invocation...
					retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed();
				}
				retVal = processReturnType(proxy, target, method, retVal);
				return retVal;
			}
			finally {
				if (target != null && !targetSource.isStatic()) {
					targetSource.releaseTarget(target);
				}
				if (setProxyContext) {
					// Restore old proxy.
					AopContext.setCurrentProxy(oldProxy);
				}
			}
		}

		@Override
		public boolean equals(Object other) {
			return (this == other ||
					(other instanceof DynamicAdvisedInterceptor &&
							this.advised.equals(((DynamicAdvisedInterceptor) other).advised)));
		}

		/**
		 * CGLIB uses this to drive proxy creation.
		 */
		@Override
		public int hashCode() {
			return this.advised.hashCode();
		}
	}
	...
}

SOA采用中心化的服务总线架构，解耦了业务逻辑和服务治理逻辑；微服务架构回归了去中心化的点对点调用方式，在提升敏捷性和可伸缩性的同时，也牺牲了业务逻辑和服务治理逻辑解耦所带来的灵活性。
为了解决上述挑战，社区提出了Service Mesh(服务网格)架构。它重新将服务治理能力下沉到基础设施，在服务的消费者和提供者两侧以独立进程的方式部署。
这样既达到了去中心化的目的，保障了系统的可伸缩性；也实现了服务治理和业务逻辑的解耦，二者可以独立演进不互相干扰，提升了整体架构演进的灵活性。同时服务网格架构减少了对业务逻辑的侵入性，降低了多语言支持的复杂性。
Istio 提供了一系列高阶的服务治理能力，比如：服务发现和负载均衡，渐进式交付(灰度发布)，混沌注入与分析，全链路追踪，零信任网络安全等，可以供上层业务系统将其编排到自己的 IT 架构和发布系统之中。
但是 Service Mesh 不是银弹，其架构选择是通过增加部署复杂性（sidecar）和损失性能（增加两跳），来换取架构的灵活性和系统的可演化性。

Java创建线程的方式：
	1. 继承Thread类
	2. 覆写Runnable接口
	3. 覆写Callable接口
	4. 通过线程池启动

Apace Shiro是一个强大且易用的Java安全框架，执行身份验证、授权、密码和会话管理。有三个核心组件：Subject, SecurityManager和Realms.

微服务之间的安全认证：
	1. 黑白名单机制；
	2. 服务注册/发现时的认证;
	3. 服务发现时，扩展注册中心，只给授权的服务列表；
	4. 服务调用时，去注册中心查看是否允许调用；为了保证有效性，可定期或注册中心推送来验证消费者的合法性；
	5. 在Provider进行验证，每次只允许特定的服务调用，登陆/验证通过后，赋值JWT。同样有有效期的限制。

Eureka Server增加安全机制: 引入Spring Security，设置用户名/密码，


1. 浏览器把自身支持的一系列Cipher Suite(密码算法套件)发给服务器；
2. 服务器接收到浏览器的所有Cipher后，与自己支持的套件进行比对，如果找到双方都支持的Cipher，则告知浏览器。

TLS_RSA_WITH_AES_128_CBC_SHA
TLS_RSA_WITH_AES_256_CBC_SHA
TLS_RSA_WITH_RC4_128_SHA
TLS_RSA_WITH_3DES_EDE_CBC_SHA
TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA_P256
TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA_P384
TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA_P521
TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA_P256
TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA_P384
TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA_P521
Cipher的一长串数字的含义，由四部分组成：
	1. 密钥交换算法，用于决定客户端与服务器之间在握手的过程中如何认证，用到的算法包括RSA，Diffie-Hellman, ECDH， PSK等；
	2. 加密算法，用于加密消息流，该名称后通常会带有两个数字，分别表示密钥的长度和初始向量的长度，比如DES 56/56, RC2 56/128, RC4 128/128, AES 256/256;
	3. 报文认证信息码(MAC)算法，用于创建报文摘要，确保消息的完整性(没有被篡改)，算法包括MD5,SHA等；
	4. PRF(伪随机数函数)，用于生成"master secret"。

TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,可以知道：
基于TLS协议的；使用ECDHE, RSA作为密钥交换算法；加密算法是AES(密钥和初始向量的长度都是256)；MAC算法是SHA。
HTTPS用到的加密算法一般如下：
	1. 非对称：RAS, DSA/DSS, ECDHE, DH, ECDH；
	2. 对称: AES, RC4, 3DES
	3. MAC: MD5, SHA1, SHA256;
HTTPS的握手流程：首先是TCP握手，TCP三次完成之后才进入SSL握手，SSL握手总是以ClientHello消息开始，就跟TCP握手总是以SYN包开始一样。
-----------------------------------------
SSL/TLS握手时的私钥用途(RSA, ECDHE)：
两种使用方式分别是：使用RSA来做密钥交换和使用ECDHE来做密钥交换。
对于RSA来说，客户端生成预主密钥，然后用公钥加密再发给服务器，服务器用私钥来解密得到预主密钥，然后由预主密钥生成主密钥，再由主密钥生成会话密钥，最后用会话密钥来通信。
对于ECDHE来说，客户端和服务端双方是交换椭圆曲线参数，私钥只是用来签名，这是为了保证这个消息是持有私钥的人给我发的，而不是冒充的。双方交换完参数之后生成预主密钥，再生成主密钥和会话密钥。
可以看出RSA和椭圆曲线密钥交换算法的私钥用途是不一样的，RSA密钥交换是用来做加解密的，椭圆曲线密钥交换是用来做签名的。
-----------------------------------------
SSL/TLS的预主密钥，主密钥和会话密钥：
主密钥是由预主密钥、客户端随机数和服务器随机数通过PRF函数来生成；
会话密钥是由主密钥、客户端随机数和服务器随机数通过PRF函数来生成，会话密钥里面包含对称加密密钥、消息认证和CBC模式的初始化向量，但对于非CBC模式的加密算法来说，就没有用到这个初始向量。
session缓存和session ticket里面保存的是主密钥，而不是会话密钥，这是为了保证每次会话都是独立的，这样才安全，即使一个主密钥泄漏了也不影响其他会话。
-----------------------------------------
TLS（Transport Layer Security，传输层安全）：其前身是SSL，它最初的几个版本（SSL 1.0、SSL 2.0、SSL 3.0）由网景公司开发，1999年从3.1开始被IETF标准化并改名，发展至今已经有TLS 1.0、TLS 1.1、TLS 1.2 三个版本。SSL3.0和TLS1.0由于存在安全漏洞，已经很少被使用到。需要关注一点的就是TLS1.3是TLS协议一个非常重大的改革。不管是安全性还是用户访问速度都会有质的提升。TLS1.3协议的最终版本（RFC8446）已于2018年8月10日发布，各主流浏览器也逐渐支持TLS1.3。

TLS协议主要有五部分：应用数据层协议，握手协议，报警协议，加密消息确认协议，心跳协议。
TLS协议本身又是由Record协议传输，Record协议的格式如下：
	1. ContentType
	2. Version
	3. Length
	4. ProtocolMessage
	5. MAC(可选)
	6. padding(cbc)
----------------------------------------
密钥交换算法本身非常复杂，密钥交换过程涉及到随机数生成、模指数运算、空白补齐、加密、签名等操作。
常见的密钥交换算法有RSA, ECDHE, DH, DHE等算法，它们的特性如下：
RSA：算法实现简单，历史悠久，经过了长时间的破解测试，安全性高。缺点就是需要比较大的素数（目前常用的是2048位）来保证安全强度，很消耗CPU运算资源。RSA是目前唯一一个既能用于密钥交换又能用于证书签名的算法。
DH：Diffie-Hellman密钥交换算法，诞生时间比较早，但是1999年才公开。缺点是比较消耗CPU性能。
ECDHE：使用椭圆曲线（ECC）的DH算法，优点是能用较小的素数（256位）实现RSA相同的安全等级。缺点是算法实现复杂，用于密钥交换的历史不长，没有经过长时间的安全攻击测试。
ECDH：不支持PFS，安全性低，同时无法实现False Start。
DHE：不支持ECC。非常消耗CPU资源。
建议优先支持RSA和ECDH_RSA密钥交换算法。原因是：
ECDHE支持ECC加速，计算速度更快。支持PFS，更加安全。支持False Start，用户访问速度更快。
目前还有至少20%以上的客户端不支持ECDHE，我们推荐使用RSA而不是DH或者DHE，因为DH系列算法非常消耗CPU（相当于要做两次RSA计算）。
----------------------------------------
非对称加密相比对称加密更加安全，但也存在两个明显缺点：
	1. CPU计算资源消耗非常大。一次完全TLS握手，密钥交换时的非对称解密计算量占整个握手过程的90%以上。而对称加密的计算量只相当于非对称加密的0.1%，如果应用层数据也使用非对称加解密，性能开销太大，无法承受。
	2. 非对称加密算法对加密内容的长度有限制，不能超过公钥长度。比如现在常用的公钥长度是2048位，意味着待加密内容不能超过256个字节。
所以公钥加密目前只能用来作密钥交换或者内容签名，不适合用来做应用层传输内容的加解密。

ElasticSearch应用场景：
	1. 日志聚合；
	2. jaeger后端存储；
	3. 全文搜索；
	4. 海量数据下的近实时数据分析；

ElasticSearch倒排索引的底层实现是基于FST(Finite State Transducer)数据结构
Lucene从4+版本开始大量使用的数据结构是FST。FST有两个优点：
	1. 空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；
	2. 查询速度快。O(len(str))的查询时间复杂度。

ElasticSearch是如何实现master选举的：
前置前提：
	1. 只有候选主节点(master:true)的节点才能成为主节点；
	2. 最小主节点数(min_master_nodes)的目的是防止脑裂；
核心入口为findMaster，选择主节点成功返回对应Master，否则返回Null。选举流程如下：
	第一步：确认候选主节点数达标，elasticsearch.yml设置的值；
		discovery.zen.minimum_master_nodes;
	第二步：先判定是否具备master资格，具备候选主节点资格的优先返回；若两节点都为候选主节点，则id小的值为主节点。
ElasticSearch是如何实现master选举的：
	1. ElasticSearch的选主是ZenDiscovery模块负责的，主要包括Ping(节点之间通过这个RPC来发现彼此)和Unicast(单播模块包含一个主机列表以控制哪些节点需要ping通)这两部分；
	2. 对所有可以成为master的节点(node.master:true)根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个节点，暂且认为它是master节点；
	3. 如果对某个节点的投票数达到一定的值(比如master节点数/2+1)并且该节点自己也选择自己，那这个节点就是master。否则重新选举一直到满足上述条件；
	4. 补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。

详细描述一下ElasticSearch搜索的过程：
	1. 搜索被执行成一个两阶段过程，称之为Query then Fetch；
	2. 在初始查询阶段时，查询会广播到索引中每一个分片拷贝(主分片或者副本分片)。每个分片在本地执行搜索并构建一个匹配文档的大小为from+size的优先队列。
		PS: 在搜索的时候是会查询FileSystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。
	3. 每个分片返回各自优先队列中所有文档的ID和排序值给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。
	4. 接下来就是取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个get请求。每个分片加载并丰富文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。
	5. 补充：Query then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。

在并发情况下，Elasticsearch如何保证读写一致：
	1. 可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；
	2. 另外对于写操作，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在不同的节点重建。
	3. 对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。

public class ArrayList<E> extends AbstractList<E> 
		implements List<E>, RandomAccess, Cloneable, java.io.Serializable {
	....
}

public class LinkedList<E> extends AbstractSequentialList<E> 
		implements List<E>, Deque<E>, Cloneable, java.io.Serializable {
	...
}

public class ConcurrentHashMap<K, V> extends AbstractMap<K, V> 
	implements ConcurrentMap<K, V> Serializable {
	...
	private transient volatile CounterCell[] counterCells;
	...
	final long sumCount() {
		CounterCell[] as = counterCells;
		CounterCell a;
		long sum = baseCount;
		if (as != null) {
			for (int i = 0;i < as.length; ++i) {
				if ((a = as[i]) != null) {
					sum += a.value;
				}
			}
		}
		return sum;
	}
	...
	public int size() {
		long n = sumCount();
		return ((n < 0L) ? 0 : 
				(n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : 
				(int)n);
	}
	...
}

JDK中的ConcurrentMap<K, V>接口的实现类有: ConcurrentHashMap, ConcurrentNavigableMap, ConcurrentSkipListMap;

Dubbo的Provider接收客户端请求后涉及的类(基于Netty通信)：
	1. NioWorker;
	2. Channels;
	3. Channel;
	4. ChannelPipeline(DefaultChannelPipeline);
	5. DefaultChannelHandlerContext;
	6. SimpleChannelUpstreamHandler(NettyCodecAdapter$InternalDecoder);
	7. NettyChannel;
	8. DubboCountCodec;
	9. DubboCodec;
	10. Request;
	11. DecodeableRpcInvocation;
	12. MultiMessage;
	13. NettyHandler;
	14. NettyServer;
	15. MultiMessageHandler;
	16. HeartbeatHandler;
	17. AllChannelHandler;
	18. ChannelEventRunnable;
	19. DecodeHandler;
	20. HeaderExchangHandler;
	21. DubboProtocol$requestHandler;
	22. ProtocolWrapper链;
	23. RegistryProtocol$InvokerDelegete;
	24. DelegateProviderMetaDataInvoker;
	25. JavassistProxyFactory;
Dubbo各层说明：
	1. config配置层：对外配置接口，以ServiceConfig, ReferenceConfig为中心，可以直接初始化配置类，也可以通过spring解析配置生成配置类。
	2. proxy服务代理层：服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton，以ServiceProxy为中心，扩展接口为ProxyFactory。
	3. registry注册中心层：封装服务地址的注册与发现，以服务URL为中心，扩展接口为RegistryFactory, Registry, ReistryService。
	4. cluster路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以Invoker为中心，扩展接口为Cluster, Directory, Router, LoadBalance。
	5. monitor监控层：RPC调用次数和调用时间监控，以Statistics为中心，扩展接口为MonitorFactory, Monitor, MonitorService。
	6. protocol远程调用层：封装RPC调用，以Invocation, Result为中心，扩展接口为Protocol,Invoker, Exporter。
	7. exchange信息交换层：封装请求应答模式，同步转异步，以Request, Response为中心，扩展接口为Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer。
	8. transport网络传输层：抽象mina和netty为统一接口，以Message为中心，扩展接口为Channel，Transporter, Client, Server, Codec。
	9. serialize数据序列化层：可复用的一些工具，扩展接口为Serialization, ObjectInput, ObjectOutput, ThreadPool.

Dubbo 提供了4种负载均衡实现:
	1. 基于权重随机算法的RandomLoadBalance
	2. 基于最少活跃调用数算法的LeastActiveLoadBalance
	3. 基于hash一致性的ConsistentHashLoadBalance
	4. 基于加权轮询算法的RoundRobinLoadBalance

AbstractLoadBalance除了实现了LoadBalance接口方法，还封装了公共逻辑，比如服务提供者权重计算逻辑，实现如下：
protected int getWeight(Invoker<?> invoker, Invocation invocation) {
	// 从 url 中获取权重 weight 配置值
    int weight = invoker.getUrl().getMethodParameter(invocation.getMethodName(), Constants.WEIGHT_KEY, Constants.DEFAULT_WEIGHT);
    if (weight > 0) {
        // 获取服务提供者启动时间戳
        long timestamp = invoker.getUrl().getParameter(Constants.REMOTE_TIMESTAMP_KEY, 0L);
        if (timestamp > 0L) {
            // 计算服务提供者运行时长
            int uptime = (int) (System.currentTimeMillis() - timestamp);
            // 获取服务预热时间，默认为10分钟
            int warmup = invoker.getUrl().getParameter(Constants.WARMUP_KEY, Constants.DEFAULT_WARMUP);
            // 如果服务运行时间小于预热时间，则重新计算服务权重，即降权
            if (uptime > 0 && uptime < warmup) {
                // 重新计算服务权重
                weight = calculateWarmupWeight(uptime, warmup, weight);
            }
        }
    }
    return weight;
}

static int calculateWarmupWeight(int uptime, int warmup, int weight) {
	// 计算权重，逻辑上形似与(uptime/warmup) * weight;
	// 随着服务运行时间uptime增大，权重计算ww会慢慢接近配置值weight
	int ww = (int) ((float)uptime / ((float)warmup/(float)weight));
	return ww < 1 ? 1 : (ww > weight ? weight : ww);
}
上面是权重的计算过程，该过程主要用于保证当服务运行时长小于服务预热时间时，对服务进行降权，避免让服务在启动之初就处于高负债状态。服务预热是一个优化手段，与类似的还有JVM预热。主要目的是让服务启动后"低功率"运行一段时间，使其效率慢慢提升至最佳状态。

RandomLoadBalance的算法思想比较简单，在经过多次请求后，能够将调用请求按照权重值进行"均匀"分配。当然RandomLoadBalance也存在一定的缺点，当调用次数比较少时，Random产生的随机数可能会比较集中，此时多数请求会落在同一台服务器上。这个缺点并不是很严重，多数情况下可以忽略。RandomLoadBalance 是一个简单，高效的负载均衡实现，因此 Dubbo 选择它作为缺省实现。

LeastActiveLoadBalance 翻译过来是最小活跃数负载均衡。活跃调用数越小，表明该服务提供者效率越高，单位时间内可处理更多的请求。此时应优先将请求分配给该服务提供者。在具体实现中，每个服务提供者对应一个活跃数 active。初始情况下，所有服务提供者活跃数均为0。每收到一个请求，活跃数加1，完成请求后则将活跃数减1。在服务运行一段时间后，性能好的服务提供者处理请求的速度更快，因此活跃数下降的也越快，此时这样的服务提供者能够优先获取到新的服务请求、这就是最小活跃数负载均衡算法的基本思想。除了最小活跃数，LeastActiveLoadBalance 在实现上还引入了权重值。所以准确的来说，LeastActiveLoadBalance 是基于加权最小活跃数算法实现的。举个例子说明一下，在一个服务提供者集群中，有两个性能优异的服务提供者。某一时刻它们的活跃数相同，此时 Dubbo 会根据它们的权重去分配请求，权重越大，获取到新请求的概率就越大。如果两个服务提供者权重相同，此时随机选择一个即可。
-----------------------------
分布式锁需要注意的几个要点：
	1. 确保互斥：在同一时刻，必须保证锁至多被一个客户端持有；
	2. 不能死锁：在一个客户端持有锁期间崩溃而没有主动解锁情况下，也能保证后续其他客户端可以获取
	3. 避免活锁：在获取锁失败的情况下，反复进行重试操作，占用CPU，影响性能；
	4. 实现更多锁特性：锁中断、锁重入、锁超时等；
	5. 确认客户端只能解锁自己持有的锁。

Redisson分布式锁有个缺陷：在Redis哨兵模式下，Client A对master写入了redisson锁，此时会异步复制给对应的slave节点。但是这个过程中一旦发生master节点宕机，主备切换，slave节点变为master节点。这时Client B来尝试加锁，也能加锁成功，违反了分布式锁的语义。

select student from student_scores group by student having min(score) > 90;
-----------------------------------------------
Cache Aside Pattern:旁路缓存方案的经验实践，这个实践又分为读实践和写实践。
对于读请求
	1. 先读cache，再读db
	2. 如果cache hit，则直接返回数据
	3. 如果cache miss，则访问db，并将数据set回缓存
对于写请求：
	1. 淘汰缓存，而不是更新缓存；
	2. 先操作数据库，再淘汰缓存；

Cache Aside Pattern为什么建议淘汰缓存，而不是更新缓存？
答：如果更新缓存，在并发写时，可能出现数据不一致；
Cache Aside Pattern为什么建议先操作数据库，再操作缓存？
答：如果先操作缓存，在读写并发时，可能出现数据不一致。
Cache Aside Pattern方案存在什么问题？
答：如果先操作数据库，再淘汰缓存，在原子性被破坏时：
	1. 修改数据库成功了；
	2. 淘汰缓存失败了；
导致数据库与缓存的数据不一致。
