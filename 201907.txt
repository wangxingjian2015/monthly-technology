
主要讨论RR隔离级别，因为RC只是少了间隙锁。

意向共享锁(Intention shared lock: IS)
意向排它锁(Intention exclusive lock: IX)
意向锁解决表级锁和行级锁的冲突。意向锁之间兼容
事务中请求S锁和X锁前，需要先获得对应的IX、IS锁。

行锁：
	1. 记录锁:Record Locks；单条索引记录上加锁，record lock锁住的永远是索引，而非记录本身。如果没有显式索引，InnoDB会创建聚集索引。
	2. 间隙锁：Gap Locks；锁住一个索引区间(开区间). 锁住索引记录的区间，或第一条索引记录之前的范围，或最后一条索引记录之后的范围。
	3. 临键锁：Next-Key Locks；记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间(左开右闭区间)。
	4. 插入意向锁：Insert Intention Locks；一种特殊的间隙锁。两个事务只要插入的行没有冲突，即使在同一个间隙，也可以插入。

存在Insert Intention锁时，申请Gap锁是允许的；但是存在Gap锁时，申请Insert Intention锁时是被阻止的。

自增锁:auto-inc Locks。表级锁，多个事务同时插入时，保证auto_increment列递增。

InnoDB和Memory引擎的数据组织方式是不同的：
	1. InnoDB引擎把数据放在主键索引上，其他索引上保存的是主键ID。这种方式，称之为索引组织表(Index Organizied Table)。
	2. Memory引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，称之为堆组织表(Heap Organizied Table)。

Memory引擎和InnoDB引擎的不同点：
	1. InnoDB表的数据总是有序存放的，而内存表的数据是按照写入顺序存放的；
	2. 当数据文件有空洞的时候，InnoDB表在插入新数据的是，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位置就可以插入新值。
	3. 数据位置发生变化的时候，InnoDB表只需要修改主键索引，而内存表需要修改所有索引；
	4. InnoDB表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找；而内存表没有这个区别，所有索引的"地位"都是相同的。
	5. InnoDB支持变长数据类型，不同记录的长度可能不同；内存表不支持Blob和Text字段，并且 即使定义了varchar(N)，实际也当作char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。

总结：
	1. RR下，事务中第一次Read操作时，会建立read-view；
	2. RC下，事务中每次Read操作时，都会建立read-view;
不同业务选择不同的隔离级别。

undo log有两个作用：提供回滚和MVCC。
在数据修改的时候，不仅记录redo，还记录相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚。
undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。

不同时刻启动的事务会有不同的read-view。同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制MVCC。当系统里没有比这个回滚日志更早的read-view的时候，回滚日志会被删除。所以要避免长事务。

redo log主要节省的是随机写磁盘的IO消耗(转成顺序写)，而change buffer主要节省的则是随机读磁盘的IO消耗。

//wt可以看线程上下文切换
$pidstat -wt <pid>

uptime: 平均负载
top: 平均负载，运行队列，整体的CPU使用率以及每个进程的状态和CPU使用率
htop: top增强版，以不同颜色区分不同类型的进程，更直观
atop: CUP，内存，磁盘和网络等各种资源的全面监控
vmstat: 系统整体的CPU使用率、上下文切换次数、中断次数，还包括处于运行和不可中断的进程数量
mpstat: 每个CPU的使用率和软中断次数
pidstat: 进程和线程的CPU使用率、中断上下文切换次数
/proc/softirqs：软中断类型和每个CPU上的累积中断次数
/proc/interrupts：硬中断类型和每个CPU上的累积中断次数
ps:每个进程的状态和CPU使用率
pstree: 进程的父子关系
dstat: 系统整体的CPU使用率 
sar: 系统整体的CPU使用率，包括可配置的历史数据 
strace: 进程的系统调用
perf：CPU性能事件剖析，如调用链分析、CPU缓存、CPU调度等
execsnoop：监控短时进程

public class ConcurrentHashMap<K, V> extends AbstractMap<K, V>
	implements ConcurrentMap<K, V>, Serializable {
...
	// The smallest table capacity for which bins may be treeified.
	//(Otherwise the table is resized if too many nodes in a bin.)
	//The value should be at leaset 4 * TREEIFT_THRESHOLD to avoid 
	// conflicts between resizing and treeification thresholds.
	static final int MIN_TREEIFY_CAPACITY = 64;
...
}

select * from information_schema.innodb_lock_waits;
select * from information_schema.innodb_locks;
show engine innodb status\G;
-------------------------------------------------
插入意向锁：Insert Intention Locks
插入意向锁本质上可以看成是一个Gap Lock。
	- 普通的Gap Lock不允许在(上一条记录，本记录)范围内插入数据；
	- 插入意向锁Gap Lock允许在(上一条记录，本记录)范围内插入数据； 
插入意向锁的作用是为了提高并发插入的性能，多个事务同时写入不同数据至同一索引范围(区间)内，并不需要等待其他事务完成，不会发生锁等待。

关于Insert Intention Locks的锁等待有两种情况：
	case1：事务A获得Gap Lock，事务B Insert Intention Lock等待；
	case2: 事务A获得Next-key Lock， 事务B Insert Intention Lock等待。
-------------------------------------------------
自增锁(AUTO-INC Locks)
在InnoDB中，每个含有自增列的表都有一个自增长计数器。当对含有自增长计数器的表进行插入时，首先会执行select max(auto_inc_col) from t for update来得到计数器的值，然后再将这个值加1赋予自增长列。这种方式称之为AUTO_INC Lock。
AUTO_INC Lock是一种特殊的表锁，它在完成对自增值插入的SQL语句后立即释放，所以性能会比事务完成后释放锁要高。由于是表级锁，所以在并发环境下依然存在性能问题。
从MySQL5.1.22开始，InnoDB中提供了一种轻量级互斥量的自增长实现机制，同时InnoDB存储引擎提供了一个参数innodb_autoinc_lock_mode来控制自增长的模式，进而提高自增长值插入的性能。
参数innodb_autoinc_lock_mode的说明：
参数值0:这是MySQL5.1.22版本之前自增长的实现方式，即通过表锁的AUTO-INC Locking方式。因为有了新的自增长实现方式，0这个选项不应该是新版用户的首选项。
参数值1：该参数的默认值。对于"simple inserts"，该值用互斥量(mutex)去对内存中的计数器进行累加的操作。对于"bulk inserts"，还是使用传统表锁的AUTO-INC Locking方式。在这种配置下，如果不考虑回滚操作，对于自增值列的增长还是连续的。并且在这种方式下，statement-based方式的replication还是能很好地工作。需要注意的是，如果已经使用AUTO-INC Locking方式去产生自增长的值，而这时需要再进行"simple inserts"的操作时，还是需要等待AUTO-INC Locking的释放。
参数值2：在这个模式下，对于所有的"INSERT-like"自增长值的产生都是通过互斥量，而不是AUTO-INC Locking的方式。显然，这是性能最高的方式。然而，这会带来一定的问题。因为并发插入的存在，在每次插入时，自增长的值可能不是连续的。此外，最重要的是，基于Statement-Base Replication会出现问题。因此，使用这个模式，任何时候都应该使用row-base replication。这样才能保证最大的并发性能及replication主从数据的一致。
-------------------------------------------------
show engine innnodb status;
需要注意：虽然插入意向锁含有意向锁三个字，但是它并不属于意向锁而属于间隙锁，因为意向锁是表锁而插入意向锁是行锁。
---------------------select/poll/epoll之间的区别----------------------------
select：时间复杂度O(n)。它仅仅知道有IO事件发生了，并不知道是哪几个流(可能一个、多个、甚至全部)，只能轮询所有流，找出可读/可写的流，进行读/写操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。
poll:时间复杂度O(n)。 本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，但是它没有最大连接数的限制，原因是它基于链表来存储的。
epoll：时间复杂度O(1)。epoll可以理解为event poll，不同于忙轮询和无差别轮询,epoll会把哪个流发生了什么IO事件通知给我们。所以说epoll实际上是事件驱动(每个事件关联上fd)的，此时对这些流的操作都是有意义的(复杂度降低到了O(1)).

select, poll, epoll都是IO多路复用的机制。IO多路复用就是通过一种机制，可以监视多个描述符，一旦某个描述符就绪(读就绪或写就绪)，能够通知程序进行相应的读写操作。但select,poll,epoll本质上都是同步IO,因为他们都需要读写事件就绪后自己负责进行读写，也就是这个读写过程是阻塞的。而异步IO无需自己负责读写，异步IO的实现会负责把数据从内核拷贝到用户空间。
epoll和select都能提供多路IO复用的解决方案。在Linux都能支持，其中epoll是Linux特有的，而select是POSIX所规定的，一般操作系统均有实现。
-------------------------------------------------
select:
select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：
	1. 单个进程可监视的fd数量被限制，即能监听端口的大小有限。
		一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max。32位机器默认1024, 64位机器默认2048。
	2. 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。
		当套接字比较多时，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费CPU时间。如果能给套接字注册回调函数，当他们活跃时，自动完成相关操作，就避免了轮询，这正是epoll与kqueue做到的。
	3. 需要维护一个用于存放大量fd的数据结构，这样会是的用户空间和内核空间中传递该结构时复制开销大。
-------------------------------------------------
poll:
poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。
它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有缺点：
	1. 大量的fd的数组被整体复制于用户态和内核态地址之间，而不管这样的复制是否有意义。
	2. poll还有一个特点是"水平触发"，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。
-------------------------------------------------
epoll:
epoll有epoll lt和epoll et两种触发模式，LT是默认的模式，ET是高速模式。LT模式下，只要这个fd还有数据可读，每次epoll_wait都会返回它的事件，提醒用户程序去操作。而在ET(边缘触发)模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值，或者遇到EAGAIN错误。还有一个特点是，epoll使用事件的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。

epoll为什么要有epoll ET触发模式？
如果采用epoll LT模式的话，系统中一旦有大量不需要读写的就绪文件描述符，它们每次调用epoll_wait都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率。而采用epoll ET这种边沿触发模式的话，当被监控的文件描述符有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小),那么下次调用epoll_wait()时，它不会再次通知，也就是只会通知一次，直到该文件描述符上出现第二次读写事件才会通知!!!这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。

epoll的优点：
	1. 没有最大并发连接的限制，能打开的F的上限远大于1024(1G的内存上能监听10万个端口)
	2. 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即epoll最大的优点就在于只管"活跃"的连接，而跟总连接无关，因此在实际的网络环境中，epoll的效率就会远远高于select和poll。
	3. 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。
-------------------------------------------------
select, poll, epoll区别总结：
	1. 支持一个进程所能打开的最大连接数；
		select:单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是(32位机器是1024, 64位机器是2048)，当然可以进行修改，然后重新编译内核，但是性能可能受到影响。
		poll:本质上select没有区别，但是它没有最大连接数的限制，原因是它基于链表来存储的。
		epoll:虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存可以20万左右；
	2. FD剧增后带来的IO效率问题。
		select：因为每次调用都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的"线性下降性能问题"
		poll:同select
		epoll:因为epoll内核中实现是根据每个FD上的callback函数来实现的，只有活跃socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两个的线性下降的性能问题，但是所有socket都很活跃的情况下，会有性能问题。
	3. 消息传递方式；
		select:内核需要将消息传递到用户空间，都需要内核拷贝动作；
		poll: 同上
		epoll: 通过内核和用户空间共享一块内存来实现的。
总结：综上，在选择select, poll, epoll要根据实际的使用场合以及三种方式的自身特点；
	1. 表面上epoll的性能最好，但是在连接数少并且连接都很活跃的情况下，select和poll的性能可能比epoll好，比较epoll的通知机制需要很多函数回调。
	2. select低效是因为每次它都需要轮询。但是低效也是相对的，视情况而定，也可通过良好的设计改善。
-------------------------------------------------
ForkJoinPool:
@sun.misc.Contended 
public class ForkJoinPool extends AbstractExecutorService {
	...
	
	/*
		Recording WorkQueues. WorkQueue are recorded in the "workQueues" array.
		The array is created upon first use(see #externalSubmit) and expanded if necessary. 
		Updates to the array while recording new works and unrecording terminated ones are 
		protected from each other by the runState lock, but the array is otherwise concurrently 
		readable, and accessed directly. We also ensure that reads of the array reference itself 
		never become too stale. To simplify index-based operations, the array size is always a 
		power of two, and all readers must tolerate null slots. Worker queue are at odd indices.
		Shared (submission) queues are at even indices, up to a maximum of 64 slots, to limit 
		growth even if array needs to expand to add more workers. Grouping them together in this way
		simplifies and speeds up task scanning.
	
	*/
	...
}

ForkJoinPool里有三个重要角色：
	1. ForkJoinWorkerThread
	2. WorkQueue
	3. ForkJoinTask
-------------------------------------------------
/* A thread managed by a ForkJoinPool, which executes ForkJoinTask.
This class is subclassable solely for the sake of adding functionality -- there are no 
overridable methods dealing with scheduling or execution. However, you can override initializationg and 
termination methods surrounding the main task processing loop.
If you do create such as subclass, you will also need to supply a custom ForkJoinPool.ForkJoinWorkerThreadFactory to 
ForkJoinPool#ForkJoinPool use it in a ForkJoinPool.
*/
public class ForkJoinWorkerThread extends Thread {
	final ForkJoinPool pool;   //the pool this thread works in 
	final ForkJoinPool.WorkQueue workQueue;   //work-stealing mechanics 
	...
	/* Returns the unique index number of this thread in its pool.
	The returned value ranges from zero to the maximum number of threads(minus one) that may exist in the pool, 
	and does not change during the lifetime of the thread. This method may be useful for application that track 
	status or collect results per-worker-thread rather than per-task.
	*/
	public int getPoolIndex() {
		return workQueue.getPoolIndex();
	}
	
	//Erases ThreadLocals by nulling out Thread maps.
	final void eraseThreadLocals() {
		U.putObject(this, THREADLOCALS, null);
		U.putObject(this, INHERITABLETHREADLOCALS, null);
	}
	
	//Non-public hook method for InnocuousForkJoinWorkerThread
	void afterTopLevelExec() {
	}
	
	/* A worker thread that has no permissions, is not a member of any user-defined ThreadGroup, 
	and erases all ThreadLocals after running each top-level task.
	*/
	static final class InnocuousForkJoinWorkerThread extends ForkJoinWorkerThread {
		
	}
	...
}


/* Abstract base class for tasks that run within a ForkJoinPool.
A ForkJoinTask is a thread-like entity that is much lighter weight than a normal thread.
Huge numbers of tasks and subtasks may be hosted by a small number of actual threads in 
a ForkJoinPool, at the price of some usage limitations.

...
The ForkJoinTask class is not usually directly subclassed. Instead, you subclass one of 
the abstract classes that support a particular style of fork/join processing, typically 
RecursiveAction for most computations that do not return results, RecursiveTask for those that do, 
and CountedCompleter for those in which completed actions trigger other actions. 
Normally, a concrete ForkJoinTask subclass declared fields comprising its parameters, established in 
a constructor, and then defines a #compute method that somehow uses the control methods supplied by 
this base class.

* <p>Method {@link #join} and its variants are appropriate for use
 * only when completion dependencies are acyclic; that is, the
 * parallel computation can be described as a directed acyclic graph
 * (DAG). Otherwise, executions may encounter a form of deadlock as
 * tasks cyclically wait for each other.  However, this framework
 * supports other methods and techniques (for example the use of
 * {@link Phaser}, {@link #helpQuiesce}, and {@link #complete}) that
 * may be of use in constructing custom subclasses for problems that
 * are not statically structured as DAGs. To support such usages, a
 * ForkJoinTask may be atomically <em>tagged</em> with a {@code short}
 * value using {@link #setForkJoinTaskTag} or {@link
 * #compareAndSetForkJoinTaskTag} and checked using {@link
 * #getForkJoinTaskTag}. The ForkJoinTask implementation does not use
 * these {@code protected} methods or tags for any purpose, but they
 * may be of use in the construction of specialized subclasses.  For
 * example, parallel graph traversals can use the supplied methods to
 * avoid revisiting nodes/tasks that have already been processed.
 * (Method names for tagging are bulky in part to encourage definition
 * of methods that reflect their usage patterns.)
 
...
*/
public abstract class ForkJoinTask<V> implements Future<V>, Serializable {
...
	// Marks completion and wakes up threads waiting to join this task.
	// @param completion one of NORMAL, CANCELLED, EXCEPTIONAL
	private int setCompletion(int completion) {
		for(int s;;) {
			if ((s = status) < 0)
				return s;
			if (U.compareAndSwapInt(this, STATUS, s, s|completion)) {
				if ((s >>> 16) != 0)
					synchronized (this) {notifyAll();}
				return completion;
			}
		}
	}
	
	/* Primary execution method for stolen tasks. Unless done, calls exec and 
		records status if completed, but doesn't wait for completion otherwise.
	*/
	final int doExec() {
		int s; boolean completed;
		if ((s = status) >= 0) {
			try {
				completed = exec();
			} catch (Throwable rex) {
				return setExceptionalCompletion(rex);
			}
			if (completed)
				s = setCompletion(NORMAL);
		}
		return s;
	}
	
	// public methods 
	/* Arranges to asynchronously execute this task in the pool the current task is running in, 
	  if applicable, or using the ForkJoinPool.commonPool() if not inForkJoinPool.
	  while it is not necessarily enforced, it is a usage error to fork a task more than once unless 
	  it has completed and been reinitialized. Subsequent modifications to the state of this task or 
	  any data it operates on are not necessarily consistently observable by any thread other than the one 
	  executing it unless preceded by a call to #join or related methods, or a call to #isDone returning true.
	*/
	public final ForkJoinTask<V> fork() {
		Thread t;
		if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
			((ForkJoinWorkerThread)t).workQueue.push(this);
		else
			ForkJoinPool.common.externalPush(this);
		return this;
	}
	
	/* Returns the result of the computation when it #isDone is done.
		This method differs from #get() in that abnormal completion results in 
		RuntimeException or Error, not ExecutionException, and that interrupts of 
		the calling thread do not cause the method to abruptly return by throwing InterruptedException.
	*/
	public final V join() {
		int s;
		if ((s = doJoin() & DONE_MASK) != NORMAL)
			reportException(s);
		return getRawResult();
	}
	/**
     * Commences performing this task, awaits its completion if
     * necessary, and returns its result, or throws an (unchecked)
     * {@code RuntimeException} or {@code Error} if the underlying
     * computation did so.
     *
     * @return the computed result
     */
    public final V invoke() {
        int s;
        if ((s = doInvoke() & DONE_MASK) != NORMAL)
            reportException(s);
        return getRawResult();
    }
	
	/* Attempts to cancel execution of this task. This attempt will fail 
		if the task has already completed or could not be cancelled for some other reason.
		If successful, and this task has not started when #cancel is called, execution of 
		this task is suppressed. After this method returns successfully, unless there is an 
		intervening call to #reinitialize, subsequent calls to #isCancelled, #isDone, and #cancel will 
		return true and calls to #join and related methods will result in CancellationException.
		
		This method may be overridden in subclasses, but if so, must still ensure that these properties hold.
		In particular, the #cancel method itself must not throw exceptions.
		
		This method is designed to be invoked by other tasks. To terminate the current task, 
		you can just return or throw an unchecked exception from its computation method, or 
		invoke #completeExceptionally(Throwable).
	*/
	public boolean cancel(boolean mayInterruptIfRunning) {
		return (setCompletion(CANCELLED) & DONE_MASK) == CANCELLED;
	}
	
	/**
     * Completes this task, and if not already aborted or cancelled,
     * returning the given value as the result of subsequent
     * invocations of {@code join} and related operations. This method
     * may be used to provide results for asynchronous tasks, or to
     * provide alternative handling for tasks that would not otherwise
     * complete normally. Its use in other situations is
     * discouraged. This method is overridable, but overridden
     * versions must invoke {@code super} implementation to maintain
     * guarantees.
     *
     * @param value the result value for this task
     */
    public void complete(V value) {
        try {
            setRawResult(value);
        } catch (Throwable rex) {
            setExceptionalCompletion(rex);
            return;
        }
        setCompletion(NORMAL);
    }
	
	
	/* Waits if necessary for the computation to complete, and then retrieves its result.
	*/
	public final V get() throws InterruptedException, ExecutionException {
		int s = (Thread.currentThread() instanceof ForkJoinWorkerThread) ?
			doJoin() : externalInterruptibleAwaitDone();
		Throwable ex;
		if ((s &= DONE_MASK) == CANCELLED)
			throw new CancellationException();
		if (s == EXCEPTIONAL && (ex = getThrowableException()) != null)
			throw new ExecutionException(ex);
		return getRawResult();
	}
	
	/* Possibly executes tasks until the pool hosting the current task 
		ForkJoinPool#isQuiescent is quiescent. This method may be of use in designs 
		in which many tasks are forked, but none are explicitly joined, instead 
		executing them until all are processed.
	*/
	public static void helpQuiesce() {
		Thread t;
		if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) {
			ForkJoinWorkerThread wt = (ForkJoinWorkerThread)t;
			wt.pool.helpQuiescePool(wt.workQueue);
		} else {
			ForkJoinPool.quiesceCommonPool();
		}
	}
	
	/*Resets the internal bookkeeping state of this task, allowing a subsequent #fork. 
		This method allows repeated reuse of this task, but only if reuse occurs when this task 
		has either never been forked, or has been forked, then completed and all outstanding joins
		of this task have also completed. Effects under any other usage conditions are not guaranteed.
		This method may be useful when executing pre-constructed trees of subtasks in loops.
		Upon completion of this method, #isDone() reports false, and #getException() reports null.
		However, the value returned by #getRawResult() is unaffected. To clear this value, you can 
		invoke #setRawResult(null).
	*/
	public void reinitialize() {
		if ((status & DONE_MASK) == EXCEPTIONAL)
			clearExceptionalCompletion();
		else
			status = 0;
	}
	
	/* Returns an estimate of how many more locally queued tasks are held by the
		current worker thread than there are other worker threads that might steal them, 
		or zero if this thread is not operating in a ForkJoinPool. This value may be useful for 
		heuristic decisions about whether to fork other tasks. In many usages of ForkJoinTasks, 
		at steady state, each worker should aim to maintian a small constant surplus(for example, 3)
		of tasks, and to process computations locally if this threshold is exceeded. 
	*/
	public static int getSurplusQueuedTaskCount() {
		return ForkJoinPool.getSurplusQueuedTaskCount();
	}
...
}



Resilience4J：
是Spring Cloud G版本推荐的容错方案，是一个轻量级的容错库。借鉴了Hystrix而设计，并且采用JDK8函数式编程，即lambda表达式。为什么是轻量级？因为它的库只使用Vavr(以前称Javaslang)，它没有任何其他外部库依赖项。相比之下，Netflix Hystrix对Archaius具有编译依赖性，这导致了更多的外部库依赖，比如Guava和Apache Commons。而如果使用Resilience4J，无需引用全部依赖，可以根据需要引入相关模块即可。
Resilience4J提供了一系列增强微服务的可用性功能：
	1. 断路器；
	2. 限流；
	3. 基于信号量的隔离；
	4. 缓存；
	5. 限时；
	6. 请求重启。

Spring Cloud Circuit breaker provides an abstraction across different circuit breaker implementations. It provides a consistent API to use in your applications alowing you the developer to choose the circuit breaker implementation that best fits your need for your app.
Supported Implementations:
	1. Netflix Hystrix;
	2. Resilience4J;
	3. Sentinel;
	4. Spring Retry;

-------------------------------------------------------------
ForkJoinTask: ForkJoinWorkerThread执行的对象，实现了Future。两种类型：一种叫submission,另一种叫task。

ForkJoinPool使用数组保存所有WorkQueue，每个ForkJoinWorkThread有属于自己的WorkQueue，但不是每个WorkQueue都有对应的ForkJoinWorkerThread。
-没有ForkJoinWorkerThread的WorkQueue: 保存的是submission,来自外部提交，在WorkQueue[]的下标是偶数；
-属于ForkJoinWorkerThread的WorkQueue: 保存的是task，在WorkQueue[]的下标是奇数。	
	
WorkQueue是一个双端队列，同时支持LIFO的push和pop操作，和FIFO的poll操作，分别操作top端和base端。ForkJoinWorkerThread操作自己的WorkQueue是LIFO操作(可选FIFO)，除此之外，ForkJoinWorkerThread会尝试steal其他WorkQueue里的任务，这个时候执行的是FIFO操作。
分开两端取任务的好处：
	1. LIFO操作只有对应的ForkJoinWorkThread才能执行，push和pop不需要考虑并发；
	2. 拆分时，越大的任务越在WorkQueue的base端，尽早分解，能够尽快进入计算。

config保存不变的参数，包括了parallelism和mode，供后续读取。mode可选FIFO_QUEUE和LIFO_QUEUE，默认是LIFO_QUEUE,具体用哪种，看具体业务。
ctl是ForkJoinPool中最重要的控制手段，将下面信息按16bit为一组封装在一个long中。
	- AC:活动的ForkJoinWorkerThread数量；
	- TC:总共的ForkJoinWorkerThread数量；
	- SS:WorkQueue状态，第一位表示active的还是inactive，其余15位表示版本号(应对ABA)
	- ID:这里保存了一个WorkQueue在WorkQueue[]的下标，和其他ForkJoinWorkerThread通过字段stackPred组成一个TreiberStack。
TreiberStack:这个栈的pull和poll使用了CAS,所以支持并发下的无锁操作。
AC和TC初始化时，取的是parallelism负数，后续代码可以直接判断正负，为负数代表还没有达到目标数量。另外ctl低32位有个技巧可以直接用sp=(int)ctl取得，为负数代表存在空闲ForkJoinWorkerThread。
线程池缺不了状态的变化，记录字段是runState。
	
ForkJoinPool执行任务的对象是ForkJoinTask,是一个抽象类，有两个具体实现类：RecursiveAction和RecursiveTask。
ForkJoinTask的抽象方法exec由RecursiveAction和RecursiveTask实现，它被定义为final，具体的执行步骤compute延迟到子类实现。RecursiveAction没有返回值，getRawResult返回空。RecursiveTask有返回结果。

ForkJoinTask有一个状态字段status，默认是0.当结果为负数时，有三种结果：
	- NORMAL 
	- CANCELLED 
	- EXCEPTIONAL
除此之外，在得到结果之前，任务状态能够被设置为SIGNAL,表示有线程等待这个任务的结果，执行完成后需要notify通知，具体详细看join()。
ForkJoinTask在触发执行后，并不支持其他特别操作，只能等待任务执行完成。
CountedCompleter是ForkJoinTask的子类，它在子任务协作方面扩展了更多操作。

WorkQueue是一个双端队列，定义在ForkJoinPool类里。
scanState描述WorkQueue当前状态：
	- 偶数表示RUNNING
	- 奇数表示SCANNING
	- 负数表示inactive
stackPred是WorkQueue组成TreiberStack时，保存前者的字段。
volatiel int base;
int top;

base和top分别指向WorkQueue的两端，区别是base带上了volatile，回答了对top端push和pop不考虑并发这个优点。
操作WorkQueue前需要锁定，记录在字段qlock:
	- 1: 锁定
	- 0：未锁定
	- 负数：对应的ForkJoinWorkerThread已经撤销注册，WorkQueue也就终止使用。
WorkQueu也有config，和ForkJoinPool不一样，不要混淆。WorkQueue的config记录了在WorkQueue[]的下标和当前mode。


ForkJoinPool状态修改：
	- STARTED
	- STOP
	- TERMINATED
	- SHUTDOWN
	- RSLOCK
	- RSIGNAL

runState记录了ForkJoinPool的运行状态，除了SHUTDOWN是负数，其他都是正数。前面四中是线程池标准状态流转。在多线程环境修改rnState，需要先获取锁，RSLOCK和RSIGNAL就用在这里。

// Acquires the runState lock; returns current (locked) runState.
private int lockRunState() {
	int rs;
	return ((((rs = runState) & RSLOCK) != 0 || 
			!U.compareAndSwapInt(this, RUNSTATE, rs, rs |= RSLOCK)) ? 
			awaitRunStateLock() : rs);
}
修改前调用lockRunState()锁定，检查当前状态，尝试一次使用CAS修改runState为RSLOCK。需要状态变化的机会很少，大多数时间一次就能成功，但不能排除小几率的竞争，这时候进入awaitRunStateLock()。

-------------------------------------------------------------	
